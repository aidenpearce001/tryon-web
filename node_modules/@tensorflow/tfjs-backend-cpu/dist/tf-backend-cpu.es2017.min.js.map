{"version":3,"file":"tf-backend-cpu.es2017.min.js","sources":["../src/cpu_util.ts","../src/backend_cpu.ts","../src/kernels/Abs.ts","../src/utils/binary_impl.ts","../src/kernels/Complex.ts","../src/kernels/Identity.ts","../src/kernels/Real.ts","../src/kernels/Cast.ts","../src/utils/kernel_utils.ts","../src/kernels/Add.ts","../src/utils/unary_impl.ts","../src/utils/unary_utils.ts","../src/kernels/Ceil.ts","../src/kernels/Exp.ts","../src/kernels/Expm1.ts","../src/kernels/Floor.ts","../src/kernels/Log.ts","../src/kernels/Max_impl.ts","../src/kernels/Multiply.ts","../src/kernels/Rsqrt.ts","../src/kernels/Slice.ts","../src/kernels/Sub.ts","../src/kernels/Transpose_impl.ts","../src/kernels/Unique_impl.ts","../src/base.ts","../src/kernels/Acos.ts","../src/kernels/Acosh.ts","../src/kernels/Asin.ts","../src/kernels/Asinh.ts","../src/kernels/Atan.ts","../src/kernels/Atanh.ts","../src/utils/pool_utils.ts","../src/kernels/AvgPool.ts","../src/kernels/AvgPoolBackprop.ts","../src/kernels/BatchNorm.ts","../src/kernels/Clip.ts","../src/kernels/Imag.ts","../src/kernels/Reshape.ts","../src/kernels/Concat.ts","../src/kernels/Cos.ts","../src/kernels/Cosh.ts","../src/kernels/Dilation2D.ts","../src/kernels/Dilation2DBackpropFilter.ts","../src/kernels/Dilation2DBackpropInput.ts","../src/kernels/Div.ts","../src/kernels/Elu.ts","../src/kernels/Erf.ts","../src/utils/fft_utils.ts","../src/kernels/FFT.ts","../src/kernels/FlipLeftRight.ts","../src/kernels/IFFT.ts","../src/kernels/IsFinite.ts","../src/kernels/IsInf.ts","../src/kernels/IsNaN.ts","../src/kernels/Log1p.ts","../src/kernels/LogicalNot.ts","../src/kernels/Max.ts","../src/kernels/MaxPool.ts","../src/kernels/MaxPoolBackprop.ts","../src/kernels/MaxPoolWithArgmax.ts","../src/kernels/MaxPoolWithArgmax_impl.ts","../src/kernels/NonMaxSuppressionV4.ts","../src/kernels/NonMaxSuppressionV5.ts","../src/kernels/NotEqual.ts","../src/kernels/PadV2.ts","../src/kernels/Reciprocal.ts","../src/kernels/RotateWithOffset.ts","../src/kernels/Round.ts","../src/kernels/Selu.ts","../src/kernels/Sigmoid.ts","../src/kernels/Sign.ts","../src/kernels/Sin.ts","../src/kernels/Sinh.ts","../src/kernels/Softplus.ts","../src/kernels/Transpose.ts","../src/kernels/SpaceToBatchND.ts","../src/kernels/Sqrt.ts","../src/kernels/Square.ts","../src/kernels/SquaredDifference.ts","../src/kernels/Step.ts","../src/kernels/Tan.ts","../src/kernels/Tanh.ts","../src/kernels/Unique.ts","../src/register_all_kernels.ts","../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${\n              opName} does not support complex64 tensors in the CPU backend.`);\n    }\n  });\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {backend_util, BackendTimingInfo, DataStorage, DataType, DataValues, engine, env, kernel_impls, KernelBackend, max, NumericDataType, Rank, Scalar, ShapeMap, slice_util, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D, Tensor5D, TensorBuffer, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV3Impl = kernel_impls.nonMaxSuppressionV3Impl;\nconst split = kernel_impls.split;\nconst tile = kernel_impls.tile;\nconst topkImpl = kernel_impls.topkImpl;\nconst whereImpl = kernel_impls.whereImpl;\nimport * as seedrandom from 'seedrandom';\nimport {assertNotComplex} from './cpu_util';\n\ninterface DataId {}\n\nfunction mapActivation(\n    backend: MathBackendCPU, x: Tensor, activation: backend_util.Activation,\n    preluActivationWeights?: Tensor): Tensor {\n  if (activation === 'linear') {\n    return backend.linear(x);\n  } else if (activation === 'relu') {\n    return backend.relu(x);\n  } else if (activation === 'elu') {\n    return tf.elu(x);\n  } else if (activation === 'relu6') {\n    return backend.relu6(x);\n  } else if (activation === 'prelu') {\n    return backend.prelu(x, preluActivationWeights);\n  }\n  throw new Error(\n      `Activation ${activation} has not been implemented for the CPU backend.`);\n}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo};\n  // refCount keeps track of how many tensors reference it. Used for memory\n  // management.\n  refCount: number;\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, which binds to TensorFlow C++, by running ' +\n            'npm i @tensorflow/tfjs-node, ' +\n            'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n            'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n            'suffix for CUDA) at the start of your program. ' +\n            'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n            '\\n============================');\n      }\n    }\n    const dataId = {};\n\n    this.data.set(dataId, {values, dtype, refCount: 1});\n\n    return dataId;\n  }\n\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: backend_util.BackendValues): TensorInfo {\n    const outId = this.write(values, shape, dtype);\n\n    return {dataId: outId, shape, dtype};\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId: DataId): void {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType): void {\n    this.data.set(dataId, {values, dtype, refCount: 1});\n  }\n\n  numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensorInfos} = this.data.get(dataId);\n\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n\n    return this.data.get(dataId).values;\n  }\n\n  private bufferSync<R extends Rank>(t: Tensor<R>): TensorBuffer<R> {\n    const data = this.readSync(t.dataId);\n    let decodedData = data as DataValues;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = (data as Uint8Array[]).map(d => util.decodeString(d));\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return tf.buffer(t.shape, t.dtype, decodedData) as TensorBuffer<R>;\n  }\n\n  makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this) as T;\n  }\n\n  disposeData(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const {complexTensorInfos} = this.data.get(dataId);\n\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId);\n        this.disposeData(complexTensorInfos.imag.dataId);\n      }\n\n      this.data.delete(dataId);\n    }\n  }\n\n  disposeIntermediateTensorInfo(tensorInfo: TensorInfo): void {\n    const dataId = tensorInfo.dataId;\n\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n\n      tensorData.refCount--;\n\n      if (tensorData.refCount < 1) {\n        this.disposeData(dataId);\n      }\n    }\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  stridedSlice<T extends Tensor>(\n      x: T, begin: number[], end: number[], strides: number[]): T {\n    assertNotComplex(x, 'stridedSlice');\n\n    const outShape = slice_util.computeOutShape(begin, end, strides);\n\n    if (outShape.some(axis => axis === 0)) {\n      return tf.tensor([], outShape) as T;\n    }\n\n    const buffer = tf.buffer(outShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n    for (let i = 0; i < buffer.size; i++) {\n      const loc = buffer.indexToLoc(i);\n\n      const newLoc: number[] = new Array(loc.length);\n      for (let j = 0; j < newLoc.length; j++) {\n        newLoc[j] = loc[j] * strides[j] + begin[j];\n      }\n      buffer.set(xBuf.get(...newLoc), ...loc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  diag(x: Tensor): Tensor {\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const buffer = tf.buffer([x.size, x.size], x.dtype);\n    const vals = buffer.values;\n    for (let i = 0; i < xVals.length; i++) {\n      vals[i * x.size + i] = xVals[i];\n    }\n    return buffer.toTensor();\n  }\n\n  unstack(x: Tensor, axis: number): Tensor[] {\n    const num = x.shape[axis];\n    const outShape: number[] = new Array(x.rank - 1);\n    let outIndex = 0;\n    for (let i = 0; i < x.rank; i++) {\n      if (i !== axis) {\n        outShape[outIndex++] = x.shape[i];\n      }\n    }\n\n    const begin = new Array(x.rank).fill(0);\n    const size = x.shape.slice();\n    size[axis] = 1;\n    const res = new Array(num);\n    for (let i = 0; i < res.length; i++) {\n      begin[axis] = i;\n      res[i] = tf.slice(x, begin, size).reshape(outShape);\n    }\n    return res;\n  }\n\n  reverse<T extends Tensor>(x: T, axis: number[]): T {\n    assertNotComplex(x, 'reverse');\n\n    const buffer = tf.buffer(x.shape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < buffer.size; i++) {\n      const outLoc = buffer.indexToLoc(i);\n      const inLoc = outLoc.slice();\n      axis.forEach(ax => inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]);\n      buffer.set(xBuf.get(...inLoc), ...outLoc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  neg<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'neg');\n\n    // TODO(lina128): Use mul directly once neg is modularized.\n    return tf.mul(tf.scalar(-1), x);\n  }\n\n  addN<T extends Tensor>(tensors: T[]): T {\n    assertNotComplex(tensors, 'addN');\n\n    const vals = tensors.map(t => this.readSync(t.dataId) as TypedArray);\n    const result = tf.buffer(tensors[0].shape, tensors[0].dtype as 'float32');\n    const resultVals = result.values;\n    for (let i = 0; i < tensors.length; i++) {\n      const currVals = vals[i];\n      for (let j = 0; j < resultVals.length; j++) {\n        resultVals[j] += currVals[j];\n      }\n    }\n    return result.toTensor() as T;\n  }\n\n  softmax<T extends Tensor>(logits: T, dim: number): T {\n    const axes = util.parseAxisParam([dim], logits.shape);\n    // TODO(annxingyuan): Call maxImpl rather than op as part of softmax kernel\n    // modularization.\n    const maxLogit = max(logits, axes);\n    const expandedShape =\n        backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n\n    // TODO(lina128): Use sub directly once softmax is modularized.\n    const a = tf.sub(logits, maxLogit.reshape(expandedShape));\n    const b = tf.exp(a);\n    const sumExp = this.sum(b, axes).reshape(expandedShape);\n\n    // TODO(annxingyuan): Call divImpl rather than op as part of softmax\n    // kernel modularization.\n    return tf.div(b, sumExp);\n  }\n\n  pow<T extends Tensor>(a: T, b: Tensor): T {\n    assertNotComplex([a, b], 'pow');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.pow(aValue, bValue)) as\n        T;\n  }\n\n  batchMatMul(\n      a: Tensor3D, b: Tensor3D, transposeA: boolean,\n      transposeB: boolean): Tensor3D {\n    assertNotComplex([a, b], 'matMul');\n\n    const sharedDim = transposeA ? a.shape[1] : a.shape[2];\n    const leftDim = transposeA ? a.shape[2] : a.shape[1];\n    const rightDim = transposeB ? b.shape[1] : b.shape[2];\n    const batchDim = a.shape[0];\n\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n        [a.strides[0], 1, a.strides[1]] :\n        [a.strides[0], a.strides[1], 1];\n    const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n        [1, b.strides[1], b.strides[0]] :\n        [b.strides[1], 1, b.strides[0]];\n\n    const size = leftDim * rightDim;\n    const result = tf.buffer([batchDim, leftDim, rightDim], a.dtype);\n    const resVals = result.values as TypedArray;\n    const blockSize = this.blockSize;\n\n    for (let b = 0; b < batchDim; b++) {\n      for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n        for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n          for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n            // for when blockSize doesn't evenly divide the input\n            const iBlock = Math.min(i0 + blockSize, leftDim);\n            const jBlock = Math.min(j0 + blockSize, rightDim);\n            const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n            for (let i = i0; i < iBlock; i++) {\n              for (let j = j0; j < jBlock; j++) {\n                let sum = 0.0;\n\n                for (let k = k0; k < kBlock; k++) {\n                  sum += aValues[b * aBatch + i * aOuterStep + k * aInnerStep] *\n                      bValues[k * bInnerStep + j * bOuterStep + b * bBatch];\n                }\n                resVals[b * size + (i * rightDim + j)] += sum;\n              }\n            }\n          }\n        }\n      }\n    }\n    return result.toTensor() as Tensor3D;\n  }\n\n  fusedBatchMatMul(\n      {a, b, transposeA, transposeB, bias, activation, preluActivationWeights}:\n          backend_util.FusedBatchMatMulConfig): Tensor3D {\n    let result = this.batchMatMul(a, b, transposeA, transposeB);\n    if (bias) {\n      // TODO(lina128): Use add directly once fusedBatchMatMul is modularized.\n      result = tf.add(result, bias);\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor3D;\n    }\n\n    return result;\n  }\n\n  floorDiv(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'floorDiv');\n\n    const op = (a: number, b: number) => Math.floor(a / b);\n    const outputDtype = 'int32';\n    return this.broadcastedBinaryOp(a, b, outputDtype, op);\n  }\n\n  sum(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    backend_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let sum = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        sum += aVals[offset + j];\n      }\n      vals[i] = sum;\n    }\n    return result;\n  }\n\n  prod(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let prod = 1;\n      for (let j = 0; j < reduceSize; ++j) {\n        prod *= aVals[offset + j];\n      }\n      vals[i] = prod;\n    }\n    return result;\n  }\n\n  unsortedSegmentSum<T extends Tensor>(\n      x: T, segmentIds: Tensor1D, numSegments: number): Tensor {\n    assertNotComplex(x, 'unsortedSegmentSum');\n\n    const res = [];\n\n    // Reshape the segment id's so that they can be broadcast with\n    // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n    const numIters = x.rank - segmentIds.rank;\n    for (let i = 0; i < numIters; ++i) {\n      segmentIds = segmentIds.expandDims(i + 1);\n    }\n\n    for (let i = 0; i < numSegments; ++i) {\n      const segmentId = tf.scalar(i, 'int32');\n      const mask = tf.equal(segmentId, segmentIds).asType('float32');\n      const sum = mask.mul(x).sum(0);\n      res.push(sum);\n    }\n\n    return tf.stack(res);\n  }\n\n  argMin(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMin');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      let minIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n          minIndex = j;\n        }\n      }\n      vals[i] = minIndex;\n    }\n    return result;\n  }\n\n  argMax(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMax');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let max = aVals[offset];\n      let maxIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value > max) {\n          max = value;\n          maxIndex = j;\n        }\n      }\n      vals[i] = maxIndex;\n    }\n    return result;\n  }\n\n  cumsum(x: Tensor, axis: number, exclusive: boolean, reverse: boolean):\n      Tensor {\n    assertNotComplex(x, 'cumsum');\n\n    if (axis !== x.rank - 1) {\n      throw new Error(\n          `backend.cumsum in CPU expects an inner-most axis=${x.rank - 1} ` +\n          `but got axis=${axis}`);\n    }\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(x.shape, resultDtype);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    const finalDim = x.shape[x.rank - 1];\n    const indexAdjuster = reverse ?\n        (i: number, j: number) => i + finalDim - j - 1 :\n        (i: number, j: number) => i + j;\n    for (let i = 0; i < aVals.length; i += finalDim) {\n      for (let j = 0; j < finalDim; j++) {\n        const idx = indexAdjuster(i, j);\n        if (j === 0) {\n          vals[idx] = exclusive ? 0 : aVals[idx];\n        } else {\n          const prevIdx = indexAdjuster(i, j - 1);\n          vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                  aVals[idx] + vals[prevIdx];\n        }\n      }\n    }\n    return result;\n  }\n\n  equal(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'equal');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal === bVal) ? 1 : 0;\n    });\n  }\n\n  notEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'notEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal !== bVal) ? 1 : 0;\n    });\n  }\n\n  less(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'less');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal < bVal) ? 1 : 0;\n    });\n  }\n\n  lessEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'lessEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal <= bVal) ? 1 : 0;\n    });\n  }\n\n  greater(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greater');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal > bVal) ? 1 : 0;\n    });\n  }\n\n  greaterEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greaterEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal >= bVal) ? 1 : 0;\n    });\n  }\n\n  logicalAnd(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalAnd');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal && bVal;\n    });\n  }\n\n  logicalOr(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalOr');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal || bVal;\n    });\n  }\n\n  select(condition: Tensor, a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([condition, a, b], 'select');\n\n    const values = this.readSync(condition.dataId) as TypedArray;\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const result = tf.zeros(a.shape, upcastType(a.dtype, b.dtype));\n    const newValues = this.readSync(result.dataId) as TypedArray;\n    let index = 0;\n    const offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n        1 :\n        util.sizeFromShape(a.shape.slice(1));\n\n    for (let i = 0; i < values.length; i++) {\n      for (let j = 0; j < offset; j++) {\n        if (values[i] === 1) {\n          newValues[index++] = aValues[i];\n        } else {\n          newValues[index++] = bValues[i];\n        }\n      }\n    }\n\n    return result;\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  topk<T extends Tensor>(x: T, k: number, sorted: boolean): [T, T] {\n    assertNotComplex(x, 'topk');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    return topkImpl(xVals, x.shape, x.dtype as NumericDataType, k, sorted);\n  }\n\n  min(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'min');\n\n    backend_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n        }\n      }\n      vals[i] = min;\n    }\n    return result;\n  }\n\n  minimum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'minimum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.min(aVal, bVal));\n  }\n\n  mod(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'mod');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const rem = aVal % bVal;\n      if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n        return rem;\n      } else {\n        return (rem + bVal) % bVal;\n      }\n    });\n  }\n\n  maximum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'maximum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.max(aVal, bVal));\n  }\n\n  all(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'all');\n\n    backend_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let all = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        all = all && value;\n      }\n      vals[i] = all;\n    }\n    return result;\n  }\n\n  any(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'any');\n\n    backend_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let anyVal = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        anyVal = anyVal || value;\n      }\n      vals[i] = anyVal;\n    }\n    return result;\n  }\n\n  squaredDifference(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'squaredDifference');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const diff = aVal - bVal;\n      return diff * diff;\n    });\n  }\n\n  linear<T extends Tensor>(x: T): T {\n    return x;\n  }\n\n  relu<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'relu');\n\n    const res = tf.zeros(x.shape, x.dtype);\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const inVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.max(0, inVals[i]);\n    }\n    return res as T;\n  }\n\n  relu6<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'relu');\n\n    const res = tf.zeros(x.shape, x.dtype);\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const inVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < inVals.length; ++i) {\n      resVals[i] = Math.min(Math.max(0, inVals[i]), 6);\n    }\n    return res as T;\n  }\n\n  prelu<T extends Tensor>(x: T, a: T): T {\n    assertNotComplex([x, a], 'prelu');\n\n    return this.broadcastedBinaryOp(\n               x, a, x.dtype,\n               (xValue, aValue) => xValue < 0 ? aValue * xValue : xValue) as T;\n  }\n\n  eluDer<T extends Tensor>(dy: T, y: T): T {\n    assertNotComplex([dy, y], 'eluDer');\n\n    const resultValues = new Float32Array(y.size);\n    const values = this.readSync(y.dataId) as TypedArray;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 1) {\n        resultValues[i] = dyValues[i];\n      } else {\n        resultValues[i] = dyValues[i] * (v + 1);\n      }\n    }\n    return this.makeOutput(resultValues, y.shape, 'float32');\n  }\n\n  atan2<T extends Tensor>(a: T, b: T): T {\n    assertNotComplex([a, b], 'atan2');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.atan2(aValue, bValue)) as\n        T;\n  }\n\n  fusedConv2d(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          backend_util.FusedConv2DConfig): Tensor4D {\n    let result = this.conv2d(input, filter, convInfo);\n\n    if (bias) {\n      // TODO(lina128): Use add directly once fusedConv2d is modularized.\n      result = tf.add(result, bias);\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor4D;\n    }\n    return result;\n  }\n\n  conv2d(x: Tensor4D, filter: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([x, filter], 'conv2d');\n\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n    const y = tf.buffer(convInfo.outShape, x.dtype as 'float32');\n\n    const xBatchStride = x.strides[0];\n    const xRowStride = isChannelsLast ? x.strides[1] : x.strides[2];\n    const xColStride = isChannelsLast ? x.strides[2] : 1;\n    const xChannelStride = isChannelsLast ? 1 : x.strides[1];\n    const yBatchStride = y.strides[0];\n    const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n    const yColStride = isChannelsLast ? y.strides[2] : 1;\n    const yChannelStride = isChannelsLast ? 1 : y.strides[1];\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * xBatchStride;\n      const yOffset1 = b * yBatchStride;\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const yOffset2 = yOffset1 + yR * yRowStride;\n        const xRCorner = yR * convInfo.strideHeight - padTop;\n        for (let wR = 0; wR < filterHeight; wR++) {\n          const xR = xRCorner + wR * dilationHeight;\n          if (xR < 0 || xR >= convInfo.inHeight) {\n            continue;\n          }\n          const wOffset1 = wR * filter.strides[0];\n          const xOffset2 = xOffset1 + xR * xRowStride;\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const yOffset3 = yOffset2 + yC * yColStride;\n            const xCCorner = yC * convInfo.strideWidth - padLeft;\n            for (let wC = 0; wC < filterWidth; wC++) {\n              const xC = xCCorner + wC * dilationWidth;\n              if (xC < 0 || xC >= convInfo.inWidth) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wC * filter.strides[1];\n              const xOffset3 = xOffset2 + xC * xColStride;\n              let wOffset3 = wOffset2;\n              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                const xVal = xVals[xOffset3 + d1 * xChannelStride];\n                for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                  yVals[yOffset3 + d2 * yChannelStride] +=\n                      xVal * wVals[wOffset3 + d2];\n                }\n                wOffset3 += convInfo.outChannels;\n              }\n            }\n          }\n        }\n      }\n    }\n    return y.toTensor() as Tensor4D;\n  }\n\n  conv3d(x: Tensor5D, filter: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padFront = convInfo.padInfo.front;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const y = tf.buffer<Rank.R5>(convInfo.outShape, x.dtype as 'float32');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * x.strides[0];\n      const yOffset1 = b * y.strides[0];\n      for (let yF = 0; yF < convInfo.outDepth; ++yF) {\n        const yOffset2 = yOffset1 + yF * y.strides[1];\n        const xFCorner = yF * convInfo.strideDepth - padFront;\n        for (let wF = 0; wF < filterDepth; wF++) {\n          const xF = xFCorner + wF * dilationDepth;\n          if (xF < 0 || xF >= convInfo.inDepth) {\n            continue;\n          }\n          const wOffset1 = wF * filter.strides[0];\n          const xOffset2 = xOffset1 + xF * x.strides[1];\n\n          for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n            const yOffset3 = yOffset2 + yR * y.strides[2];\n            const xRCorner = yR * convInfo.strideHeight - padTop;\n            for (let wR = 0; wR < filterHeight; wR++) {\n              const xR = xRCorner + wR * dilationHeight;\n              if (xR < 0 || xR >= convInfo.inHeight) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wR * filter.strides[1];\n              const xOffset3 = xOffset2 + xR * x.strides[2];\n              for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n                const yOffset4 = yOffset3 + yC * convInfo.outChannels;\n                const xCCorner = yC * convInfo.strideWidth - padLeft;\n                for (let wC = 0; wC < filterWidth; wC++) {\n                  const xC = xCCorner + wC * dilationWidth;\n                  if (xC < 0 || xC >= convInfo.inWidth) {\n                    continue;\n                  }\n                  const wOffset3 = wOffset2 + wC * filter.strides[2];\n                  const xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                  let wOffset4 = wOffset3;\n                  for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    const xVal = xVals[xOffset4 + d1];\n                    for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                      yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                    }\n                    wOffset4 += convInfo.outChannels;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    return y.toTensor();\n  }\n\n  conv2dDerInput(\n      dy: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([dy, filter], 'conv2dDerInput');\n\n    const dx = tf.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {\n      batchSize,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inHeight,\n      inWidth,\n      outChannels,\n      outHeight,\n      outWidth,\n      strideHeight,\n      strideWidth,\n      dataFormat\n    } = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    const isChannelsLast = dataFormat === 'channelsLast';\n    const xBatchStride = dx.strides[0];\n    const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n    const xColStride = isChannelsLast ? dx.strides[2] : 1;\n    const xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n    const yBatchStride = dy.strides[0];\n    const yRowStride = isChannelsLast ? dy.strides[1] : dy.strides[2];\n    const yColStride = isChannelsLast ? dy.strides[2] : 1;\n    const yChannelStride = isChannelsLast ? 1 : dy.strides[1];\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset =\n                    yBatchStride * b + yRowStride * yR + yColStride * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n                for (let d2 = 0; d2 < outChannels; ++d2) {\n                  const pixel = dyValues[dyOffset + yChannelStride * d2];\n                  const weight = fltValues[fltOffset + d2];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            const dxOffset = xBatchStride * b + xRowStride * xR +\n                xColStride * xC + xChannelStride * d1;\n            dxValues[dxOffset] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv3dDerInput(\n      dy: Tensor5D, filter: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    const dx = tf.buffer<Rank.R5>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2, dxS3] = dx.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2, dyS3] = dy.strides;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2, fltS3] = filter.strides;\n    const {\n      batchSize,\n      filterDepth,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inDepth,\n      inHeight,\n      inWidth,\n      outChannels,\n      outDepth,\n      outHeight,\n      outWidth,\n      strideDepth,\n      strideHeight,\n      strideWidth\n    } = convInfo;\n    const frontPad = filterDepth - 1 - convInfo.padInfo.front;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        // Frames of depth\n        for (let xF = 0; xF < inDepth; ++xF) {\n          const xFCorner = xF - frontPad;\n          const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n          const yFMax =\n              Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n\n          // Rows as per standard 2d matrix notation\n          for (let xR = 0; xR < inHeight; ++xR) {\n            const xRCorner = xR - topPad;\n            const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n            const yRMax =\n                Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n            // Columns as per standard 2d matrix notation\n            for (let xC = 0; xC < inWidth; ++xC) {\n              const xCCorner = xC - leftPad;\n              const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n              const yCMax =\n                  Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n              let dotProd = 0;\n              for (let yF = xFMin; yF < yFMax; ++yF) {\n                const wF = yF * strideDepth - xFCorner;\n\n                for (let yR = xRMin; yR < yRMax; ++yR) {\n                  const wR = yR * strideHeight - xRCorner;\n\n                  for (let yC = xCMin; yC < yCMax; ++yC) {\n                    const wC = yC * strideWidth - xCCorner;\n                    const dyOffset =\n                        dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                    const fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                        fltS1 * (filterHeight - 1 - wR) +\n                        fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n\n                    for (let d2 = 0; d2 < outChannels; ++d2) {\n                      const pixel = dyValues[dyOffset + d2];\n                      const weight = fltValues[fltOffset + d2];\n                      dotProd += pixel * weight;\n                    }\n                  }\n                }\n              }\n              dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                  dotProd;\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  conv2dDerFilter(x: Tensor4D, dy: Tensor4D, convInfo: backend_util.Conv2DInfo):\n      Tensor4D {\n    assertNotComplex([x, dy], 'conv2dDerFilter');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    const dW = tf.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n    const xBuf = this.bufferSync(x);\n    const dyBuf = this.bufferSync(dy);\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            // Need to convolve.\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              for (let yR = yRMin; yR < yRMax; ++yR) {\n                const xR = wR + yR * strideHeight - topPad;\n                for (let yC = yCMin; yC < yCMax; ++yC) {\n                  const xC = wC + yC * strideWidth - leftPad;\n                  if (isChannelsLast) {\n                    dotProd +=\n                        xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n                  } else {\n                    dotProd +=\n                        xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);\n                  }\n                }\n              }\n            }\n            dW.set(dotProd, wR, wC, d1, d2);\n          }\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  conv3dDerFilter(x: Tensor5D, dy: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n\n    const dw = tf.buffer<Rank.R5>(convInfo.filterShape, 'float32');\n    const dwValues = dw.values;\n    const [dwS0, dwS1, dwS2, dwS3] = dw.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2, dyS3] = dy.strides;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const [xS0, xS1, xS2, xS3] = x.strides;\n\n    const frontPad = convInfo.padInfo.front;\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n\n    for (let wF = 0; wF < filterDepth; ++wF) {\n      const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n      const yFMax = Math.min(\n          convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n      const wOffset1 = wF * dwS0;\n\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n        const yRMax = Math.min(\n            convInfo.outHeight,\n            (convInfo.inHeight + topPad - wR) / strideHeight);\n        const wOffset2 = wR * dwS1 + wOffset1;\n\n        for (let wC = 0; wC < filterWidth; ++wC) {\n          const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n          const yCMax = Math.min(\n              convInfo.outWidth,\n              (convInfo.inWidth + leftPad - wC) / strideWidth);\n          const wOffset3 = wC * dwS2 + wOffset2;\n\n          for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n            const wOffset4 = d1 * dwS3 + wOffset3;\n\n            for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n              let dotProd = 0;\n              for (let b = 0; b < convInfo.batchSize; ++b) {\n                const xOffset1 = b * xS0;\n                const yOffset1 = b * dyS0;\n\n                for (let yF = yFMin; yF < yFMax; ++yF) {\n                  const xF = wF + yF * strideDepth - frontPad;\n                  const xOffset2 = xF * xS1 + xOffset1;\n                  const yOffset2 = yF * dyS1 + yOffset1;\n\n                  for (let yR = yRMin; yR < yRMax; ++yR) {\n                    const xR = wR + yR * strideHeight - topPad;\n                    const xOffset3 = xR * xS2 + xOffset2;\n                    const yOffset3 = yR * dyS2 + yOffset2;\n\n                    for (let yC = yCMin; yC < yCMax; ++yC) {\n                      const xC = wC + yC * strideWidth - leftPad;\n                      const xOffset4 = xC * xS3 + xOffset3;\n                      const yOffset4 = yC * dyS3 + yOffset3;\n\n                      dotProd +=\n                          xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                    }\n                  }\n                }\n              }\n              dwValues[wOffset4 + d2] = dotProd;\n            }\n          }\n        }\n      }\n    }\n    return dw.toTensor();\n  }\n\n  fusedDepthwiseConv2D(\n      {input, filter, convInfo, bias, activation, preluActivationWeights}:\n          backend_util.FusedConv2DConfig): Tensor4D {\n    let result = this.depthwiseConv2D(input, filter, convInfo);\n\n    if (bias) {\n      // TODO(lina128): Use add directly once fusedDepthwiseConv2D is\n      // modularized.\n      result = tf.add(result, bias);\n    }\n    if (activation) {\n      result =\n          mapActivation(this, result, activation, preluActivationWeights) as\n          Tensor4D;\n    }\n    return result;\n  }\n\n  depthwiseConv2D(\n      x: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, filter], 'depthwiseConv2D');\n\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const padLeft = convInfo.padInfo.left;\n    const padTop = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n    const y = tf.buffer(convInfo.outShape, x.dtype as 'float32');\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const wVals = this.readSync(filter.dataId) as TypedArray;\n    const yVals = y.values;\n\n    for (let b = 0; b < convInfo.batchSize; ++b) {\n      const xOffset1 = b * x.strides[0];\n      const yOffset1 = b * y.strides[0];\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const yOffset2 = yOffset1 + yR * y.strides[1];\n        const xRCorner = yR * convInfo.strideHeight - padLeft;\n        for (let wR = 0; wR < filterHeight; ++wR) {\n          const xR = xRCorner + wR * dilationHeight;\n          if (xR < 0 || xR >= convInfo.inHeight) {\n            continue;\n          }\n          const wOffset1 = wR * filter.strides[0];\n          const xOffset2 = xOffset1 + xR * x.strides[1];\n          for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n            const yOffset3 = yOffset2 + yC * y.strides[2];\n            const xCCorner = yC * convInfo.strideWidth - padTop;\n            for (let wC = 0; wC < filterWidth; ++wC) {\n              const xC = xCCorner + wC * dilationWidth;\n              if (xC < 0 || xC >= convInfo.inWidth) {\n                continue;\n              }\n              const wOffset2 = wOffset1 + wC * filter.strides[1];\n              const xOffset3 = xOffset2 + xC * convInfo.inChannels;\n              let yOffset4 = yOffset3;\n              let wOffset3 = wOffset2;\n              for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                const xVal = xVals[xOffset3 + d1];\n                for (let q = 0; q < chMul; ++q) {\n                  yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n                }\n                yOffset4 += chMul;\n                wOffset3 += chMul;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    return y.toTensor() as Tensor4D;\n  }\n\n  depthwiseConv2DDerInput(\n      dy: Tensor4D, filter: Tensor4D,\n      convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([dy, filter], 'depthwiseConv2DDerInput');\n\n    const dx = tf.buffer<Rank.R4>(convInfo.inShape, 'float32');\n    const dxValues = dx.values;\n    const [dxS0, dxS1, dxS2] = dx.strides;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const [dyS0, dyS1, dyS2] = dy.strides;\n    const fltValues = this.readSync(filter.dataId) as TypedArray;\n    const [fltS0, fltS1, fltS2] = filter.strides;\n    const {\n      batchSize,\n      filterHeight,\n      filterWidth,\n      inChannels,\n      inHeight,\n      inWidth,\n      outChannels,\n      outHeight,\n      outWidth,\n      strideHeight,\n      strideWidth\n    } = convInfo;\n    const topPad = filterHeight - 1 - convInfo.padInfo.top;\n    const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n    const chMul = outChannels / inChannels;\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let d1 = 0; d1 < inChannels; ++d1) {\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yR = xRMin; yR < yRMax; ++yR) {\n              const wR = yR * strideHeight - xRCorner;\n\n              for (let yC = xCMin; yC < yCMax; ++yC) {\n                const wC = yC * strideWidth - xCCorner;\n                const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n                for (let dm = 0; dm < chMul; ++dm) {\n                  const d2 = d1 * chMul + dm;\n                  const pixel = dyValues[dyOffset + d2];\n                  const weight = fltValues[fltOffset + dm];\n                  dotProd += pixel * weight;\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  depthwiseConv2DDerFilter(\n      x: Tensor4D, dy: Tensor4D, convInfo: backend_util.Conv2DInfo): Tensor4D {\n    assertNotComplex([x, dy], 'depthwiseConv2DDerFilter');\n\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dW = tf.buffer<Rank.R4>(convInfo.filterShape, 'float32');\n\n    const leftPad = convInfo.padInfo.left;\n    const topPad = convInfo.padInfo.top;\n    const chMul = convInfo.outChannels / convInfo.inChannels;\n\n    const xBuf = this.bufferSync(x);\n    const dyBuf = this.bufferSync(dy);\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n          const d1 = Math.trunc(d2 / chMul);\n          const dm = d2 % chMul;\n\n          let dotProd = 0;\n          for (let b = 0; b < convInfo.batchSize; ++b) {\n            for (let yR = yRMin; yR < yRMax; ++yR) {\n              const xR = wR + yR * strideHeight - topPad;\n              for (let yC = yCMin; yC < yCMax; ++yC) {\n                const xC = wC + yC * strideWidth - leftPad;\n                dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n              }\n            }\n          }\n          dW.set(dotProd, wR, wC, d1, dm);\n        }\n      }\n    }\n    return dW.toTensor();\n  }\n\n  tile<T extends Tensor>(x: T, reps: number[]): T {\n    assertNotComplex(x, 'tile');\n    return tile(this.bufferSync(x), reps) as T;\n  }\n\n  gather<T extends Tensor>(x: T, indices: Tensor1D, axis: number): T {\n    assertNotComplex([x, indices], 'gather');\n\n    const newShape: number[] = x.shape.slice();\n    const indicesValues = this.readSync(indices.dataId) as TypedArray;\n    newShape[axis] = indicesValues.length;\n    const result = tf.buffer(newShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < result.size; ++i) {\n      const newLoc = result.indexToLoc(i);\n\n      const originalLoc: number[] = newLoc.slice();\n      originalLoc[axis] = indicesValues[newLoc[axis]];\n\n      const originalIndex = xBuf.locToIndex(originalLoc);\n      result.values[i] = xBuf.values[originalIndex];\n    }\n    return result.toTensor() as T;\n  }\n\n  batchToSpaceND<T extends Tensor>(\n      x: T, blockShape: number[], crops: number[][]): T {\n    assertNotComplex([x], 'batchToSpaceND');\n\n    const prod = blockShape.reduce((a, b) => a * b);\n\n    const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n    const permuted =\n        backend_util.getPermuted(reshaped.length, blockShape.length);\n    const reshapedPermuted =\n        backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n    const sliceBeginCoords =\n        backend_util.getSliceBeginCoords(crops, blockShape.length);\n    const sliceSize =\n        backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n    return tf.transpose(x.reshape(reshaped), permuted)\n               .reshape(reshapedPermuted)\n               .slice(sliceBeginCoords, sliceSize) as T;\n  }\n\n  private pool3d(\n      x: Tensor5D, convInfo: backend_util.Conv3DInfo,\n      poolType: 'max'|'avg'): Tensor5D {\n    assertNotComplex(x, 'pool3d');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const initialValue =\n        (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                              Number.POSITIVE_INFINITY);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = tf.buffer(convInfo.outShape, x.dtype);\n    const outputVals = output.values;\n\n    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n        convInfo.outShape[3] * convInfo.outShape[4];\n    const outputDepthStrides =\n        convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n    const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n    const outputColStrides = convInfo.outShape[4];\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      const outputBatchOffset = batch * outputBatchStrides;\n      const inputBatchOffset = batch * x.strides[0];\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          const outputDepthOffset =\n              outputBatchOffset + yDepth * outputDepthStrides;\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n              // Shader code begins\n              const outputColOffset = outputRowOffset + yCol * outputColStrides;\n              let minMaxValue = initialValue;\n              let avgValue = 0;\n              let count = 0;\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const xDepthOffset = inputBatchOffset + xDepth * x.strides[1];\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const xRowOffset = xDepthOffset + xRow * x.strides[2];\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const xColOffset = xRowOffset + xCol * x.strides[3];\n                    const pixel = xValues[xColOffset + channel];\n                    if ((poolType === 'max' && pixel > minMaxValue)) {\n                      minMaxValue = pixel;\n                    } else if (poolType === 'avg') {\n                      avgValue += pixel;\n                      count++;\n                    }\n                    if (isNaN(minMaxValue)) {\n                      break;\n                    }\n                  }\n                  if (isNaN(minMaxValue)) {\n                    break;\n                  }\n                }\n                if (isNaN(minMaxValue)) {\n                  break;\n                }\n              }\n              const outputOffset = outputColOffset + channel;\n              outputVals[outputOffset] =\n                  poolType === 'avg' ? avgValue / count : minMaxValue;\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor5D;\n  }\n\n  avgPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'avgPool3d');\n\n    return this.pool3d(x, convInfo, 'avg').toFloat();\n  }\n\n  avgPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([dy, x], 'avgPool3dBackprop');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins.\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel;\n                  }\n                }\n              }\n              dx.set(\n                  dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol,\n                  channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  maxPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'maxPool3d');\n\n    return this.pool3d(x, convInfo, 'max').toFloat();\n  }\n\n  private maxPool3dPositions(x: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const maxPositions = tf.buffer(convInfo.outShape, 'int32');\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const xBuf = this.bufferSync(x);\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n\n              // Shader code begins\n              let maxValue = Number.NEGATIVE_INFINITY;\n              let maxPosition = -1;\n\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const wDepth = xDepth - xDepthCorner;\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const wRow = xRow - xRowCorner;\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const wCol = xCol - xColCorner;\n                    const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                    if (pixel >= maxValue) {\n                      maxValue = pixel;\n                      maxPosition = wDepth * effectiveFilterHeight *\n                              effectiveFilterWidth +\n                          wRow * effectiveFilterHeight + wCol;\n                    }\n                  }\n                }\n              }\n\n              maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return maxPositions.toTensor() as Tensor5D;\n  }\n\n  maxPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, y: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([x, y], 'maxPool3dBackprop');\n\n    const maxPositions = this.maxPool3dPositions(x, convInfo);\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const maxPosBuf = this.bufferSync(maxPositions);\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const maxPos = effectiveFilterDepth *\n                            effectiveFilterHeight * effectiveFilterWidth -\n                        1 -\n                        maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    const curPos =\n                        wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                        wRow * effectiveFilterWidth + wCol;\n\n                    const mask = maxPos === curPos ? 1 : 0;\n                    if (mask === 0) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel * mask;\n                  }\n                }\n              }\n              dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  resizeBilinear(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeBilinear');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result = new Float32Array(\n        util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n    let outputIdx = 0;\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n    for (let b = 0; b < batch; b++) {\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceRowFloor = Math.floor(sourceFracRow);\n        const rowFrac = sourceFracRow - sourceRowFloor;\n        const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n        const topRowOffset = b * x.strides[0] + sourceRowFloor * x.strides[1];\n        const botRowOffset = b * x.strides[0] + sourceRowCeil * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceColFloor = Math.floor(sourceFracCol);\n          const colFrac = sourceFracCol - sourceColFloor;\n          const sourceColCeil =\n              Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n          const topLeftOffest = topRowOffset + sourceColFloor * x.strides[2];\n          const botLeftOffset = botRowOffset + sourceColFloor * x.strides[2];\n          const topRightOffset = topRowOffset + sourceColCeil * x.strides[2];\n          const botRightOffest = botRowOffset + sourceColCeil * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n\n            // Compute the fractional index of the source.\n            const topLeft = xValues[topLeftOffest + d];\n            const bottomLeft = xValues[botLeftOffset + d];\n            const topRight = xValues[topRightOffset + d];\n            const bottomRight = xValues[botRightOffest + d];\n\n            const top = topLeft + (topRight - topLeft) * colFrac;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n            const newValue = top + (bottom - top) * rowFrac;\n\n            result[outputIdx++] = newValue;\n          }\n        }\n      }\n    }\n    return tf.tensor(result, [batch, newHeight, newWidth, numChannels]);\n  }\n\n  resizeBilinearBackprop(dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeBilinearBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass and add the\n    // corresponding coefficient from dy to the gradient (with some\n    // interpolation).\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    let offset = 0;\n    for (let b = 0; b < batch; b++) {\n      const bOffset = b * x.strides[0];\n      for (let r = 0; r < yHeight; r++) {\n        const dxR = r * heightScale;\n        const topDxRIndex = Math.floor(dxR);\n        const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n\n        const topDxROffset = bOffset + topDxRIndex * x.strides[1];\n        const bottomDxROffset = bOffset + bottomDxRIndex * x.strides[1];\n\n        const dxRLerp = dxR - topDxRIndex;\n        const inverseDxRLerp = 1.0 - dxRLerp;\n        for (let c = 0; c < yWidth; c++) {\n          const dxC = c * widthScale;\n          const leftDxCIndex = Math.floor(dxC);\n          const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n          const dxCLerp = dxC - leftDxCIndex;\n          const inverseDxCLerp = 1.0 - dxCLerp;\n\n          const topLeftRCOffset = topDxROffset + leftDxCIndex * x.strides[2];\n          const topRightRCOffset = topDxROffset + rightDxCIndex * x.strides[2];\n          const bottomLeftRCOffset =\n              bottomDxROffset + leftDxCIndex * x.strides[2];\n          const bottomRightRCOffset =\n              bottomDxROffset + rightDxCIndex * x.strides[2];\n\n          const inverseDxRLerpTimesInverseDxCLerp =\n              inverseDxRLerp * inverseDxCLerp;\n          const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n          const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n          const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n          for (let d = 0; d < depth; d++) {\n            const dyVal = dyValues[offset++];\n            output[topLeftRCOffset + d] +=\n                dyVal * inverseDxRLerpTimesInverseDxCLerp;\n            output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n            output[bottomLeftRCOffset + d] +=\n                dyVal * dxRLerpTimesInverseDxCLerp;\n            output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, [batch, xWidth, xHeight, depth], x.dtype);\n  }\n\n  resizeNearestNeighbor(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeNearestNeighbor');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = new Float32Array(batch * newHeight * newWidth * numChannels);\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n\n    let outputOffset = 0;\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceNearestRow = Math.min(\n            oldHeight - 1,\n            alignCorners ? Math.round(sourceFracRow) :\n                           Math.floor(sourceFracRow));\n        const rowOffset = batchOffset + sourceNearestRow * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceNearestCol = Math.min(\n              oldWidth - 1,\n              alignCorners ? Math.round(sourceFracCol) :\n                             Math.floor(sourceFracCol));\n          const colOffset = rowOffset + sourceNearestCol * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n            // Compute the fractional index of the source.\n            const newVal = xValues[colOffset + d];\n            output[outputOffset++] = newVal;\n          }\n        }\n      }\n    }\n    return tf.tensor(\n        output, [batch, newHeight, newWidth, numChannels], x.dtype);\n  }\n\n  resizeNearestNeighborBackprop(\n      dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeNearestNeighborBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    const invHeightScale = 1 / heightScale;\n    const invWidthScale = 1 / widthScale;\n\n    // This defines the size of the window of values around a particular\n    // index in dy that we want to search for contributions to dx.\n    const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n    const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n    // Loop over the output space.\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < xHeight; r++) {\n        const rowOffset = batchOffset + r * x.strides[1];\n\n        // Compute bounds for where in dy we will look\n        const startRLerp = Math.floor(r * invHeightScale);\n        const startDyR = Math.floor(startRLerp - (winHeight / 2));\n        for (let c = 0; c < xWidth; c++) {\n          const colOffset = rowOffset + c * x.strides[2];\n\n          // Compute bounds for where in dy we will look\n          const startCLerp = Math.floor(c * invWidthScale);\n          const startDyC = Math.floor(startCLerp - (winWidth / 2));\n\n          for (let d = 0; d < depth; d++) {\n            let accum = 0;\n            // loop over dy\n\n            for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n              const dyR = dyRIndex + startDyR;\n              // Guard against the window exceeding the bounds of dy\n              if (dyR < 0 || dyR >= yHeight) {\n                continue;\n              }\n\n              const dyROffset = batchOffset + dyR * dy.strides[1];\n              const sourceFracRow = dyR * heightScale;\n              const sourceNearestRow = Math.min(\n                  xHeight - 1,\n                  alignCorners ? Math.round(sourceFracRow) :\n                                 Math.floor(sourceFracRow));\n              if (r !== sourceNearestRow) {\n                continue;\n              }\n              for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n                const dyC = dyCIndex + startDyC;\n                // Guard against the window exceeding the bounds of dy\n                if (dyC < 0 || dyC >= yWidth) {\n                  continue;\n                }\n\n                const dyCOffset = dyROffset + dyC * dy.strides[2];\n                const sourceFracCol = dyC * widthScale;\n                const sourceNearestCol = Math.min(\n                    xWidth - 1,\n                    alignCorners ? Math.round(sourceFracCol) :\n                                   Math.floor(sourceFracCol));\n\n                if (c === sourceNearestCol) {\n                  accum += dyValues[dyCOffset + d];\n                }\n              }\n            }\n            output[colOffset + d] = accum;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, x.shape, x.dtype);\n  }\n\n  localResponseNormalization4D(\n      x: Tensor4D, depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(x, 'localResponseNormalization4D');\n\n    const channels = x.shape[3];\n    const maxD = channels - 1;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const size = x.size;\n    const result = new Float32Array(size);\n\n    function sumAcrossChannels(offset: number) {\n      const currentChannel = offset % channels;\n      let beginSumOffset =\n          offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n      const endSumOffset = offset - currentChannel +\n          Math.min(currentChannel + depthRadius, maxD);\n\n      let sum = 0.0;\n      for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n        const z = xValues[beginSumOffset];\n        sum += z * z;\n      }\n      return sum;\n    }\n\n    for (let offset = 0; offset < size; offset++) {\n      const sum = sumAcrossChannels(offset);\n      const val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n      result[offset] = val;\n    }\n\n    return tf.tensor4d(result, x.shape);\n  }\n\n  LRNGrad(\n      dy: Tensor4D, inputImage: Tensor4D, outputImage: Tensor4D,\n      depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(dy, 'LRNGrad');\n    const channels = dy.shape[3];\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const inputImageValues = this.readSync(inputImage.dataId) as TypedArray;\n    const outputImageValues = this.readSync(outputImage.dataId) as TypedArray;\n    const result = new Float32Array(dy.size);\n    const size = dy.size;\n\n    for (let offset = 0; offset < size; offset++) {\n      const currentChannel = offset % channels;\n      const depthBegin =\n          (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n      const depthEnd = (offset - currentChannel) +\n          Math.min(channels, currentChannel + depthRadius + 1);\n\n      let norm = 0;\n      for (let k = depthBegin; k < depthEnd; k++) {\n        norm += Math.pow(inputImageValues[k], 2);\n      }\n      norm = alpha * norm + bias;\n\n      for (let k = depthBegin; k < depthEnd; k++) {\n        let dyi = -2 * alpha * beta * inputImageValues[k] *\n            outputImageValues[offset] / norm;\n        if (offset === k) {\n          dyi += Math.pow(norm, -beta);\n        }\n        dyi *= dyValues[offset];\n        result[k] += dyi;\n      }\n    }\n    return tf.tensor4d(result, dy.shape);\n  }\n\n  multinomial(\n      logits: Tensor2D, normalized: boolean, numSamples: number,\n      seed: number): Tensor2D {\n    assertNotComplex(logits, 'multinomial');\n\n    const probabilities = normalized ? logits : tf.softmax(logits);\n    const batchSize = probabilities.shape[0];\n    const numEvents = probabilities.shape[1];\n    const res = tf.zeros<Rank.R2>([batchSize, numSamples], 'int32');\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const probVals = this.readSync(probabilities.dataId) as TypedArray;\n\n    for (let b = 0; b < batchSize; ++b) {\n      const offset = b * numEvents;\n      // The cdf won't include the last event. It will be implicit if no other\n      // event happened.\n      const cdf = new Float32Array(numEvents - 1);\n      cdf[0] = probVals[offset];\n      for (let event = 1; event < cdf.length; ++event) {\n        cdf[event] = cdf[event - 1] + probVals[offset + event];\n      }\n\n      const random = seedrandom.alea(seed.toString());\n      const outOffset = b * numSamples;\n      for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n        const r = random();\n\n        // Assume last event happened by default.\n        resVals[outOffset + sampleId] = cdf.length;\n\n        for (let event = 0; event < cdf.length; event++) {\n          if (r < cdf[event]) {\n            resVals[outOffset + sampleId] = event;\n            break;\n          }\n        }\n      }\n    }\n    return res;\n  }\n\n  oneHot(indices: Tensor1D, depth: number, onValue: number, offValue: number):\n      Tensor2D {\n    assertNotComplex(indices, 'oneHot');\n\n    const res = new Float32Array(indices.size * depth);\n    res.fill(offValue);\n    const indicesVal = this.readSync(indices.dataId) as TypedArray;\n\n    for (let event = 0; event < indices.size; ++event) {\n      if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n        res[event * depth + indicesVal[event]] = onValue;\n      }\n    }\n    return tf.tensor2d(res, [indices.size, depth], 'int32');\n  }\n\n  nonMaxSuppression(\n      boxes: Tensor2D, scores: Tensor1D, maxOutputSize: number,\n      iouThreshold: number, scoreThreshold: number): Tensor1D {\n    assertNotComplex(boxes, 'nonMaxSuppression');\n\n    const boxesVals = this.readSync(boxes.dataId) as TypedArray;\n    const scoresVals = this.readSync(scores.dataId) as TypedArray;\n    return nonMaxSuppressionV3Impl(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n  }\n\n  depthToSpace(x: Tensor4D, blockSize: number, dataFormat: 'NHWC'|'NCHW'):\n      Tensor4D {\n    util.assert(\n        dataFormat === 'NHWC',\n        () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${\n            dataFormat}`);\n    util.assert(\n        blockSize > 1,\n        () =>\n            `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);\n\n    const batchSize = x.shape[0];\n    const inputHeight = x.shape[1];\n    const inputWidth = x.shape[2];\n    const inputDepth = x.shape[3];\n\n    const outputHeight = inputHeight * blockSize;\n    const outputWidth = inputWidth * blockSize;\n    const outputDepth = inputDepth / (blockSize * blockSize);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result =\n        new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n\n    let outputIdx = 0;\n    for (let b = 0; b < batchSize; ++b) {\n      for (let h = 0; h < outputHeight; ++h) {\n        const inH = Math.floor(h / blockSize);\n        const offsetH = (h % blockSize);\n        for (let w = 0; w < outputWidth; ++w) {\n          const inW = Math.floor(w / blockSize);\n          const offsetW = (w % blockSize);\n          const offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n          for (let d = 0; d < outputDepth; ++d) {\n            const inD = d + offsetD;\n            const inputIdx =\n                inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n            result[outputIdx++] = xValues[inputIdx];\n          }\n        }\n      }\n    }\n    return tf.tensor4d(\n        result, [batchSize, outputHeight, outputWidth, outputDepth]);\n  }\n\n  private broadcastedBinaryOp(\n      a: Tensor, b: Tensor, dtype: DataType,\n      op: (a: number, b: number) => number): Tensor {\n    const newShape = backend_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const result = tf.buffer(newShape, dtype);\n    const aVals = this.readSync(a.dataId) as TypedArray;\n    const bVals = this.readSync(b.dataId) as TypedArray;\n    const aBroadcastDims = backend_util.getBroadcastDims(a.shape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(b.shape, newShape);\n\n    const resVals = result.values;\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resVals.length; ++i) {\n        resVals[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      const aBuf = this.bufferSync(a);\n      const bBuf = this.bufferSync(b);\n      for (let i = 0; i < resVals.length; ++i) {\n        const loc = result.indexToLoc(i);\n\n        const aLoc = loc.slice(-a.rank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = aBuf.locToIndex(aLoc);\n\n        const bLoc = loc.slice(-b.rank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = bBuf.locToIndex(bLoc);\n\n        resVals[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n    return result.toTensor();\n  }\n\n  split<T extends Tensor>(x: T, sizeSplits: number[], axis: number): T[] {\n    return split(x, sizeSplits, axis);\n  }\n\n  dispose() {}\n\n  floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return super.epsilon();\n  }\n\n  cropAndResize(\n      images: Tensor4D,\n      boxes: Tensor2D,\n      boxIndex: Tensor1D,\n      cropSize: [number, number],\n      method: string,\n      extrapolationValue: number,\n  ) {\n    const [batch, imageHeight, imageWidth, numChannels] = images.shape;\n    const numBoxes = boxes.shape[0];\n\n    const [cropHeight, cropWidth] = cropSize;\n    const output =\n        tf.buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n\n    const boxVals = this.readSync(boxes.dataId) as TypedArray;\n    const boxIndVals = this.readSync(boxIndex.dataId) as TypedArray;\n    const imageVals = this.readSync(images.dataId) as TypedArray;\n\n    const inStride = images.strides;   // to calculate flat indexes into image\n    const outStride = output.strides;  // to calculate flat indexes into output\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n    for (let b = 0; b < numBoxes; b++) {\n      const startInd = b * 4;\n      const y1 = boxVals[startInd];\n      const x1 = boxVals[startInd + 1];\n      const y2 = boxVals[startInd + 2];\n      const x2 = boxVals[startInd + 3];\n\n      const bInd: number = boxIndVals[b];\n      if (bInd >= batch) {\n        continue;\n      }\n\n      const heightScale = (cropHeight > 1) ?\n          (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) :\n          0;\n      const widthScale =\n          (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n\n      for (let y = 0; y < cropHeight; y++) {\n        const yInd: number = (cropHeight > 1) ?\n            y1 * (imageHeight - 1) + y * (heightScale) :\n            0.5 * (y1 + y2) * (imageHeight - 1);\n\n        if (yInd < 0 || yInd > imageHeight - 1) {\n          for (let x = 0; x < cropWidth; x++) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n          }\n          continue;\n        }\n\n        if (method === 'bilinear') {\n          const topInd = Math.floor(yInd);\n          const bottomInd = Math.ceil(yInd);\n          const yLerp = yInd - topInd;\n\n          for (let x = 0; x < cropWidth; x++) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const leftInd = Math.floor(xInd);\n            const rightInd = Math.ceil(xInd);\n            const xLerp = xInd - leftInd;\n\n            for (let c = 0; c < numChannels; c++) {\n              let ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topRight = imageVals[ind];\n\n              ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomRight = imageVals[ind];\n\n              const top = topLeft + (topRight - topLeft) * xLerp;\n              const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n\n              ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = top + ((bottom - top) * yLerp);\n            }\n          }\n        } else {  // method == \"nearest\"\n          for (let x = 0; x < cropWidth; ++x) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const closestX = Math.round(xInd);\n            const closestY = Math.round(yInd);\n            for (let c = 0; c < numChannels; c++) {\n              const inInd = c + closestX * inStride[2] +\n                  closestY * inStride[1] + bInd * inStride[0];\n              const outInd =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[outInd] = imageVals[inInd];\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor4D;\n  }\n\n  sparseToDense<R extends Rank>(\n      sparseIndices: Tensor, sparseValues: Tensor, outputShape: ShapeMap[R],\n      defaultValue: Scalar): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n    const sumDupeIndices = false;\n    return this.scatter(\n        sparseIndices, sparseValues, outputShape, outputSize, sliceSize,\n        numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n  }\n\n  gatherND(x: Tensor, indices: Tensor): Tensor {\n    const indicesShape = indices.shape;\n    const sliceRank = indicesShape[indicesShape.length - 1];\n\n    const [resultShape, numSlices, sliceSize, strides] =\n        backend_util.prepareAndValidate(x, indices);\n    if (numSlices === 0) {\n      return tf.tensor([], resultShape, x.dtype);\n    }\n\n    const buffer = new TensorBuffer([numSlices, sliceSize], x.dtype);\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const xData = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < numSlices; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        flattenIndex += dim * strides[j];\n        index.push(dim);\n      }\n      if (flattenIndex < 0 || flattenIndex >= x.size / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${x.shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        buffer.values[i * sliceSize + k] = xData[flattenIndex * sliceSize + k];\n      }\n    }\n    return buffer.toTensor().reshape(resultShape);\n  }\n\n  scatterND<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R]): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(updates, indices, shape);\n    const defaultValue = tf.scalar(0);\n    const sumDupeIndices = true;\n    return this.scatter(\n        indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank,\n        strides, defaultValue, sumDupeIndices);\n  }\n\n  fill<R extends Rank>(\n      shape: ShapeMap[R], value: number|string, dtype?: DataType): Tensor<R> {\n    dtype = dtype || util.inferDtype(value);\n    const values =\n        util.getArrayFromDType(dtype, util.sizeFromShape(shape)) as TypedArray;\n    values.fill(value as number);\n    return engine().makeTensor(values, shape, dtype, this) as Tensor<R>;\n  }\n\n  onesLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    if (x.dtype === 'string') {\n      throw new Error('onesLike is not supported for string tensors');\n    } else {\n      return this.fill(x.shape, 1, x.dtype);\n    }\n  }\n\n  zerosLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    const values = util.getArrayFromDType(\n                       x.dtype, util.sizeFromShape(x.shape)) as TypedArray;\n    return this.makeOutput(values, x.shape, x.dtype);\n  }\n\n  linspace(start: number, stop: number, num: number): Tensor1D {\n    return backend_util.linspaceImpl(start, stop, num);\n  }\n\n  private scatter<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R], outputSize: number,\n      sliceSize: number, numUpdates: number, sliceRank: number,\n      strides: number[], defaultValue: Scalar,\n      sumDupeIndices: boolean): Tensor<R> {\n    const flattenShape = [outputSize / sliceSize, sliceSize];\n\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const updatesData = this.readSync(updates.dataId) as TypedArray;\n\n    if (outputSize === 0) {\n      return tf.tensor([], shape, updates.dtype);\n    }\n\n    const buffer = new TensorBuffer(flattenShape, updates.dtype as 'float32');\n    buffer.values.fill((this.readSync(defaultValue.dataId) as TypedArray)[0]);\n\n    for (let i = 0; i < numUpdates; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        index.push(dim);\n        flattenIndex += dim * strides[j];\n      }\n\n      if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        if (sumDupeIndices) {\n          buffer.values[flattenIndex * sliceSize + k] +=\n              updatesData[i * sliceSize + k];\n        } else {\n          buffer.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n              updatesData[0] :\n              updatesData[i * sliceSize + k];\n        }\n      }\n    }\n    return buffer.toTensor().reshape(shape);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, AbsInputs, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function simpleAbsImpl(vals: TypedArray): Float32Array {\n  const resultValues = new Float32Array(vals.length);\n  for (let i = 0; i < vals.length; ++i) {\n    resultValues[i] = Math.abs(vals[i]);\n  }\n  return resultValues;\n}\n\nexport const absKernelFunc =\n    (args: {inputs: AbsInputs, backend: MathBackendCPU}) => {\n      const {x} = args.inputs;\n      const cpuBackend = args.backend;\n      let resultValues = new Float32Array(util.sizeFromShape(x.shape));\n      if (x.dtype !== 'complex64') {\n        const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n        resultValues = simpleAbsImpl(values);\n      } else {\n        const complexVals = cpuBackend.data.get(x.dataId);\n        const real = complexVals.complexTensorInfos.real;\n        const imag = complexVals.complexTensorInfos.imag;\n        const realVals =\n            cpuBackend.data.get(real.dataId).values as Float32Array;\n        const imagVals =\n            cpuBackend.data.get(imag.dataId).values as Float32Array;\n        for (let i = 0; i < realVals.length; i++) {\n          const real = realVals[i];\n          const imag = imagVals[i];\n          resultValues[i] = Math.hypot(real, imag);\n        }\n      }\n      return cpuBackend.makeOutput(resultValues, x.shape, 'float32');\n    };\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'cpu',\n  kernelFunc: absKernelFunc as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleBinaryKernelImpl, SimpleBinaryOperation} from './binary_types';\n\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nexport function createSimpleBinaryKernelImpl(op: SimpleBinaryOperation):\n    SimpleBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aVals: TypedArray,\n          bVals: TypedArray, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function complex(args: {inputs: ComplexInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const realVals = backend.data.get(real.dataId).values as TypedArray;\n  const imagVals = backend.data.get(imag.dataId).values as TypedArray;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n\n  const complex = backend.data.get(complexInfo.dataId);\n\n  // The complex tensor owns the underlying real and imag tensorInfos, only the\n  // complex tensor tracks refCount, when complexData is disposed the\n  // underlying tensorData will be disposed.\n  complex.complexTensorInfos = {\n    real: backend.makeTensorInfo(real.shape, 'float32', realVals),\n    imag: backend.makeTensorInfo(imag.shape, 'float32', imagVals)\n  };\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'cpu',\n  kernelFunc: complex as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  backend.incRef(x.dataId);\n\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'cpu',\n  kernelFunc: identity as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function real(args: {inputs: RealInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const real = backend.data.get(input.dataId).complexTensorInfos.real;\n  const realVal = backend.data.get(real.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the real value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(real.shape, real.dtype, realVal);\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'cpu',\n  kernelFunc: real as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport {Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    // TODO(lina128): Import kernel function once zeros is modularized.\n    const zerosTensor = tf.zeros(x.shape);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensor}, backend});\n\n    zerosTensor.dispose();\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (dtype === 'int32') {\n    const values = backend.data.get(x.dataId).values as TypedArray;\n    const resultValues = Int32Array.from(values);\n    return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const zero = util.toTypedArray([0], x.dtype);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(x.shape, [], xVals, zero, 'bool');\n\n    return backend.makeTensorInfo(resultShape, 'bool', resultData);\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from '../kernels/Cast';\nimport {complex} from '../kernels/Complex';\n\nimport {ComplexBinaryKernelImpl, ComplexBinaryOperation, SimpleBinaryKernelImpl} from './binary_types';\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param name Kernel name.\n * @param binaryKernelImpl A `SimpleBinaryKernelImpl` for the kernel.\n * @param binaryKernelComplexImpl Optional. If exists, represents a\n *     `ComplexBinaryKernelImpl` for the kernel, will be used when input dtype\n *     is `complex64`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    name: string, simpleImpl: SimpleBinaryKernelImpl,\n    complexImpl?: ComplexBinaryKernelImpl, dtype?: DataType): KernelFunc {\n  if (complexImpl == null) {\n    return ({inputs, backend}) => {\n      const {a, b} = inputs as BinaryInputs;\n      const cpuBackend = backend as MathBackendCPU;\n\n      assertNotComplex([a, b], name);\n\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    };\n  }\n\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      const $aComplex = cast(\n          {inputs: {x: a}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);\n\n      const aReal = $aComplexVals.complexTensorInfos.real;\n      const aImag = $aComplexVals.complexTensorInfos.imag;\n\n      const aRealVals =\n          cpuBackend.data.get(aReal.dataId).values as Float32Array;\n      const aImagVals =\n          cpuBackend.data.get(aImag.dataId).values as Float32Array;\n\n      const $bComplex = cast(\n          {inputs: {x: b}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);\n\n      const bReal = $bComplexVals.complexTensorInfos.real;\n      const bImag = $bComplexVals.complexTensorInfos.imag;\n\n      const bRealVals =\n          cpuBackend.data.get(bReal.dataId).values as Float32Array;\n      const bImagVals =\n          cpuBackend.data.get(bImag.dataId).values as Float32Array;\n\n      const [resultRealData, resultImagData, resultShape] = complexImpl(\n          a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);\n\n      const resultReal =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultRealData);\n\n      const resultImag =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultImagData);\n\n      const result = complex(\n          {inputs: {real: resultReal, imag: resultImag}, backend: cpuBackend});\n\n      cpuBackend.disposeIntermediateTensorInfo($aComplex);\n      cpuBackend.disposeIntermediateTensorInfo($bComplex);\n      cpuBackend.disposeIntermediateTensorInfo(resultReal);\n      cpuBackend.disposeIntermediateTensorInfo(resultImag);\n\n      return result;\n    } else {\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    }\n  };\n}\n\n/**\n * Template that creates the complex type implementation for binary ops.\n * Supports broadcast.\n */\nexport function createComplexBinaryKernelImpl(op: ComplexBinaryOperation):\n    ComplexBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aRealVals: Float32Array,\n          aImagVals: Float32Array, bRealVals: Float32Array,\n          bImagVals: Float32Array): [TypedArray, TypedArray, number[]] => {\n    const resultShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    const resultSize = util.sizeFromShape(resultShape);\n    const resultRank = resultShape.length;\n    const resultStrides = util.computeStrides(resultShape);\n\n    const resultRealVals = util.getTypedArrayFromDType('float32', resultSize);\n    const resultImagVals = util.getTypedArrayFromDType('float32', resultSize);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, resultShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, resultShape);\n\n    const aVals = backend_util.mergeRealAndImagArrays(aRealVals, aImagVals);\n    const bVals = backend_util.mergeRealAndImagArrays(bRealVals, bImagVals);\n\n    const aRank = aShape.length;\n    const aStrides = util.computeStrides(aShape);\n\n    const bRank = bShape.length;\n    const bStrides = util.computeStrides(bShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const aIdx = i % aVals.length;\n        const bIdx = i % bVals.length;\n\n        const result =\n            op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2],\n               bVals[bIdx * 2 + 1]);\n\n        resultRealVals[i] = result.real;\n        resultImagVals[i] = result.imag;\n      }\n    } else {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        const opResult =\n            op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2],\n               bVals[bIndex * 2 + 1]);\n\n        resultRealVals[i] = opResult.real;\n        resultImagVals[i] = opResult.imag;\n      }\n    }\n    return [resultRealVals, resultImagVals, resultShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const addImpl = createSimpleBinaryKernelImpl(((a, b) => a + b));\nexport const addComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal + bReal, imag: aImag + bImag};\n    }));\n\nexport const add = binaryKernelFunc(Add, addImpl, addComplexImpl);\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'cpu',\n  kernelFunc: add\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumericDataType, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates implementation for unary op.\n */\nexport function createSimpleUnaryImpl(op: SimpleUnaryOperation):\n    SimpleUnaryImpl {\n  return (values, dtype, attrs) => {\n    const newValues =\n        util.getTypedArrayFromDType(dtype as NumericDataType, values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return newValues;\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelFunc, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param name Kernel name.\n * @param op A `SimpleUnaryOperation` for the kernel.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFunc(\n    name: string, op: SimpleUnaryOperation, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xSize = util.sizeFromShape(x.shape);\n    const $dtype = dtype || x.dtype;\n    const newValues = util.getArrayFromDType($dtype, xSize);\n    for (let i = 0; i < xSize; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n\n/**\n * Template that creates a `KernelFunc` for unary ops from the given\n * `SimpleUnaryImpl`..\n * @param name Kernel name.\n * @param unaryImpl A `SimpleUnaryImpl` that implements the op.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFuncFromImpl(\n    name: string, unaryImpl: SimpleUnaryImpl, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const $dtype = dtype || x.dtype;\n    const newValues = unaryImpl(values, $dtype, attrs);\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));\nexport const ceilKernelFunc = unaryKernelFuncFromImpl(Ceil, ceilImpl);\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'cpu',\n  kernelFunc: ceilKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));\nexport const expKernelFunc = unaryKernelFuncFromImpl(Exp, expImpl);\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'cpu',\n  kernelFunc: expKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));\nexport const expm1KernelFunc = unaryKernelFuncFromImpl(Expm1, expm1Impl);\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'cpu',\n  kernelFunc: expm1KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));\nexport const floorKernelFunc = unaryKernelFuncFromImpl(Floor, floorImpl);\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'cpu',\n  kernelFunc: floorKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));\nexport const logKernelFunc = unaryKernelFuncFromImpl(Log, logImpl);\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'cpu',\n  kernelFunc: logKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const multiplyImpl =\n    createSimpleBinaryKernelImpl(((aValue, bValue) => aValue * bValue));\nexport const multiplyComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n      };\n    }));\n\nexport const multiply =\n    binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'cpu',\n  kernelFunc: multiply\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));\nexport const rsqrtKernelFunc = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'cpu',\n  kernelFunc: rsqrtKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, KernelFunc, NumericDataType, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: TypedArray, begin: number[], size: number[], shape: number[],\n    dtype: DataType): TypedArray {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n    return vals.subarray(flatOffset, flatOffset + length);\n  }\n\n  const outVals = util.getTypedArrayFromDType(dtype as NumericDataType, length);\n  for (let i = 0; i < length; ++i) {\n    const rank = size.length;\n    const strides = util.computeStrides(size);\n    const loc = util.indexToLoc(i, rank, strides);\n    const xLoc = loc.map((idx: number, j) => idx + begin[j]);\n    const xIndex = util.locToIndex(xLoc, shape.length, xStrides);\n    outVals[i] = vals[xIndex];\n  }\n  return outVals;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values as TypedArray;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const subImpl =\n    createSimpleBinaryKernelImpl(((aValue, bValue) => aValue - bValue));\nexport const subComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal - bReal, imag: aImag - bImag};\n    }));\nexport const sub = binaryKernelFunc(Sub, subImpl, subComplexImpl);\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'cpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements: {[key: string]: number} = {};\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    if (uniqueElements[element] !== undefined) {\n      indices[i] = uniqueElements[element];\n    } else {\n      const uniqueIndex = Object.keys(uniqueElements).length;\n      uniqueElements[element] = uniqueIndex;\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = Object.keys(uniqueElements).length;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/*\n * base.ts contains all the exports from tfjs-backend-cpu\n * without auto-kernel registration\n */\nimport {registerBackend} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from './backend_cpu';\nimport * as shared from './shared';\n\nexport {MathBackendCPU} from './backend_cpu';\nexport {version as version_cpu} from './version';\nexport {shared};\n\n// Side effects for default initialization of MathBackendCPU\nregisterBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acosKernelFunc = unaryKernelFunc(Acos, (xi) => Math.acos(xi));\n\nexport const acosConfig: KernelConfig = {\n  kernelName: Acos,\n  backendName: 'cpu',\n  kernelFunc: acosKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acoshKernelFunc = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));\n\nexport const acoshConfig: KernelConfig = {\n  kernelName: Acosh,\n  backendName: 'cpu',\n  kernelFunc: acoshKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asinKernelFunc = unaryKernelFunc(Asin, (xi) => Math.asin(xi));\n\nexport const asinConfig: KernelConfig = {\n  kernelName: Asin,\n  backendName: 'cpu',\n  kernelFunc: asinKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asinhKernelFunc = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));\n\nexport const asinhConfig: KernelConfig = {\n  kernelName: Asinh,\n  backendName: 'cpu',\n  kernelFunc: asinhKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atanKernelFunc = unaryKernelFunc(Atan, (xi) => Math.atan(xi));\n\nexport const atanConfig: KernelConfig = {\n  kernelName: Atan,\n  backendName: 'cpu',\n  kernelFunc: atanKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atanhKernelFunc = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));\n\nexport const atanhConfig: KernelConfig = {\n  kernelName: Atanh,\n  backendName: 'cpu',\n  kernelFunc: atanhKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function pool(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv2DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides =\n      convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n  const outputColStrides = convInfo.outShape[3];\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const outputBatchOffset = b * outputBatchStrides;\n    const inputBatchOffset = b * strides[0];\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          const xCMin = Math.max(0, xCCorner);\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let minMaxValue = initialValue;\n          let avgValue = 0;\n          let count = 0;\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const xROffset = inputBatchOffset + xR * strides[1];\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const xCOffset = xROffset + xC * strides[2];\n              const pixel = xValues[xCOffset + d];\n              if ((poolType === 'max' && pixel > minMaxValue)) {\n                minMaxValue = pixel;\n              } else if (poolType === 'avg') {\n                avgValue += pixel;\n                count++;\n              }\n            }\n            if (isNaN(minMaxValue)) {\n              break;\n            }\n          }\n          const outputOffset = outputRowOffset + yC * outputColStrides + d;\n          outputVals[outputOffset] =\n              poolType === 'avg' ? avgValue / count : minMaxValue;\n        }\n      }\n    }\n  }\n  return output;\n}\n\nexport function maxPoolPositions(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    convInfo: backend_util.Conv2DInfo, flattenPositions = false,\n    includeBatchInIndex = false): TensorBuffer<Rank, 'int32'> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const xBuf = buffer(xShape, dtype, xValues);\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        let xRMin = xRCorner;\n        while (xRMin < 0) {\n          xRMin += dilationHeight;\n        }\n        // const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          let xCMin = xCCorner;\n          while (xCMin < 0) {\n            xCMin += dilationWidth;\n          }\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let maxValue = Number.NEGATIVE_INFINITY;\n          let maxPosition = -1;\n\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const wR = xR - xRCorner;\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const wC = xC - xCCorner;\n              const pixel = xBuf.get(b, xR, xC, d);\n              if (pixel > maxValue) {\n                maxValue = pixel as number;\n                if (flattenPositions) {\n                  maxPosition = includeBatchInIndex ?\n                      ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                              convInfo.inChannels +\n                          d :\n                      (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                } else {\n                  maxPosition = wR * effectiveFilterWidth + wC;\n                }\n              }\n            }\n          }\n          maxPositions.set(maxPosition, b, yR, yC, d);\n        }\n      }\n    }\n  }\n  return maxPositions;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function avgPool(\n    args:\n        {inputs: AvgPoolInputs, backend: MathBackendCPU, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'avgPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'avg');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'cpu',\n  kernelFunc: avgPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPoolBackprop, AvgPoolBackpropAttrs, AvgPoolBackpropInputs, backend_util, buffer, KernelConfig, KernelFunc, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPoolBackprop(args: {\n  inputs: AvgPoolBackpropInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPoolBackpropAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  assertNotComplex([dy, input], 'avgPoolBackprop');\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel;\n            }\n          }\n          dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPoolBackpropConfig: KernelConfig = {\n  kernelName: AvgPoolBackprop,\n  backendName: 'cpu',\n  kernelFunc: avgPoolBackprop as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function batchNormKernelFunc(args: {\n  inputs: FusedBatchNormInputs,\n  backend: MathBackendCPU,\n  attrs: FusedBatchNormAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, scale, offset, mean, variance} = inputs;\n\n  util.assert(\n      mean.shape.length === variance.shape.length,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      offset == null || mean.shape.length === offset.shape.length,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      scale == null || mean.shape.length === scale.shape.length,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n  let {varianceEpsilon} = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const mVals = backend.data.get(mean.dataId).values as TypedArray;\n  const varVals = backend.data.get(variance.dataId).values as TypedArray;\n  const sVals = scale ? backend.data.get(scale.dataId).values as TypedArray :\n                        new Float32Array([1]);\n  const offVals = offset ?\n      backend.data.get(offset.dataId).values as TypedArray :\n      new Float32Array([0]);\n  const outVals = new Float32Array(xVals.length);\n\n  const offValsLength = offVals.length;\n  const sValsLength = sVals.length;\n  const varValsLength = varVals.length;\n  const mValsLength = mVals.length;\n\n  let offi = 0;\n  let mi = 0;\n  let si = 0;\n  let vi = 0;\n  for (let i = 0; i < xVals.length; ++i) {\n    outVals[i] = offVals[offi++] +\n        (xVals[i] - mVals[mi++]) * sVals[si++] /\n            Math.sqrt(varVals[vi++] + varianceEpsilon);\n    if (offi >= offValsLength) {\n      offi = 0;\n    }\n    if (mi >= mValsLength) {\n      mi = 0;\n    }\n    if (si >= sValsLength) {\n      si = 0;\n    }\n    if (vi >= varValsLength) {\n      vi = 0;\n    }\n  }\n  return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\n\nexport const batchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'cpu',\n  kernelFunc: batchNormKernelFunc as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const clipKernelFunc = unaryKernelFunc(ClipByValue, (xi, attrs) => {\n  const clipAttrs = attrs as {} as ClipByValueAttrs;\n  if (xi > clipAttrs.clipValueMax) {\n    return clipAttrs.clipValueMax;\n  }\n  return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;\n});\n\nexport const clipConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'cpu',\n  kernelFunc: clipKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function imag(args: {inputs: ImagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const imag = backend.data.get(input.dataId).complexTensorInfos.imag;\n  const imagVal = backend.data.get(imag.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the imag value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(imag.shape, imag.dtype, imagVal);\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'cpu',\n  kernelFunc: imag as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function reshape(\n    args:\n        {inputs: ReshapeInputs, backend: MathBackendCPU, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  backend.incRef(x.dataId);\n\n  const xData = backend.data.get(x.dataId);\n\n  if (xData.complexTensorInfos != null) {\n    const real = xData.complexTensorInfos.real;\n    const imag = xData.complexTensorInfos.imag;\n\n    real.shape = $shape;\n    imag.shape = $shape;\n  }\n\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'cpu',\n  kernelFunc: reshape as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concat(\n    args: {inputs: ConcatInputs, backend: MathBackendCPU, attrs: ConcatAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return $inputs[0];\n  }\n\n  const shapes = $inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = $inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concat({inputs: reals, backend, attrs: {axis}});\n    const imagConcated = concat({inputs: imags, backend, attrs: {axis}});\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n\n    return result;\n  }\n\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({inputs: {x: t}, backend, attrs: {shape}});\n  });\n\n  // Concats 2d tensors along axis=1.\n  outShape =\n      backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n\n  const outVals = util.getTypedArrayFromDType(\n      $inputs[0].dtype as 'float32', util.sizeFromShape(outShape));\n\n  if (inputs2D[0].shape[0] === 1) {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs2D.forEach(t => {\n      const val = backend.data.get(t.dataId).values as TypedArray;\n      const size = util.sizeFromShape(t.shape);\n\n      outVals.set(val, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs2D.forEach(t => {\n      const tVals = backend.data.get(t.dataId).values as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < t.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < t.shape[1]; ++col) {\n          outVals[resIdx + col] = tVals[tIdx++];\n        }\n      }\n\n      colOffset += t.shape[1];\n    });\n  }\n\n  const finalOutShape =\n      backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n\n  const outInfo =\n      backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outInfo;\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cosKernelFunc = unaryKernelFunc(Cos, (xi) => Math.cos(xi));\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'cpu',\n  kernelFunc: cosKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const coshKernelFunc = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'cpu',\n  kernelFunc: coshKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter} = inputs as Dilation2DInputs;\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xRank = x.shape.length;\n\n    const filterVals = cpuBackend.data.get(filter.dataId).values as TypedArray;\n    const filterRank = filter.shape.length;\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    const outSize = util.sizeFromShape(outShape);\n    const outRank = outShape.length;\n    const outputVals = util.getArrayFromDType(x.dtype, outSize);\n\n    // Upsampling the input by fill in `dilation size - 1` values between each\n    // input value.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const xIndex = util.locToIndex(\n                        [b, hIn, wIn, d], xRank, util.computeStrides(x.shape));\n                    const filterIndex = util.locToIndex(\n                        [h, w, d], filterRank,\n                        util.computeStrides(filter.shape));\n                    const val = xVals[xIndex] + filterVals[filterIndex];\n                    if (val > curVal) {\n                      curVal = val;\n                    }\n                  }\n                }\n              }\n            }\n            const outputIndex = util.locToIndex(\n                [b, hOut, wOut, d], outRank, util.computeStrides(outShape));\n            outputVals[outputIndex] = curVal;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropFilter}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed filter gradients has the same dimensions as the filter:\n    // [filterHeight, filterWidth, depth]\n    const gradients = util.makeZerosNestedTypedArray(\n                          filter.shape, filter.dtype) as number[][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hMax = 0;\n            let wMax = 0;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hMax = h;\n                      wMax = w;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);\n\n    return {dataId, shape: filter.shape, dtype: filter.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n    const gradients =\n        util.makeZerosNestedTypedArray(x.shape, x.dtype) as number[][][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hInMax = (hBeg < 0) ? 0 : hBeg;\n            let wInMax = (wBeg < 0) ? 0 : wBeg;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Div, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const divImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a / b);\nexport const div = binaryKernelFunc(Div, divImpl);\n\nexport const divConfig: KernelConfig = {\n  kernelName: Div,\n  backendName: 'cpu',\n  kernelFunc: div\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const eluKernelFunc =\n    unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : (Math.exp(xi) - 1));\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'cpu',\n  kernelFunc: eluKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst p = backend_util.ERF_P;\nconst a1 = backend_util.ERF_A1;\nconst a2 = backend_util.ERF_A2;\nconst a3 = backend_util.ERF_A3;\nconst a4 = backend_util.ERF_A4;\nconst a5 = backend_util.ERF_A5;\n\nexport const erfKernelFunc = unaryKernelFunc(\n    Erf,\n    (xi) => {\n      const sign = Math.sign(xi);\n      const v = Math.abs(xi);\n      const t = 1.0 / (1.0 + p * v);\n      return sign *\n          (1.0 -\n           (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n               Math.exp(-v * v));\n    },\n);\n\nexport const erfConfig: KernelConfig = {\n  kernelName: Erf,\n  backendName: 'cpu',\n  kernelFunc: erfKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Tensor, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {add} from '../kernels/Add';\nimport {complex} from '../kernels/Complex';\nimport {concat} from '../kernels/Concat';\nimport {divConfig} from '../kernels/Div';\nimport {identity} from '../kernels/Identity';\nimport {imag} from '../kernels/Imag';\nimport {multiply} from '../kernels/Multiply';\nimport {real} from '../kernels/Real';\nimport {slice} from '../kernels/Slice';\nimport {sub} from '../kernels/Sub';\n\n/**\n * Calculate FFT of inner most elements of batch tensor.\n */\nexport function fftBatch(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): TensorInfo {\n  const inputShape = input.shape;\n  const batch = inputShape[0];\n  const innerDim = inputShape[1];\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const real2D = inputVals.complexTensorInfos.real;\n  const imag2D = inputVals.complexTensorInfos.imag;\n\n  // Collects real and imaginary values separately.\n  const resultShape = [batch, innerDim];\n  const resultSize = util.sizeFromShape(resultShape);\n  const resultReal = util.getTypedArrayFromDType('float32', resultSize);\n  const resultImag = util.getTypedArrayFromDType('float32', resultSize);\n\n  for (let b = 0; b < batch; b++) {\n    // TODO: Support slice ops for complex type.\n    const r = slice({\n      inputs: {x: real2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n    const i = slice({\n      inputs: {x: imag2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n\n    const input = complex({inputs: {real: r, imag: i}, backend: cpuBackend});\n\n    // Run FFT by batch element.\n    const {real, imag} = fftImpl(input, inverse, cpuBackend);\n    const res = backend_util.mergeRealAndImagArrays(real, imag);\n\n    for (let d = 0; d < innerDim; d++) {\n      const c = backend_util.getComplexWithIndex(res, d);\n      resultReal[b * innerDim + d] = c.real;\n      resultImag[b * innerDim + d] = c.imag;\n    }\n\n    cpuBackend.disposeIntermediateTensorInfo(r);\n    cpuBackend.disposeIntermediateTensorInfo(i);\n    cpuBackend.disposeIntermediateTensorInfo(input);\n  }\n\n  const $realInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultReal);\n  const $imagInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultImag);\n\n  const result = complex(\n      {inputs: {real: $realInfo, imag: $imagInfo}, backend: cpuBackend});\n\n  cpuBackend.disposeIntermediateTensorInfo($realInfo);\n  cpuBackend.disposeIntermediateTensorInfo($imagInfo);\n\n  return result;\n}\n\nexport function fftImpl(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  const inputSize = util.sizeFromShape(input.shape);\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const realVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values as\n      Float32Array;\n\n  const imagVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values as\n      Float32Array;\n\n  if (isExponentOf2(inputSize)) {\n    const result =\n        fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);\n\n    const resultShape = [input.shape[0], input.shape[1]];\n\n    if (inverse) {\n      const realInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.real);\n      const imagInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.imag);\n\n      const sizeInfo: TensorInfo = cpuBackend.makeTensorInfo(\n          [], 'float32',\n          util.createScalarValue(inputSize as {} as 'float32', 'float32'));\n      const sizeInfoCopy =\n          identity({inputs: {x: sizeInfo}, backend: cpuBackend});\n\n      const divRealInfo =\n          divConfig.kernelFunc(\n              {inputs: {a: realInfo, b: sizeInfo}, backend: cpuBackend}) as\n          TensorInfo;\n      const divImagInfo =\n          divConfig.kernelFunc(\n              {inputs: {a: imagInfo, b: sizeInfoCopy}, backend: cpuBackend}) as\n          TensorInfo;\n\n      const divRealVals =\n          cpuBackend.data.get(divRealInfo.dataId).values as Float32Array;\n      const divImagVals =\n          cpuBackend.data.get(divImagInfo.dataId).values as Float32Array;\n\n      cpuBackend.disposeIntermediateTensorInfo(realInfo);\n      cpuBackend.disposeIntermediateTensorInfo(imagInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);\n      cpuBackend.disposeIntermediateTensorInfo(divRealInfo);\n      cpuBackend.disposeIntermediateTensorInfo(divImagInfo);\n\n      return {real: divRealVals, imag: divImagVals};\n    }\n\n    return result;\n  } else {\n    const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n    const rawOutput =\n        fourierTransformByMatmul(data, inputSize, inverse) as Float32Array;\n\n    return backend_util.splitRealAndImagArrays(rawOutput);\n  }\n}\n\nfunction isExponentOf2(size: number): boolean {\n  return (size & size - 1) === 0;\n}\n\n// FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\nfunction fftRadix2(\n    realVals: Float32Array, imagVals: Float32Array, size: number,\n    inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  if (size === 1) {\n    return {real: realVals, imag: imagVals};\n  }\n\n  const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n  const half = size / 2;\n\n  const evenComplex = backend_util.complexWithEvenIndex(data);\n\n  const evenRealVals = evenComplex.real;\n  const evenImagVals = evenComplex.imag;\n\n  const evenShape = [evenRealVals.length];\n\n  const evenRealInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenRealVals);\n  const evenImagInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenImagVals);\n\n  const evenTensorInfo = complex(\n      {inputs: {real: evenRealInfo, imag: evenImagInfo}, backend: cpuBackend});\n\n  const oddComplex = backend_util.complexWithOddIndex(data);\n\n  const oddRealVals = oddComplex.real;\n  const oddImagVals = oddComplex.imag;\n\n  const oddShape = [oddRealVals.length];\n\n  const oddRealInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddRealVals);\n  const oddImagInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddImagVals);\n\n  const oddTensorInfo = complex(\n      {inputs: {real: oddRealInfo, imag: oddImagInfo}, backend: cpuBackend});\n\n  // Recursive call for half part of original input.\n  const $evenComplex =\n      fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);\n\n  const $evenRealVals = $evenComplex.real;\n  const $evenImagVals = $evenComplex.imag;\n\n  const $evenShape = [$evenRealVals.length];\n\n  const $evenRealInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenRealVals);\n  const $evenImagInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenImagVals);\n\n  const $evenTensorInfo = complex({\n    inputs: {real: $evenRealInfo, imag: $evenImagInfo},\n    backend: cpuBackend\n  });\n\n  const $oddComplex =\n      fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);\n\n  const $oddRealVals = $oddComplex.real;\n  const $oddImagVals = $oddComplex.imag;\n\n  const $oddShape = [$oddRealVals.length];\n\n  const $oddRealInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddRealVals);\n  const $oddImagInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddImagVals);\n\n  const $oddTensorInfo = complex(\n      {inputs: {real: $oddRealInfo, imag: $oddImagInfo}, backend: cpuBackend});\n\n  const e = backend_util.exponents(size, inverse);\n  const eShape = [e.real.length];\n\n  const eRealInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.real);\n  const eImagInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.imag);\n\n  const complexInfo = complex(\n      {inputs: {real: eRealInfo, imag: eImagInfo}, backend: cpuBackend});\n\n  const exponentInfo =\n      multiply(\n          {inputs: {a: complexInfo, b: $oddTensorInfo}, backend: cpuBackend}) as\n      TensorInfo;\n\n  const addPart = add({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n  const subPart = sub({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n\n  const addPartReal = real({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartReal = real({inputs: {input: subPart}, backend: cpuBackend});\n\n  const addPartImag = imag({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartImag = imag({inputs: {input: subPart}, backend: cpuBackend});\n\n  const $real = concat({\n    inputs: [addPartReal as Tensor, subPartReal as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n  const $imag = concat({\n    inputs: [addPartImag as Tensor, subPartImag as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n\n  const $realVals = cpuBackend.data.get($real.dataId).values as Float32Array;\n  const $imagVals = cpuBackend.data.get($imag.dataId).values as Float32Array;\n\n  cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(complexInfo);\n  cpuBackend.disposeIntermediateTensorInfo(exponentInfo);\n  cpuBackend.disposeIntermediateTensorInfo(addPart);\n  cpuBackend.disposeIntermediateTensorInfo(subPart);\n  cpuBackend.disposeIntermediateTensorInfo(addPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(addPartImag);\n  cpuBackend.disposeIntermediateTensorInfo(subPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(subPartImag);\n  cpuBackend.disposeIntermediateTensorInfo($real);\n  cpuBackend.disposeIntermediateTensorInfo($imag);\n\n  return {real: $realVals, imag: $imagVals};\n}\n\n// Calculate fourier transform by multplying sinusoid matrix.\nfunction fourierTransformByMatmul(\n    data: TypedArray, size: number, inverse: boolean): TypedArray {\n  const ret = new Float32Array(size * 2);\n  // TODO: Use matmul instead once it supports complex64 type.\n  for (let r = 0; r < size; r++) {\n    let real = 0.0;\n    let imag = 0.0;\n    for (let c = 0; c < size; c++) {\n      const e = backend_util.exponent(r * c, size, inverse);\n      const term = backend_util.getComplexWithIndex(data as Float32Array, c);\n      real += term.real * e.real - term.imag * e.imag;\n      imag += term.real * e.imag + term.imag * e.real;\n    }\n    if (inverse) {\n      real /= size;\n      imag /= size;\n    }\n    backend_util.assignToTypedArray(ret, real, imag, r);\n  }\n  return ret;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FFT, FFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function fft(args: {inputs: FFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, false, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const fftConfig: KernelConfig = {\n  kernelName: FFT,\n  backendName: 'cpu',\n  kernelFunc: fft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n  kernelName: FlipLeftRight,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as FlipLeftRightInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n\n            const coordX = Math.round(imageWidth - x);\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n\n            let outputValue = imageVals[outIdx];\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth) {\n              // set the output to the image value at the coordinate position.\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n            output[outIdx] = outputValue;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IFFT, IFFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function ifft(args: {inputs: IFFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, true, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const ifftConfig: KernelConfig = {\n  kernelName: IFFT,\n  backendName: 'cpu',\n  kernelFunc: ifft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isFiniteKernelFunc =\n    unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, 'bool');\n\nexport const isFiniteConfig: KernelConfig = {\n  kernelName: IsFinite,\n  backendName: 'cpu',\n  kernelFunc: isFiniteKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isInfKernelFunc =\n    unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, 'bool');\n\nexport const isInfConfig: KernelConfig = {\n  kernelName: IsInf,\n  backendName: 'cpu',\n  kernelFunc: isInfKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isNaNKernelFunc =\n    unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, 'bool');\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'cpu',\n  kernelFunc: isNaNKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const log1pKernelFunc = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));\n\nexport const log1pConfig: KernelConfig = {\n  kernelName: Log1p,\n  backendName: 'cpu',\n  kernelFunc: log1pKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const logicalNotKernelFunc =\n    unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, 'bool');\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'cpu',\n  kernelFunc: logicalNotKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Max, MaxAttrs, MaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxInputs;\n    const {reductionIndices, keepDims} = attrs as {} as MaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    let xShape = x.shape;\n    const xRank = xShape.length;\n\n    const origAxes = util.parseAxisParam(reductionIndices, xShape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    if (permutedAxes != null) {\n      const newShape: number[] = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = xShape[permutedAxes[i]];\n      }\n\n      xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n      axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n      xShape = newShape;\n    }\n\n    assertNotComplex(x, 'max');\n    backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n    const [maxOutShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(xShape, axes);\n\n    const reduceSize = util.sizeFromShape(reduceShape);\n\n    const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n    const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n    let outShape = maxOutShape;\n    if (keepDims) {\n      // reshape\n      const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n      outShape = newShape;\n    }\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function maxPool(\n    args:\n        {inputs: MaxPoolInputs, backend: MathBackendCPU, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'maxPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'max');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'cpu',\n  kernelFunc: maxPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPoolBackprop, MaxPoolBackpropAttrs, MaxPoolBackpropInputs, Rank, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPoolPositions} from '../utils/pool_utils';\n\nexport function maxPoolBackprop(args: {\n  inputs: MaxPoolBackpropInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPoolBackpropAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input, output} = inputs;\n  const x = input;\n  assertNotComplex([input, output], 'maxPoolBackprop');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const maxPosBuf = buffer(\n      convInfo.outShape, x.dtype,\n      maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n              const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 -\n                  (maxPosBuf.get(b, dyR, dyC, d) as number);\n              const curPos = wR * effectiveFilterWidth + wC;\n\n              const mask = maxPos === curPos ? 1 : 0;\n              if (mask === 0) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel * mask;\n            }\n          }\n          dx.set(dotProd, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPoolBackpropConfig: KernelConfig = {\n  kernelName: MaxPoolBackprop,\n  backendName: 'cpu',\n  kernelFunc: maxPoolBackprop as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxPoolWithArgmaxImpl} from './MaxPoolWithArgmax_impl';\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxPoolWithArgmaxInputs;\n    const {filterSize, strides, pad, includeBatchInIndex} =\n        attrs as {} as MaxPoolWithArgmaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'MaxPoolWithArgmax');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const convInfo = backend_util.computePool2DInfo(\n        x.shape as [number, number, number, number], filterSize, strides,\n        [1, 1], pad);\n    const [pooled, indexes] = maxPoolWithArgmaxImpl(\n        values, x.shape, x.dtype, includeBatchInIndex, convInfo);\n\n    const pooledDataId =\n        cpuBackend.write(pooled as Float32Array, convInfo.outShape, x.dtype);\n    const indexesDataId =\n        cpuBackend.write(indexes as Int32Array, convInfo.outShape, x.dtype);\n    return [\n      {dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype},\n      {dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32'}\n    ];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {maxPoolPositions, pool} from '../utils/pool_utils';\nexport function maxPoolWithArgmaxImpl(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    includeBatchInIndex: boolean, convInfo: backend_util.Conv2DInfo) {\n  const strides = util.computeStrides(xShape);\n  const maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n  const maxPositions = maxPoolPositions(\n      xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n\n  return [maxPools.values, maxPositions.values];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV4Impl = kernel_impls.nonMaxSuppressionV4Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV4Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV4,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV4Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize} =\n        attrs as unknown as NonMaxSuppressionV4Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionPadded');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const {selectedIndices, validOutputs} = nonMaxSuppressionV4Impl(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold,\n        padToMaxOutputSize);\n\n    return [selectedIndices, validOutputs];\n  }\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV5Impl = kernel_impls.nonMaxSuppressionV5Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV5Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} =\n        attrs as unknown as NonMaxSuppressionV5Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const maxOutputSizeVal = maxOutputSize;\n    const iouThresholdVal = iouThreshold;\n    const scoreThresholdVal = scoreThreshold;\n    const softNmsSigmaVal = softNmsSigma;\n\n    const {selectedIndices, selectedScores} = nonMaxSuppressionV5Impl(\n        boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n        scoreThresholdVal, softNmsSigmaVal);\n\n    return [selectedIndices, selectedScores];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const notEqualImpl =\n    createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));\nexport const notEqual =\n    binaryKernelFunc(NotEqual, notEqualImpl, null /* complexOp */, 'bool');\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'cpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function padV2(\n    args: {inputs: PadV2Inputs, backend: MathBackendCPU, attrs: PadV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, constantValue} = attrs;\n\n  assertNotComplex(x, 'pad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xSize = util.sizeFromShape(x.shape);\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  if (constantValue !== 0) {\n    resVals.fill(constantValue);\n  }\n\n  for (let i = 0; i < xSize; i++) {\n    const coords = util.indexToLoc(i, xRank, xStrides);\n    const outCoords = coords.map((c, i) => c + start[i]);\n    const outIndex = util.locToIndex(outCoords, resultRank, resultStrides);\n\n    resVals[outIndex] = xVals[i];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'cpu',\n  kernelFunc: padV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const reciprocalKernelFunc = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'cpu',\n  kernelFunc: reciprocalKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util, RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n  kernelName: RotateWithOffset,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as RotateWithOffsetInputs;\n    const {radians, fillValue, center} = attrs as {} as RotateWithOffsetAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const [centerX, centerY] =\n        backend_util.getImageCenter(center, imageHeight, imageWidth);\n    const fullOpacityValue = 255;\n\n    const sinFactor = Math.sin(radians);\n    const cosFactor = Math.cos(radians);\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n            const y = coords[1];\n\n            // coordX/coordY are the result of rotating and translating x/y.\n            let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;\n            let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;\n            coordX = Math.round(coordX + centerX);\n            coordY = Math.round(coordY + centerY);\n\n            let outputValue = fillValue;\n            if (typeof fillValue !== 'number') {\n              if (channel === 3) {\n                outputValue = fullOpacityValue;\n              } else {\n                outputValue = fillValue[channel];\n              }\n            }\n\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth && coordY >= 0 &&\n                coordY < imageHeight) {\n              // set the output to the image value at the coordinate position.\n              const rotatedRowOffset = coordY * (imageWidth * numChannels);\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rotatedRowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n            output[outIdx] = outputValue as number;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const roundKernelFunc = unaryKernelFunc(Round, (xi) => {\n  // The algorithm is based on banker's rounding.\n  const base = Math.floor(xi);\n  if (xi - base < 0.5) {\n    return Math.floor(xi);\n  } else if (xi - base > 0.5) {\n    return Math.ceil(xi);\n  } else {\n    if (base % 2.0 === 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n});\n\nexport const roundConfig: KernelConfig = {\n  kernelName: Round,\n  backendName: 'cpu',\n  kernelFunc: roundKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst scaleAlpha = backend_util.SELU_SCALEALPHA;\nconst scale = backend_util.SELU_SCALE;\n\nexport const seluKernelFunc = unaryKernelFunc(Selu, (xi) => {\n  if (xi >= 0) {\n    return scale * xi;\n  } else {\n    return scaleAlpha * (Math.exp(xi) - 1);\n  }\n});\n\nexport const seluConfig: KernelConfig = {\n  kernelName: Selu,\n  backendName: 'cpu',\n  kernelFunc: seluKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sigmoidKernelFunc =\n    unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'cpu',\n  kernelFunc: sigmoidKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const signKernelFunc = unaryKernelFunc(Sign, (xi) => {\n  if (xi < 0) {\n    return -1;\n  } else if (xi > 0) {\n    return 1;\n  } else {\n    return 0;\n  }\n});\n\nexport const signConfig: KernelConfig = {\n  kernelName: Sign,\n  backendName: 'cpu',\n  kernelFunc: signKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sinKernelFunc = unaryKernelFunc(Sin, (xi) => Math.sin(xi));\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'cpu',\n  kernelFunc: sinKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sinhKernelFunc = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'cpu',\n  kernelFunc: sinhKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\n// mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\nconst epsilon = 1.1920928955078125e-7;\nconst threshold = Math.log(epsilon) + 2.0;\n\nexport const softplusKernelFunc = unaryKernelFunc(Softplus, (xi) => {\n  // Value above which exp(x) may overflow, but softplus(x) == x\n  // is within machine epsilon.\n  const tooLarge = xi > -threshold;\n\n  // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n  // is within machine epsilon.\n  const tooSmall = xi < threshold;\n\n  const expX = Math.exp(xi);\n  let result;\n\n  if (tooSmall) {\n    result = expX;\n  } else if (tooLarge) {\n    result = xi;\n  } else {\n    result = Math.log(1.0 + expX);\n  }\n  return result;\n});\n\nexport const softplusConfig: KernelConfig = {\n  kernelName: Softplus,\n  backendName: 'cpu',\n  kernelFunc: softplusKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transpose, TransposeAttrs, TransposeInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n\n  assertNotComplex(x, 'transpose');\n\n  const xRank = x.shape.length;\n\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n\n  const dataId = backend.write(result, newShape, x.dtype);\n  return {dataId, shape: newShape, dtype: x.dtype};\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'cpu',\n  kernelFunc: transpose as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ReshapeAttrs, ReshapeInputs, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, TransposeAttrs, TransposeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {padV2Config} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function spaceToBatchND(args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: MathBackendCPU,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  assertNotComplex([x], 'spaceToBatchND');\n\n  const prod = util.sizeFromShape(blockShape);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...(paddings as Array<[number, number]>));\n\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedX = padV2Config.kernelFunc({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  }) as TensorInfo;\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapeInputs: ReshapeInputs = {x: paddedX};\n  const reshapeAttrs: ReshapeAttrs = {shape: reshapedPaddedShape};\n  const paddedXReshaped =\n      reshape({inputs: reshapeInputs, backend, attrs: reshapeAttrs});\n\n  const transposeInputs: TransposeInputs = {x: paddedXReshaped};\n  const transposeAttrs:\n      TransposeAttrs = {perm: permutedReshapedPaddedPermutation};\n  const paddedXT =\n      transpose({inputs: transposeInputs, backend, attrs: transposeAttrs});\n\n  const resultReshapeInputs: ReshapeInputs = {x: paddedXT};\n  const resultReshapeAttrs: ReshapeAttrs = {shape: flattenShape};\n  const result = reshape(\n      {inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs});\n\n  backend.disposeIntermediateTensorInfo(paddedX);\n  backend.disposeIntermediateTensorInfo(paddedXReshaped);\n  backend.disposeIntermediateTensorInfo(paddedXT);\n\n  return result;\n}\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'cpu',\n  kernelFunc: spaceToBatchND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sqrtKernelFunc = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'cpu',\n  kernelFunc: sqrtKernelFunc,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'square');\n\n    const values = cpuBackend.data.get(x.dataId).values as Float32Array;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const squaredDifferenceImpl = createSimpleBinaryKernelImpl(((a, b) => {\n  const diff = a - b;\n  return diff * diff;\n}));\nexport const squaredDifference =\n    binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'cpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Step, StepAttrs} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const stepKernelFunc = unaryKernelFunc(Step, (xi, attrs) => {\n  const stepAttrs = attrs as {} as StepAttrs;\n  if (isNaN(xi)) {\n    return NaN;\n  } else {\n    return xi > 0 ? 1 : stepAttrs.alpha;\n  }\n});\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'cpu',\n  kernelFunc: stepKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tanKernelFunc = unaryKernelFunc(Tan, (xi) => Math.tan(xi));\n\nexport const tanConfig: KernelConfig = {\n  kernelName: Tan,\n  backendName: 'cpu',\n  kernelFunc: tanKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tanhKernelFunc = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'cpu',\n  kernelFunc: tanhKernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unique, UniqueAttrs, UniqueInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {uniqueImpl} from './Unique_impl';\n\nexport function unique(\n    args: {inputs: UniqueInputs, attrs: UniqueAttrs, backend: MathBackendCPU}):\n    TensorInfo[] {\n  const {inputs, attrs, backend} = args;\n  const {axis} = attrs;\n  const {x} = inputs;\n  assertNotComplex(x, 'unique');\n\n  const values = backend.data.get(x.dataId).values;\n  const {outputValues, outputShape, indices} =\n      uniqueImpl(values, axis, x.shape, x.dtype);\n  return [\n    backend.makeTensorInfo(outputShape, x.dtype, outputValues),\n    backend.makeTensorInfo([indices.length], 'int32', indices),\n  ];\n}\n\nexport const uniqueConfig: KernelConfig = {\n  kernelName: Unique,\n  backendName: 'cpu',\n  kernelFunc: unique as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPoolBackpropConfig} from './kernels/AvgPoolBackprop';\nimport {batchNormConfig} from './kernels/BatchNorm';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipConfig} from './kernels/Clip';\nimport {complexConfig} from './kernels/Complex';\nimport {concatConfig} from './kernels/Concat';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {dilation2dConfig} from './kernels/Dilation2D';\nimport {dilation2dBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2dBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {divConfig} from './kernels/Div';\nimport {eluConfig} from './kernels/Elu';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expm1Config} from './kernels/Expm1';\nimport {fftConfig} from './kernels/FFT';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {identityConfig} from './kernels/Identity';\nimport {ifftConfig} from './kernels/IFFT';\nimport {imagConfig} from './kernels/Imag';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {maxConfig} from './kernels/Max';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPoolBackpropConfig} from './kernels/MaxPoolBackprop';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {nonMaxSuppressionV4Config} from './kernels/NonMaxSuppressionV4';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {padV2Config} from './kernels/PadV2';\nimport {realConfig} from './kernels/Real';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stepConfig} from './kernels/Step';\nimport {subConfig} from './kernels/Sub';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {transposeConfig} from './kernels/Transpose';\nimport {uniqueConfig} from './kernels/Unique';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atanhConfig,\n  avgPoolConfig,\n  avgPoolBackpropConfig,\n  batchNormConfig,\n  castConfig,\n  ceilConfig,\n  clipConfig,\n  complexConfig,\n  concatConfig,\n  cosConfig,\n  coshConfig,\n  dilation2dConfig,\n  dilation2dBackpropInputConfig,\n  dilation2dBackpropFilterConfig,\n  divConfig,\n  eluConfig,\n  erfConfig,\n  expConfig,\n  expm1Config,\n  fftConfig,\n  flipLeftRightConfig,\n  floorConfig,\n  identityConfig,\n  ifftConfig,\n  imagConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  logConfig,\n  log1pConfig,\n  logicalNotConfig,\n  maxPoolConfig,\n  maxPoolBackpropConfig,\n  maxPoolWithArgmaxConfig,\n  maxConfig,\n  multiplyConfig,\n  nonMaxSuppressionV4Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  padV2Config,\n  realConfig,\n  reciprocalConfig,\n  reshapeConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  stepConfig,\n  subConfig,\n  tanConfig,\n  tanhConfig,\n  transposeConfig,\n  uniqueConfig,\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '2.6.0';\nexport {version};\n"],"names":["assertNotComplex","tensor","opName","Array","isArray","forEach","t","util","assert","dtype","nonMaxSuppressionV3Impl","kernel_impls","split","tile","topkImpl","whereImpl","mapActivation","backend","x","activation","preluActivationWeights","linear","relu","tf.elu","relu6","prelu","Error","MathBackendCPU","KernelBackend","[object Object]","super","this","data","DataStorage","engine","values","shape","firstUse","env","get","backend_util","warn","dataId","set","refCount","write","has","numDataIds","readSync","complexTensorInfos","realValues","real","imagValues","imag","mergeRealAndImagArrays","decodedData","map","d","decodeString","tf.buffer","makeTensorFromDataId","disposeData","delete","tensorInfo","tensorData","f","start","now","kernelMs","unreliable","reasons","begin","end","strides","outShape","slice_util","computeOutShape","some","axis","tf.tensor","buffer","xBuf","bufferSync","i","size","loc","indexToLoc","newLoc","length","j","toTensor","xVals","vals","num","rank","outIndex","fill","slice","res","tf.slice","reshape","outLoc","inLoc","ax","tf.mul","tf.scalar","tensors","result","resultVals","currVals","logits","dim","axes","parseAxisParam","maxLogit","max","expandedShape","expandShapeToKeepDim","a","tf.sub","b","tf.exp","sumExp","sum","tf.div","broadcastedBinaryOp","aValue","bValue","Math","pow","transposeA","transposeB","sharedDim","leftDim","rightDim","batchDim","aValues","bValues","aBatch","aOuterStep","aInnerStep","bInnerStep","bOuterStep","bBatch","resVals","blockSize","i0","j0","k0","iBlock","min","jBlock","kBlock","k","bias","batchMatMul","tf.add","floor","assertAxesAreInnerMostDims","reduceShape","computeOutAndReduceShapes","resultDtype","upcastType","tf.zeros","reduceSize","sizeFromShape","aVals","offset","prod","segmentIds","numSegments","numIters","expandDims","segmentId","tf.equal","asType","mul","push","tf.stack","minIndex","value","maxIndex","exclusive","reverse","finalDim","indexAdjuster","idx","prevIdx","aVal","bVal","condition","newValues","index","condVals","sorted","rem","all","anyVal","diff","inVals","xValue","dy","y","resultValues","Float32Array","dyValues","v","makeOutput","atan2","input","filter","convInfo","conv2d","filterHeight","filterWidth","dilationHeight","dilationWidth","padLeft","padInfo","left","padTop","top","isChannelsLast","dataFormat","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","wVals","yVals","batchSize","xOffset1","yOffset1","yR","outHeight","yOffset2","xRCorner","strideHeight","wR","xR","inHeight","wOffset1","xOffset2","yC","outWidth","yOffset3","xCCorner","strideWidth","wC","xC","inWidth","xOffset3","wOffset3","d1","inChannels","xVal","d2","outChannels","filterDepth","dilationDepth","padFront","front","yF","outDepth","xFCorner","strideDepth","wF","xF","inDepth","wOffset2","yOffset4","xOffset4","wOffset4","dx","inShape","dxValues","fltValues","fltS0","fltS1","fltS2","topPad","leftPad","xRMin","ceil","yRMax","xCMin","yCMax","dotProd","dyOffset","fltOffset","dxS0","dxS1","dxS2","dxS3","dyS0","dyS1","dyS2","dyS3","fltS3","frontPad","xFMin","yFMax","dW","filterShape","dyBuf","yRMin","yCMin","dw","dwValues","dwS0","dwS1","dwS2","dwS3","xValues","xS0","xS1","xS2","xS3","yFMin","depthwiseConv2D","chMul","q","dm","trunc","reps","indices","newShape","indicesValues","originalLoc","originalIndex","locToIndex","blockShape","crops","reduce","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","sliceSize","getSliceSize","tf.transpose","poolType","effectiveFilterDepth","effectiveFilterHeight","effectiveFilterWidth","initialValue","Number","NEGATIVE_INFINITY","POSITIVE_INFINITY","output","outputVals","outputBatchStrides","outputDepthStrides","outputRowStrides","outputColStrides","batch","outputBatchOffset","inputBatchOffset","channel","yDepth","xDepthCorner","xDepthMin","xDepthMax","outputDepthOffset","yRow","xRowCorner","xRowMin","xRowMax","outputRowOffset","yCol","xColCorner","xColMin","xColMax","outputColOffset","minMaxValue","avgValue","count","xDepth","xDepthOffset","xRow","xRowOffset","xCol","pixel","isNaN","pool3d","toFloat","avgMultiplier","dxDepth","dxRow","dxCol","dyDepthCorner","dyRowCorner","dyColCorner","wDepth","dyDepth","wRow","dyRow","wCol","dyCol","maxPositions","maxValue","maxPosition","maxPool3dPositions","maxPosBuf","mask","newHeight","newWidth","alignCorners","oldHeight","oldWidth","numChannels","effectiveInputSize","effectiveOutputSize","outputIdx","effectiveRowSizeRatio","effectiveColSizeRatio","r","sourceFracRow","sourceRowFloor","rowFrac","sourceRowCeil","topRowOffset","botRowOffset","c","sourceFracCol","sourceColFloor","colFrac","sourceColCeil","topLeftOffest","botLeftOffset","topRightOffset","botRightOffest","topLeft","bottomLeft","newValue","xHeight","xWidth","depth","yHeight","yWidth","effectiveXSize","effectiveYSize","heightScale","widthScale","bOffset","dxR","topDxRIndex","bottomDxRIndex","topDxROffset","bottomDxROffset","dxRLerp","inverseDxRLerp","dxC","leftDxCIndex","rightDxCIndex","dxCLerp","inverseDxCLerp","topLeftRCOffset","topRightRCOffset","bottomLeftRCOffset","bottomRightRCOffset","inverseDxRLerpTimesInverseDxCLerp","inverseDxRLerpTimesDxCLerp","dxRLerpTimesInverseDxCLerp","dxRLerpTimesDxCLerp","dyVal","tf.tensor4d","outputOffset","batchOffset","rowOffset","round","colOffset","newVal","invHeightScale","invWidthScale","winHeight","winWidth","startRLerp","startDyR","startCLerp","startDyC","accum","dyRIndex","dyR","dyROffset","dyCIndex","dyC","dyCOffset","depthRadius","alpha","beta","channels","maxD","sumAcrossChannels","currentChannel","beginSumOffset","endSumOffset","z","val","inputImage","outputImage","inputImageValues","outputImageValues","depthBegin","depthEnd","norm","dyi","normalized","numSamples","seed","probabilities","tf.softmax","numEvents","probVals","cdf","event","random","seedrandom.alea","toString","outOffset","sampleId","onValue","offValue","indicesVal","tf.tensor2d","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","h","inH","offsetH","w","inW","offsetD","inputIdx","op","assertAndGetBroadcastShape","bVals","aBroadcastDims","getBroadcastDims","bBroadcastDims","aBuf","bBuf","aLoc","aIndex","bLoc","bIndex","sizeSplits","epsilon","images","boxIndex","cropSize","method","extrapolationValue","imageHeight","imageWidth","numBoxes","cropHeight","cropWidth","boxVals","boxIndVals","imageVals","inStride","outStride","startInd","y1","x1","y2","x2","bInd","yInd","ind","topInd","bottomInd","yLerp","xInd","leftInd","rightInd","xLerp","topRight","bottom","closestX","closestY","inInd","outInd","sparseIndices","sparseValues","outputShape","defaultValue","sliceRank","numUpdates","outputSize","calculateShapes","scatter","indicesShape","resultShape","numSlices","prepareAndValidate","TensorBuffer","indicesData","xData","flattenIndex","updates","inferDtype","getArrayFromDType","makeTensor","stop","linspaceImpl","sumDupeIndices","flattenShape","updatesData","simpleAbsImpl","abs","absConfig","kernelName","Abs","backendName","kernelFunc","args","inputs","cpuBackend","complexVals","realVals","imagVals","hypot","createSimpleBinaryKernelImpl","aShape","bShape","resultRank","resultStrides","computeStrides","resultSize","getTypedArrayFromDType","aRank","bRank","aStrides","bStrides","complex","complexInfo","makeTensorInfo","complexConfig","Complex","identity","incRef","identityConfig","Identity","realVal","realConfig","Real","cast","attrs","zerosTensor","floatX","dispose","disposeIntermediateTensorInfo","realPart","hasEncodingLoss","Int32Array","from","zero","toTypedArray","resultData","castConfig","Cast","binaryKernelFunc","name","simpleImpl","complexImpl","$dtype","$aComplex","$aComplexVals","aReal","aImag","aRealVals","aImagVals","$bComplex","$bComplexVals","bReal","bImag","bRealVals","bImagVals","resultRealData","resultImagData","resultReal","resultImag","createComplexBinaryKernelImpl","resultRealVals","resultImagVals","aIdx","bIdx","opResult","addImpl","addComplexImpl","add","Add","addConfig","createSimpleUnaryImpl","unaryKernelFunc","xSize","unaryKernelFuncFromImpl","unaryImpl","ceilImpl","xi","ceilKernelFunc","Ceil","ceilConfig","expImpl","exp","expKernelFunc","Exp","expConfig","expm1Impl","expm1","expm1KernelFunc","Expm1","expm1Config","floorImpl","floorKernelFunc","Floor","floorConfig","logImpl","log","logKernelFunc","Log","logConfig","maxImpl","multiplyImpl","multiplyComplexImpl","multiply","Multiply","multiplyConfig","rsqrtImpl","sqrt","rsqrtKernelFunc","Rsqrt","rsqrtConfig","sliceImpl","isContinous","isSliceContinous","xStrides","flatOffset","computeFlatOffset","subarray","outVals","xLoc","xIndex","$begin","$size","parseSliceParams","assertParamsValid","sliceConfig","Slice","subImpl","subComplexImpl","sub","Sub","subConfig","transposeImpl","xShape","perm","xRank","newStrides","uniqueImpl","$axis","uniqueElements","inputBuffer","uniqueIndices","is1DTensor","element","axisValues","m","n","join","undefined","uniqueIndex","Object","keys","outputTmpShape","outputBuffer","uniqueElementIndex","outputValues","acosKernelFunc","Acos","acos","acosConfig","acoshKernelFunc","Acosh","acosh","acoshConfig","asinKernelFunc","Asin","asin","asinConfig","asinhKernelFunc","Asinh","asinh","asinhConfig","atanKernelFunc","Atan","atan","atanConfig","atanhKernelFunc","Atanh","atanh","atanhConfig","pool","xRMax","xCMax","xROffset","maxPoolPositions","flattenPositions","includeBatchInIndex","avgPoolConfig","AvgPool","filterSize","pad","dimRoundingMode","eitherStridesOrDilationsAreOne","computePool2DInfo","arraysEqual","avgPoolBackpropConfig","AvgPoolBackprop","dyData","dyRCorner","dyCCorner","batchNormConfig","FusedBatchNorm","scale","mean","variance","varianceEpsilon","mVals","varVals","sVals","offVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","clipKernelFunc","ClipByValue","clipAttrs","clipValueMax","clipValueMin","clipConfig","imagVal","imagConfig","Imag","$shape","inferFromImplicitShape","$xSize","reshapeConfig","Reshape","concat","$inputs","shapes","assertParamsConsistent","reals","imags","realConcated","imagConcated","inputs2D","innerSize","tVals","tIdx","row","resIdx","col","finalOutShape","outInfo","concatConfig","Concat","cosKernelFunc","Cos","cos","cosConfig","coshKernelFunc","Cosh","cosh","coshConfig","dilation2dConfig","Dilation2D","dilations","filterVals","filterRank","computeDilation2DInfo","outSize","outRank","hOut","hBeg","wOut","wBeg","curVal","MIN_SAFE_INTEGER","hIn","wIn","filterIndex","dilation2dBackpropFilterConfig","Dilation2DBackpropFilter","$x","toNestedArray","$filter","$dy","gradients","makeZerosNestedTypedArray","hMax","wMax","dilation2dBackpropInputConfig","Dilation2DBackpropInput","hInMax","wInMax","divImpl","div","Div","divConfig","eluKernelFunc","Elu","eluConfig","p","ERF_P","a1","ERF_A1","a2","ERF_A2","a3","ERF_A3","a4","ERF_A4","a5","ERF_A5","erfKernelFunc","Erf","sign","erfConfig","fftBatch","inverse","inputShape","innerDim","inputVals","real2D","imag2D","fftImpl","getComplexWithIndex","$realInfo","$imagInfo","inputSize","fftRadix2","half","evenComplex","complexWithEvenIndex","evenRealVals","evenImagVals","evenShape","evenRealInfo","evenImagInfo","evenTensorInfo","oddComplex","complexWithOddIndex","oddRealVals","oddImagVals","oddShape","oddRealInfo","oddImagInfo","oddTensorInfo","$evenComplex","$evenRealVals","$evenImagVals","$evenShape","$evenRealInfo","$evenImagInfo","$evenTensorInfo","$oddComplex","$oddRealVals","$oddImagVals","$oddShape","$oddRealInfo","$oddImagInfo","$oddTensorInfo","e","exponents","eShape","eRealInfo","eImagInfo","exponentInfo","addPart","subPart","addPartReal","subPartReal","addPartImag","subPartImag","$real","$imag","$realVals","$imagVals","realInfo","imagInfo","sizeInfo","createScalarValue","sizeInfoCopy","divRealInfo","divImagInfo","divRealVals","divImagVals","rawOutput","ret","exponent","term","assignToTypedArray","fourierTransformByMatmul","splitRealAndImagArrays","fftConfig","FFT","innerDimensionSize","input2D","resultReshaped","flipLeftRightConfig","FlipLeftRight","image","batchIdx","coordX","outIdx","outputValue","ifftConfig","IFFT","isFiniteKernelFunc","IsFinite","isFinite","isFiniteConfig","isInfKernelFunc","IsInf","Infinity","isInfConfig","isNaNKernelFunc","IsNan","isNaNConfig","log1pKernelFunc","Log1p","log1p","log1pConfig","logicalNotKernelFunc","LogicalNot","logicalNotConfig","maxConfig","Max","reductionIndices","keepDims","origAxes","permutedAxes","getAxesPermutation","getInnerMostAxes","maxOutShape","maxPoolConfig","MaxPool","maxPoolBackpropConfig","MaxPoolBackprop","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","pooled","indexes","maxPools","maxPoolWithArgmaxImpl","pooledDataId","indexesDataId","nonMaxSuppressionV4Impl","nonMaxSuppressionV4Config","NonMaxSuppressionV4","padToMaxOutputSize","selectedIndices","validOutputs","nonMaxSuppressionV5Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","maxOutputSizeVal","iouThresholdVal","scoreThresholdVal","softNmsSigmaVal","selectedScores","notEqualImpl","notEqual","NotEqual","notEqualConfig","padV2Config","PadV2","paddings","constantValue","outCoords","reciprocalKernelFunc","Reciprocal","reciprocalConfig","rotateWithOffsetConfig","RotateWithOffset","radians","fillValue","center","centerX","centerY","getImageCenter","sinFactor","sin","cosFactor","coords","coordY","roundKernelFunc","Round","base","roundConfig","scaleAlpha","SELU_SCALEALPHA","SELU_SCALE","seluKernelFunc","Selu","seluConfig","sigmoidKernelFunc","Sigmoid","sigmoidConfig","signKernelFunc","Sign","signConfig","sinKernelFunc","Sin","sinConfig","sinhKernelFunc","Sinh","sinh","sinhConfig","threshold","softplusKernelFunc","Softplus","tooLarge","tooSmall","expX","softplusConfig","transpose","transposeConfig","Transpose","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","paddedX","reshapedPaddedShape","permutedReshapedPaddedPermutation","paddedXReshaped","paddedXT","sqrtKernelFunc","Sqrt","sqrtConfig","squareConfig","Square","squaredDifferenceImpl","squaredDifference","SquaredDifference","squaredDifferenceConfig","stepKernelFunc","Step","stepAttrs","NaN","stepConfig","tanKernelFunc","Tan","tan","tanConfig","tanhKernelFunc","Tanh","tanh","tanhConfig","uniqueConfig","Unique","kernelConfigs","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;iUAmBgBA,EACZC,EAAiCC,GAC9BC,MAAMC,QAAQH,KACjBA,EAAS,CAACA,IAEZA,EAAOI,QAAQC,IACJ,MAALA,GACFC,OAAKC,OACW,cAAZF,EAAEG,MACF,IAAM,GACFP,8DCTd,MAAMQ,EAA0BC,eAAaD,wBACvCE,EAAQD,eAAaC,MACrBC,EAAOF,eAAaE,KACpBC,EAAWH,eAAaG,SACxBC,EAAYJ,eAAaI,UAM/B,SAASC,EACLC,EAAyBC,EAAWC,EACpCC,GACF,GAAmB,WAAfD,EACF,OAAOF,EAAQI,OAAOH,GACjB,GAAmB,SAAfC,EACT,OAAOF,EAAQK,KAAKJ,GACf,GAAmB,QAAfC,EACT,OAAOI,MAAOL,GACT,GAAmB,UAAfC,EACT,OAAOF,EAAQO,MAAMN,GAChB,GAAmB,UAAfC,EACT,OAAOF,EAAQQ,MAAMP,EAAGE,GAE1B,MAAM,IAAIM,MACN,cAAcP,yDAePQ,UAAuBC,gBAMlCC,cACEC,QANKC,eAAY,GAGXA,eAAW,EAIjBA,KAAKC,KAAO,IAAIC,cAAYF,KAAMG,YAGpCL,MAAMM,EAAoCC,EAAiB3B,GAErDsB,KAAKM,WACPN,KAAKM,UAAW,EACZC,QAAMC,IAAI,YACZC,eAAaC,KACT,4dAYR,MAAMC,EAAS,GAIf,OAFAX,KAAKC,KAAKW,IAAID,EAAQ,CAACP,OAAAA,EAAQ1B,MAAAA,EAAOmC,SAAU,IAEzCF,EASTb,eACIO,EAAiB3B,EACjB0B,GAGF,MAAO,CAACO,OAFMX,KAAKc,MAAMV,EAAQC,EAAO3B,GAEjB2B,MAAAA,EAAO3B,MAAAA,GAIhCoB,OAAOa,GACcX,KAAKC,KAAKO,IAAIG,GACtBE,WAIbf,OAAOa,GACL,GAAIX,KAAKC,KAAKc,IAAIJ,GAAS,CACNX,KAAKC,KAAKO,IAAIG,GACtBE,YAIff,KACIa,EAAgBP,EAAoCC,EACpD3B,GACFsB,KAAKC,KAAKW,IAAID,EAAQ,CAACP,OAAAA,EAAQ1B,MAAAA,EAAOmC,SAAU,IAGlDf,aACE,OAAOE,KAAKC,KAAKe,aAGnBlB,WAAWa,GACT,OAAOX,KAAKiB,SAASN,GAEvBb,SAASa,GACP,MAAMjC,MAACA,EAAKwC,mBAAEA,GAAsBlB,KAAKC,KAAKO,IAAIG,GAElD,GAAc,cAAVjC,EAAuB,CACzB,MAAMyC,EACFnB,KAAKiB,SAASC,EAAmBE,KAAKT,QACpCU,EACFrB,KAAKiB,SAASC,EAAmBI,KAAKX,QAC1C,OAAOF,eAAac,uBAAuBJ,EAAYE,GAGzD,OAAOrB,KAAKC,KAAKO,IAAIG,GAAQP,OAGvBN,WAA2BvB,GACjC,MAAM0B,EAAOD,KAAKiB,SAAS1C,EAAEoC,QAC7B,IAAIa,EAAcvB,EAClB,GAAgB,WAAZ1B,EAAEG,MACJ,IAEE8C,EAAevB,EAAsBwB,IAAIC,GAAKlD,OAAKmD,aAAaD,IAChE,SACA,MAAM,IAAI/B,MAAM,oDAGpB,OAAOiC,SAAUrD,EAAE8B,MAAO9B,EAAEG,MAAO8C,GAGrC1B,WACIM,EAAoCC,EAAiB3B,GACvD,MAAMiC,EAASX,KAAKc,MAAMV,EAAQC,EAAO3B,GACzC,OAAOyB,WAAS0B,qBAAqBlB,EAAQN,EAAO3B,EAAOsB,MAG7DF,YAAYa,GACV,GAAIX,KAAKC,KAAKc,IAAIJ,GAAS,CACzB,MAAMO,mBAACA,GAAsBlB,KAAKC,KAAKO,IAAIG,GAEjB,MAAtBO,IACFlB,KAAK8B,YAAYZ,EAAmBE,KAAKT,QACzCX,KAAK8B,YAAYZ,EAAmBI,KAAKX,SAG3CX,KAAKC,KAAK8B,OAAOpB,IAIrBb,8BAA8BkC,GAC5B,MAAMrB,EAASqB,EAAWrB,OAE1B,GAAIX,KAAKC,KAAKc,IAAIJ,GAAS,CACzB,MAAMsB,EAAajC,KAAKC,KAAKO,IAAIG,GAEjCsB,EAAWpB,WAEPoB,EAAWpB,SAAW,GACxBb,KAAK8B,YAAYnB,IAKvBb,WAAWoC,GACT,MAAMC,EAAQ3D,OAAK4D,MAGnB,OAFAF,IAEO,CAACG,SADS7D,OAAK4D,MAAQD,GAIhCrC,SACE,MAAO,CAELwC,YAAY,EACZC,QACI,CAAC,uHAKTzC,aACIX,EAAMqD,EAAiBC,EAAeC,GACxCzE,EAAiBkB,EAAG,gBAEpB,MAAMwD,EAAWC,aAAWC,gBAAgBL,EAAOC,EAAKC,GAExD,GAAIC,EAASG,KAAKC,GAAiB,IAATA,GACxB,OAAOC,SAAU,GAAIL,GAGvB,MAAMM,EAASrB,SAAUe,EAAUxD,EAAET,OAC/BwE,EAAOlD,KAAKmD,WAAWhE,GAC7B,IAAK,IAAIiE,EAAI,EAAGA,EAAIH,EAAOI,KAAMD,IAAK,CACpC,MAAME,EAAML,EAAOM,WAAWH,GAExBI,EAAmB,IAAIpF,MAAMkF,EAAIG,QACvC,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAOC,OAAQC,IACjCF,EAAOE,GAAKJ,EAAII,GAAKhB,EAAQgB,GAAKlB,EAAMkB,GAE1CT,EAAOrC,IAAIsC,EAAK1C,OAAOgD,MAAYF,GAGrC,OAAOL,EAAOU,WAGhB7D,KAAKX,GACH,MAAMyE,EAAQ5D,KAAKiB,SAAS9B,EAAEwB,QACxBsC,EAASrB,SAAU,CAACzC,EAAEkE,KAAMlE,EAAEkE,MAAOlE,EAAET,OACvCmF,EAAOZ,EAAO7C,OACpB,IAAK,IAAIgD,EAAI,EAAGA,EAAIQ,EAAMH,OAAQL,IAChCS,EAAKT,EAAIjE,EAAEkE,KAAOD,GAAKQ,EAAMR,GAE/B,OAAOH,EAAOU,WAGhB7D,QAAQX,EAAW4D,GACjB,MAAMe,EAAM3E,EAAEkB,MAAM0C,GACdJ,EAAqB,IAAIvE,MAAMe,EAAE4E,KAAO,GAC9C,IAAIC,EAAW,EACf,IAAK,IAAIZ,EAAI,EAAGA,EAAIjE,EAAE4E,KAAMX,IACtBA,IAAML,IACRJ,EAASqB,KAAc7E,EAAEkB,MAAM+C,IAInC,MAAMZ,EAAQ,IAAIpE,MAAMe,EAAE4E,MAAME,KAAK,GAC/BZ,EAAOlE,EAAEkB,MAAM6D,QACrBb,EAAKN,GAAQ,EACb,MAAMoB,EAAM,IAAI/F,MAAM0F,GACtB,IAAK,IAAIV,EAAI,EAAGA,EAAIe,EAAIV,OAAQL,IAC9BZ,EAAMO,GAAQK,EACde,EAAIf,GAAKgB,QAASjF,EAAGqD,EAAOa,GAAMgB,QAAQ1B,GAE5C,OAAOwB,EAGTrE,QAA0BX,EAAM4D,GAC9B9E,EAAiBkB,EAAG,WAEpB,MAAM8D,EAASrB,SAAUzC,EAAEkB,MAAOlB,EAAET,OAC9BwE,EAAOlD,KAAKmD,WAAWhE,GAE7B,IAAK,IAAIiE,EAAI,EAAGA,EAAIH,EAAOI,KAAMD,IAAK,CACpC,MAAMkB,EAASrB,EAAOM,WAAWH,GAC3BmB,EAAQD,EAAOJ,QACrBnB,EAAKzE,QAAQkG,GAAMD,EAAMC,GAAMrF,EAAEkB,MAAMmE,GAAM,EAAID,EAAMC,IACvDvB,EAAOrC,IAAIsC,EAAK1C,OAAO+D,MAAWD,GAGpC,OAAOrB,EAAOU,WAGhB7D,IAAsBX,GAIpB,OAHAlB,EAAiBkB,EAAG,OAGbsF,MAAOC,UAAW,GAAIvF,GAG/BW,KAAuB6E,GACrB1G,EAAiB0G,EAAS,QAE1B,MAAMd,EAAOc,EAAQlD,IAAIlD,GAAKyB,KAAKiB,SAAS1C,EAAEoC,SACxCiE,EAAShD,SAAU+C,EAAQ,GAAGtE,MAAOsE,EAAQ,GAAGjG,OAChDmG,EAAaD,EAAOxE,OAC1B,IAAK,IAAIgD,EAAI,EAAGA,EAAIuB,EAAQlB,OAAQL,IAAK,CACvC,MAAM0B,EAAWjB,EAAKT,GACtB,IAAK,IAAIM,EAAI,EAAGA,EAAImB,EAAWpB,OAAQC,IACrCmB,EAAWnB,IAAMoB,EAASpB,GAG9B,OAAOkB,EAAOjB,WAGhB7D,QAA0BiF,EAAWC,GACnC,MAAMC,EAAOzG,OAAK0G,eAAe,CAACF,GAAMD,EAAO1E,OAGzC8E,EAAWC,MAAIL,EAAQE,GACvBI,EACF5E,eAAa6E,qBAAqBH,EAAS9E,MAAO4E,GAGhDM,EAAIC,MAAOT,EAAQI,EAASd,QAAQgB,IACpCI,EAAIC,MAAOH,GACXI,EAAS3F,KAAK4F,IAAIH,EAAGR,GAAMZ,QAAQgB,GAIzC,OAAOQ,MAAOJ,EAAGE,GAGnB7F,IAAsByF,EAAME,GAG1B,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,OAElBzF,KAAK8F,oBACDP,EAAGE,EAAGF,EAAE7G,MAAO,CAACqH,EAAQC,IAAWC,KAAKC,IAAIH,EAAQC,IAIjElG,YACIyF,EAAaE,EAAaU,EAC1BC,GACFnI,EAAiB,CAACsH,EAAGE,GAAI,UAEzB,MAAMY,EAAYF,EAAaZ,EAAElF,MAAM,GAAKkF,EAAElF,MAAM,GAC9CiG,EAAUH,EAAaZ,EAAElF,MAAM,GAAKkF,EAAElF,MAAM,GAC5CkG,EAAWH,EAAaX,EAAEpF,MAAM,GAAKoF,EAAEpF,MAAM,GAC7CmG,EAAWjB,EAAElF,MAAM,GAEnBoG,EAAUzG,KAAKiB,SAASsE,EAAE5E,QAC1B+F,EAAU1G,KAAKiB,SAASwE,EAAE9E,SACzBgG,EAAQC,EAAYC,GAAcV,EACrC,CAACZ,EAAE7C,QAAQ,GAAI,EAAG6C,EAAE7C,QAAQ,IAC5B,CAAC6C,EAAE7C,QAAQ,GAAI6C,EAAE7C,QAAQ,GAAI,IAC1BoE,EAAYC,EAAYC,GAAUZ,EACrC,CAAC,EAAGX,EAAE/C,QAAQ,GAAI+C,EAAE/C,QAAQ,IAC5B,CAAC+C,EAAE/C,QAAQ,GAAI,EAAG+C,EAAE/C,QAAQ,IAE1BW,EAAOiD,EAAUC,EACjB3B,EAAShD,SAAU,CAAC4E,EAAUF,EAASC,GAAWhB,EAAE7G,OACpDuI,EAAUrC,EAAOxE,OACjB8G,EAAYlH,KAAKkH,UAEvB,IAAK,IAAIzB,EAAI,EAAGA,EAAIe,EAAUf,IAC5B,IAAK,IAAI0B,EAAK,EAAGA,EAAKb,EAASa,GAAMD,EACnC,IAAK,IAAIE,EAAK,EAAGA,EAAKb,EAAUa,GAAMF,EACpC,IAAK,IAAIG,EAAK,EAAGA,EAAKhB,EAAWgB,GAAMH,EAAW,CAEhD,MAAMI,EAASrB,KAAKsB,IAAIJ,EAAKD,EAAWZ,GAClCkB,EAASvB,KAAKsB,IAAIH,EAAKF,EAAWX,GAClCkB,EAASxB,KAAKsB,IAAIF,EAAKH,EAAWb,GAExC,IAAK,IAAIjD,EAAI+D,EAAI/D,EAAIkE,EAAQlE,IAC3B,IAAK,IAAIM,EAAI0D,EAAI1D,EAAI8D,EAAQ9D,IAAK,CAChC,IAAIkC,EAAM,EAEV,IAAK,IAAI8B,EAAIL,EAAIK,EAAID,EAAQC,IAC3B9B,GAAOa,EAAQhB,EAAIkB,EAASvD,EAAIwD,EAAac,EAAIb,GAC7CH,EAAQgB,EAAIZ,EAAapD,EAAIqD,EAAatB,EAAIuB,GAEpDC,EAAQxB,EAAIpC,GAAQD,EAAImD,EAAW7C,KAAOkC,GAOtD,OAAOhB,EAAOjB,WAGhB7D,kBACIyF,EAACA,EAACE,EAAEA,EAACU,WAAEA,EAAUC,WAAEA,EAAUuB,KAAEA,EAAIvI,WAAEA,EAAUC,uBAAEA,IAEnD,IAAIuF,EAAS5E,KAAK4H,YAAYrC,EAAGE,EAAGU,EAAYC,GAWhD,OAVIuB,IAEF/C,EAASiD,MAAOjD,EAAQ+C,IAEtBvI,IACFwF,EACI3F,EAAce,KAAM4E,EAAQxF,EAAYC,IAIvCuF,EAGT9E,SAASyF,EAAWE,GAClBxH,EAAiB,CAACsH,EAAGE,GAAI,YAIzB,OAAOzF,KAAK8F,oBAAoBP,EAAGE,EADf,QADT,CAACF,EAAWE,IAAcQ,KAAK6B,MAAMvC,EAAIE,IAKtD3F,IAAIX,EAAW8F,GACbhH,EAAiBkB,EAAG,OAEpBsB,eAAasH,2BAA2B,MAAO9C,EAAM9F,EAAE4E,MACvD,MAAOpB,EAAUqF,GACbvH,eAAawH,0BAA0B9I,EAAEkB,MAAO4E,GAC9CiD,EAAcC,aAAWhJ,EAAET,MAAO,SAClCkG,EAASwD,QAASzF,EAAUuF,GAC5BG,EAAa7J,OAAK8J,cAAcN,GAChCnE,EAAO7D,KAAKiB,SAAS2D,EAAOjE,QAE5B4H,EAAQvI,KAAKiB,SAAS9B,EAAEwB,QAC9B,IAAK,IAAIyC,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CACpC,MAAMoF,EAASpF,EAAIiF,EACnB,IAAIzC,EAAM,EACV,IAAK,IAAIlC,EAAI,EAAGA,EAAI2E,IAAc3E,EAChCkC,GAAO2C,EAAMC,EAAS9E,GAExBG,EAAKT,GAAKwC,EAEZ,OAAOhB,EAGT9E,KAAKX,EAAW8F,GACdhH,EAAiBkB,EAAG,OAEpB,MAAOwD,EAAUqF,GACbvH,eAAawH,0BAA0B9I,EAAEkB,MAAO4E,GAC9CiD,EAAcC,aAAWhJ,EAAET,MAAO,SAClCkG,EAASwD,QAASzF,EAAUuF,GAC5BG,EAAa7J,OAAK8J,cAAcN,GAChCnE,EAAO7D,KAAKiB,SAAS2D,EAAOjE,QAE5B4H,EAAQvI,KAAKiB,SAAS9B,EAAEwB,QAC9B,IAAK,IAAIyC,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CACpC,MAAMoF,EAASpF,EAAIiF,EACnB,IAAII,EAAO,EACX,IAAK,IAAI/E,EAAI,EAAGA,EAAI2E,IAAc3E,EAChC+E,GAAQF,EAAMC,EAAS9E,GAEzBG,EAAKT,GAAKqF,EAEZ,OAAO7D,EAGT9E,mBACIX,EAAMuJ,EAAsBC,GAC9B1K,EAAiBkB,EAAG,sBAEpB,MAAMgF,EAAM,GAINyE,EAAWzJ,EAAE4E,KAAO2E,EAAW3E,KACrC,IAAK,IAAIX,EAAI,EAAGA,EAAIwF,IAAYxF,EAC9BsF,EAAaA,EAAWG,WAAWzF,EAAI,GAGzC,IAAK,IAAIA,EAAI,EAAGA,EAAIuF,IAAevF,EAAG,CACpC,MAAM0F,EAAYpE,SAAUtB,EAAG,SAEzBwC,EADOmD,QAASD,EAAWJ,GAAYM,OAAO,WACnCC,IAAI9J,GAAGyG,IAAI,GAC5BzB,EAAI+E,KAAKtD,GAGX,OAAOuD,QAAShF,GAGlBrE,OAAOX,EAAW4D,GAChB9E,EAAiBkB,EAAG,UAEpB,MAAM8F,EAAO,CAAClC,GACdtC,eAAasH,2BAA2B,SAAU9C,EAAM9F,EAAE4E,MAC1D,MAAOpB,EAAUqF,GACbvH,eAAawH,0BAA0B9I,EAAEkB,MAAO4E,GAC9CL,EAASwD,QAASzF,EAAU,SAC5B0F,EAAa7J,OAAK8J,cAAcN,GAChCnE,EAAO7D,KAAKiB,SAAS2D,EAAOjE,QAE5B4H,EAAQvI,KAAKiB,SAAS9B,EAAEwB,QAC9B,IAAK,IAAIyC,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CACpC,MAAMoF,EAASpF,EAAIiF,EACnB,IAAId,EAAMgB,EAAMC,GACZY,EAAW,EACf,IAAK,IAAI1F,EAAI,EAAGA,EAAI2E,IAAc3E,EAAG,CACnC,MAAM2F,EAAQd,EAAMC,EAAS9E,GACzB2F,EAAQ9B,IACVA,EAAM8B,EACND,EAAW1F,GAGfG,EAAKT,GAAKgG,EAEZ,OAAOxE,EAGT9E,OAAOX,EAAW4D,GAChB9E,EAAiBkB,EAAG,UAEpB,MAAM8F,EAAO,CAAClC,GACdtC,eAAasH,2BAA2B,SAAU9C,EAAM9F,EAAE4E,MAC1D,MAAOpB,EAAUqF,GACbvH,eAAawH,0BAA0B9I,EAAEkB,MAAO4E,GAC9CL,EAASwD,QAASzF,EAAU,SAC5B0F,EAAa7J,OAAK8J,cAAcN,GAChCnE,EAAO7D,KAAKiB,SAAS2D,EAAOjE,QAE5B4H,EAAQvI,KAAKiB,SAAS9B,EAAEwB,QAC9B,IAAK,IAAIyC,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CACpC,MAAMoF,EAASpF,EAAIiF,EACnB,IAAIjD,EAAMmD,EAAMC,GACZc,EAAW,EACf,IAAK,IAAI5F,EAAI,EAAGA,EAAI2E,IAAc3E,EAAG,CACnC,MAAM2F,EAAQd,EAAMC,EAAS9E,GACzB2F,EAAQjE,IACVA,EAAMiE,EACNC,EAAW5F,GAGfG,EAAKT,GAAKkG,EAEZ,OAAO1E,EAGT9E,OAAOX,EAAW4D,EAAcwG,EAAoBC,GAIlD,GAFAvL,EAAiBkB,EAAG,UAEhB4D,IAAS5D,EAAE4E,KAAO,EACpB,MAAM,IAAIpE,MACN,oDAAoDR,EAAE4E,KAAO,KAC7D,gBAAgBhB,KAEtB,MAAMmF,EAAcC,aAAWhJ,EAAET,MAAO,SAClCkG,EAASwD,QAASjJ,EAAEkB,MAAO6H,GAC3BrE,EAAO7D,KAAKiB,SAAS2D,EAAOjE,QAE5B4H,EAAQvI,KAAKiB,SAAS9B,EAAEwB,QACxB8I,EAAWtK,EAAEkB,MAAMlB,EAAE4E,KAAO,GAC5B2F,EAAgBF,EAClB,CAACpG,EAAWM,IAAcN,EAAIqG,EAAW/F,EAAI,EAC7C,CAACN,EAAWM,IAAcN,EAAIM,EAClC,IAAK,IAAIN,EAAI,EAAGA,EAAImF,EAAM9E,OAAQL,GAAKqG,EACrC,IAAK,IAAI/F,EAAI,EAAGA,EAAI+F,EAAU/F,IAAK,CACjC,MAAMiG,EAAMD,EAActG,EAAGM,GAC7B,GAAU,IAANA,EACFG,EAAK8F,GAAOJ,EAAY,EAAIhB,EAAMoB,OAC7B,CACL,MAAMC,EAAUF,EAActG,EAAGM,EAAI,GACrCG,EAAK8F,GAAOJ,EAAYhB,EAAMqB,GAAW/F,EAAK+F,GACtBrB,EAAMoB,GAAO9F,EAAK+F,IAIhD,OAAOhF,EAGT9E,MAAMyF,EAAWE,GAGf,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,SAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAG,OAAQ,CAACoE,EAAMC,IAC3CD,IAASC,EAAQ,EAAI,GAIjChK,SAASyF,EAAWE,GAGlB,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,YAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAG,OAAQ,CAACoE,EAAMC,IAC3CD,IAASC,EAAQ,EAAI,GAIjChK,KAAKyF,EAAWE,GAGd,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,QAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAG,OAAQ,CAACoE,EAAMC,IAC3CD,EAAOC,EAAQ,EAAI,GAI/BhK,UAAUyF,EAAWE,GAGnB,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,aAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAG,OAAQ,CAACoE,EAAMC,IAC3CD,GAAQC,EAAQ,EAAI,GAIhChK,QAAQyF,EAAWE,GAGjB,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,WAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAG,OAAQ,CAACoE,EAAMC,IAC3CD,EAAOC,EAAQ,EAAI,GAI/BhK,aAAayF,EAAWE,GAGtB,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,gBAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAG,OAAQ,CAACoE,EAAMC,IAC3CD,GAAQC,EAAQ,EAAI,GAIhChK,WAAWyF,EAAWE,GAGpB,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,cAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAG,OAAQ,CAACoE,EAAMC,IAC5CD,GAAQC,GAInBhK,UAAUyF,EAAWE,GAGnB,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,aAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAG,OAAQ,CAACoE,EAAMC,IAC5CD,GAAQC,GAInBhK,OAAOiK,EAAmBxE,EAAWE,GACnCxH,EAAiB,CAAC8L,EAAWxE,EAAGE,GAAI,UAEpC,MAAMrF,EAASJ,KAAKiB,SAAS8I,EAAUpJ,QACjC8F,EAAUzG,KAAKiB,SAASsE,EAAE5E,QAC1B+F,EAAU1G,KAAKiB,SAASwE,EAAE9E,QAC1BiE,EAASwD,QAAS7C,EAAElF,MAAO8H,aAAW5C,EAAE7G,MAAO+G,EAAE/G,QACjDsL,EAAYhK,KAAKiB,SAAS2D,EAAOjE,QACvC,IAAIsJ,EAAQ,EACZ,MAAMzB,EAA4B,IAAnBuB,EAAUhG,MAAcgG,EAAUhG,KAAO,GAAgB,IAAXwB,EAAExB,KAC3D,EACAvF,OAAK8J,cAAc/C,EAAElF,MAAM6D,MAAM,IAErC,IAAK,IAAId,EAAI,EAAGA,EAAIhD,EAAOqD,OAAQL,IACjC,IAAK,IAAIM,EAAI,EAAGA,EAAI8E,EAAQ9E,IACR,IAAdtD,EAAOgD,GACT4G,EAAUC,KAAWxD,EAAQrD,GAE7B4G,EAAUC,KAAWvD,EAAQtD,GAKnC,OAAOwB,EAGT9E,MAAMiK,GACJ9L,EAAiB,CAAC8L,GAAY,SAE9B,MAAMG,EAAWlK,KAAKiB,SAAS8I,EAAUpJ,QACzC,OAAO3B,EAAU+K,EAAU1J,MAAO6J,GAGpCpK,KAAuBX,EAAMuI,EAAWyC,GACtClM,EAAiBkB,EAAG,QAEpB,MAAMyE,EAAQ5D,KAAKiB,SAAS9B,EAAEwB,QAC9B,OAAO5B,EAAS6E,EAAOzE,EAAEkB,MAAOlB,EAAET,MAA0BgJ,EAAGyC,GAGjErK,IAAIX,EAAW8F,GACbhH,EAAiBkB,EAAG,OAEpBsB,eAAasH,2BAA2B,MAAO9C,EAAM9F,EAAE4E,MACvD,MAAOpB,EAAUqF,GACbvH,eAAawH,0BAA0B9I,EAAEkB,MAAO4E,GAC9CL,EAASwD,QAASzF,EAAUxD,EAAET,OAC9B2J,EAAa7J,OAAK8J,cAAcN,GAChCnE,EAAO7D,KAAKiB,SAAS2D,EAAOjE,QAE5B4H,EAAQvI,KAAKiB,SAAS9B,EAAEwB,QAC9B,IAAK,IAAIyC,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CACpC,MAAMoF,EAASpF,EAAIiF,EACnB,IAAId,EAAMgB,EAAMC,GAChB,IAAK,IAAI9E,EAAI,EAAGA,EAAI2E,IAAc3E,EAAG,CACnC,MAAM2F,EAAQd,EAAMC,EAAS9E,GACzB2F,EAAQ9B,IACVA,EAAM8B,GAGVxF,EAAKT,GAAKmE,EAEZ,OAAO3C,EAGT9E,QAAQyF,EAAWE,GAGjB,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,WAElBzF,KAAK8F,oBACRP,EAAGE,EAAGF,EAAE7G,MAAO,CAACmL,EAAMC,IAAS7D,KAAKsB,IAAIsC,EAAMC,IAGpDhK,IAAIyF,EAAWE,GAGb,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,OAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAGF,EAAE7G,MAAO,CAACmL,EAAMC,KACpD,MAAMM,EAAMP,EAAOC,EACnB,OAAKD,EAAO,GAAKC,EAAO,GAAOD,GAAQ,GAAKC,GAAQ,EAC3CM,GAECA,EAAMN,GAAQA,IAK5BhK,QAAQyF,EAAWE,GAGjB,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,WAElBzF,KAAK8F,oBACRP,EAAGE,EAAGF,EAAE7G,MAAO,CAACmL,EAAMC,IAAS7D,KAAKb,IAAIyE,EAAMC,IAGpDhK,IAAIX,EAAW8F,GACbhH,EAAiBkB,EAAG,OAEpBsB,eAAasH,2BAA2B,MAAO9C,EAAM9F,EAAE4E,MACvD,MAAOpB,EAAUqF,GACbvH,eAAawH,0BAA0B9I,EAAEkB,MAAO4E,GAC9CL,EAASwD,QAASzF,EAAUxD,EAAET,OAC9B2J,EAAa7J,OAAK8J,cAAcN,GAChCnE,EAAO7D,KAAKiB,SAAS2D,EAAOjE,QAE5B4H,EAAQvI,KAAKiB,SAAS9B,EAAEwB,QAC9B,IAAK,IAAIyC,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CACpC,MAAMoF,EAASpF,EAAIiF,EACnB,IAAIgC,EAAM9B,EAAMC,GAChB,IAAK,IAAI9E,EAAI,EAAGA,EAAI2E,IAAc3E,EAAG,CACnC,MAAM2F,EAAQd,EAAMC,EAAS9E,GAC7B2G,EAAMA,GAAOhB,EAEfxF,EAAKT,GAAKiH,EAEZ,OAAOzF,EAGT9E,IAAIX,EAAW8F,GACbhH,EAAiBkB,EAAG,OAEpBsB,eAAasH,2BAA2B,MAAO9C,EAAM9F,EAAE4E,MACvD,MAAOpB,EAAUqF,GACbvH,eAAawH,0BAA0B9I,EAAEkB,MAAO4E,GAC9CL,EAASwD,QAASzF,EAAUxD,EAAET,OAC9B2J,EAAa7J,OAAK8J,cAAcN,GAChCnE,EAAO7D,KAAKiB,SAAS2D,EAAOjE,QAE5B4H,EAAQvI,KAAKiB,SAAS9B,EAAEwB,QAC9B,IAAK,IAAIyC,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CACpC,MAAMoF,EAASpF,EAAIiF,EACnB,IAAIiC,EAAS/B,EAAMC,GACnB,IAAK,IAAI9E,EAAI,EAAGA,EAAI2E,IAAc3E,EAAG,CACnC,MAAM2F,EAAQd,EAAMC,EAAS9E,GAC7B4G,EAASA,GAAUjB,EAErBxF,EAAKT,GAAKkH,EAEZ,OAAO1F,EAGT9E,kBAAkByF,EAAWE,GAG3B,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,qBAElBzF,KAAK8F,oBAAoBP,EAAGE,EAAGF,EAAE7G,MAAO,CAACmL,EAAMC,KACpD,MAAMS,EAAOV,EAAOC,EACpB,OAAOS,EAAOA,IAIlBzK,OAAyBX,GACvB,OAAOA,EAGTW,KAAuBX,GACrBlB,EAAiBkB,EAAG,QAEpB,MAAMgF,EAAMiE,QAASjJ,EAAEkB,MAAOlB,EAAET,OAC1BuI,EAAUjH,KAAKiB,SAASkD,EAAIxD,QAC5B6J,EAASxK,KAAKiB,SAAS9B,EAAEwB,QAC/B,IAAK,IAAIyC,EAAI,EAAGA,EAAIoH,EAAO/G,SAAUL,EACnC6D,EAAQ7D,GAAK6C,KAAKb,IAAI,EAAGoF,EAAOpH,IAElC,OAAOe,EAGTrE,MAAwBX,GACtBlB,EAAiBkB,EAAG,QAEpB,MAAMgF,EAAMiE,QAASjJ,EAAEkB,MAAOlB,EAAET,OAC1BuI,EAAUjH,KAAKiB,SAASkD,EAAIxD,QAC5B6J,EAASxK,KAAKiB,SAAS9B,EAAEwB,QAC/B,IAAK,IAAIyC,EAAI,EAAGA,EAAIoH,EAAO/G,SAAUL,EACnC6D,EAAQ7D,GAAK6C,KAAKsB,IAAItB,KAAKb,IAAI,EAAGoF,EAAOpH,IAAK,GAEhD,OAAOe,EAGTrE,MAAwBX,EAAMoG,GAG5B,OAFAtH,EAAiB,CAACkB,EAAGoG,GAAI,SAElBvF,KAAK8F,oBACD3G,EAAGoG,EAAGpG,EAAET,MACR,CAAC+L,EAAQ1E,IAAW0E,EAAS,EAAI1E,EAAS0E,EAASA,GAGhE3K,OAAyB4K,EAAOC,GAC9B1M,EAAiB,CAACyM,EAAIC,GAAI,UAE1B,MAAMC,EAAe,IAAIC,aAAaF,EAAEtH,MAClCjD,EAASJ,KAAKiB,SAAS0J,EAAEhK,QACzBmK,EAAW9K,KAAKiB,SAASyJ,EAAG/J,QAClC,IAAK,IAAIyC,EAAI,EAAGA,EAAIhD,EAAOqD,SAAUL,EAAG,CACtC,MAAM2H,EAAI3K,EAAOgD,GAEfwH,EAAaxH,GADX2H,GAAK,EACWD,EAAS1H,GAET0H,EAAS1H,IAAM2H,EAAI,GAGzC,OAAO/K,KAAKgL,WAAWJ,EAAcD,EAAEtK,MAAO,WAGhDP,MAAwByF,EAAME,GAG5B,OAFAxH,EAAiB,CAACsH,EAAGE,GAAI,SAElBzF,KAAK8F,oBACDP,EAAGE,EAAGF,EAAE7G,MAAO,CAACqH,EAAQC,IAAWC,KAAKgF,MAAMlF,EAAQC,IAInElG,aACIoL,MAACA,EAAKC,OAAEA,EAAMC,SAAEA,EAAQzD,KAAEA,EAAIvI,WAAEA,EAAUC,uBAAEA,IAE9C,IAAIuF,EAAS5E,KAAKqL,OAAOH,EAAOC,EAAQC,GAWxC,OATIzD,IAEF/C,EAASiD,MAAOjD,EAAQ+C,IAEtBvI,IACFwF,EACI3F,EAAce,KAAM4E,EAAQxF,EAAYC,IAGvCuF,EAGT9E,OAAOX,EAAagM,EAAkBC,GAEpCnN,EAAiB,CAACkB,EAAGgM,GAAS,UAE9B,MAAMG,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAUN,EAASO,QAAQC,KAC3BC,EAAST,EAASO,QAAQG,IAC1BC,EAAyC,iBAAxBX,EAASY,WAE1BrB,EAAI/I,SAAUwJ,EAASzI,SAAUxD,EAAET,OAEnCuN,EAAe9M,EAAEuD,QAAQ,GACzBwJ,EAAaH,EAAiB5M,EAAEuD,QAAQ,GAAKvD,EAAEuD,QAAQ,GACvDyJ,EAAaJ,EAAiB5M,EAAEuD,QAAQ,GAAK,EAC7C0J,EAAiBL,EAAiB,EAAI5M,EAAEuD,QAAQ,GAChD2J,EAAe1B,EAAEjI,QAAQ,GACzB4J,EAAaP,EAAiBpB,EAAEjI,QAAQ,GAAKiI,EAAEjI,QAAQ,GACvD6J,EAAaR,EAAiBpB,EAAEjI,QAAQ,GAAK,EAC7C8J,EAAiBT,EAAiB,EAAIpB,EAAEjI,QAAQ,GAEhDkB,EAAQ5D,KAAKiB,SAAS9B,EAAEwB,QACxB8L,EAAQzM,KAAKiB,SAASkK,EAAOxK,QAC7B+L,EAAQ/B,EAAEvK,OAEhB,IAAK,IAAIqF,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EAAG,CAC3C,MAAMmH,EAAWnH,EAAIwG,EACfY,EAAWpH,EAAI4G,EACrB,IAAK,IAAIS,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAAI,CAC9C,MAAME,EAAWH,EAAWC,EAAKR,EAC3BW,EAAWH,EAAK1B,EAAS8B,aAAerB,EAC9C,IAAK,IAAIsB,EAAK,EAAGA,EAAK7B,EAAc6B,IAAM,CACxC,MAAMC,EAAKH,EAAWE,EAAK3B,EAC3B,GAAI4B,EAAK,GAAKA,GAAMhC,EAASiC,SAC3B,SAEF,MAAMC,EAAWH,EAAKhC,EAAOzI,QAAQ,GAC/B6K,EAAWX,EAAWQ,EAAKlB,EACjC,IAAK,IAAIsB,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAAI,CAC7C,MAAME,EAAWV,EAAWQ,EAAKjB,EAC3BoB,EAAWH,EAAKpC,EAASwC,YAAclC,EAC7C,IAAK,IAAImC,EAAK,EAAGA,EAAKtC,EAAasC,IAAM,CACvC,MAAMC,EAAKH,EAAWE,EAAKpC,EAC3B,GAAIqC,EAAK,GAAKA,GAAM1C,EAAS2C,QAC3B,SAEF,MACMC,EAAWT,EAAWO,EAAK3B,EACjC,IAAI8B,EAFaX,EAAWO,EAAK1C,EAAOzI,QAAQ,GAGhD,IAAK,IAAIwL,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAAI,CAC/C,MAAME,EAAOxK,EAAMoK,EAAWE,EAAK9B,GACnC,IAAK,IAAIiC,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAC5C3B,EAAMgB,EAAWW,EAAK7B,IAClB4B,EAAO3B,EAAMwB,EAAWI,GAE9BJ,GAAY7C,EAASkD,iBAOjC,OAAO3D,EAAEhH,WAGX7D,OAAOX,EAAagM,EAAkBC,GAEpC,MAAMmD,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAWrD,EAASO,QAAQ+C,MAC5BhD,EAAUN,EAASO,QAAQC,KAC3BC,EAAST,EAASO,QAAQG,IAC1BnB,EAAI/I,SAAmBwJ,EAASzI,SAAUxD,EAAET,OAE5CkF,EAAQ5D,KAAKiB,SAAS9B,EAAEwB,QACxB8L,EAAQzM,KAAKiB,SAASkK,EAAOxK,QAC7B+L,EAAQ/B,EAAEvK,OAEhB,IAAK,IAAIqF,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EAAG,CAC3C,MAAMmH,EAAWnH,EAAItG,EAAEuD,QAAQ,GACzBmK,EAAWpH,EAAIkF,EAAEjI,QAAQ,GAC/B,IAAK,IAAIiM,EAAK,EAAGA,EAAKvD,EAASwD,WAAYD,EAAI,CAC7C,MAAM3B,EAAWH,EAAW8B,EAAKhE,EAAEjI,QAAQ,GACrCmM,EAAWF,EAAKvD,EAAS0D,YAAcL,EAC7C,IAAK,IAAIM,EAAK,EAAGA,EAAKR,EAAaQ,IAAM,CACvC,MAAMC,EAAKH,EAAWE,EAAKP,EAC3B,GAAIQ,EAAK,GAAKA,GAAM5D,EAAS6D,QAC3B,SAEF,MAAM3B,EAAWyB,EAAK5D,EAAOzI,QAAQ,GAC/B6K,EAAWX,EAAWoC,EAAK7P,EAAEuD,QAAQ,GAE3C,IAAK,IAAIoK,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAAI,CAC9C,MAAMY,EAAWV,EAAWF,EAAKnC,EAAEjI,QAAQ,GACrCuK,EAAWH,EAAK1B,EAAS8B,aAAerB,EAC9C,IAAK,IAAIsB,EAAK,EAAGA,EAAK7B,EAAc6B,IAAM,CACxC,MAAMC,EAAKH,EAAWE,EAAK3B,EAC3B,GAAI4B,EAAK,GAAKA,GAAMhC,EAASiC,SAC3B,SAEF,MAAM6B,EAAW5B,EAAWH,EAAKhC,EAAOzI,QAAQ,GAC1CsL,EAAWT,EAAWH,EAAKjO,EAAEuD,QAAQ,GAC3C,IAAK,IAAI8K,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAAI,CAC7C,MAAM2B,EAAWzB,EAAWF,EAAKpC,EAASkD,YACpCX,EAAWH,EAAKpC,EAASwC,YAAclC,EAC7C,IAAK,IAAImC,EAAK,EAAGA,EAAKtC,EAAasC,IAAM,CACvC,MAAMC,EAAKH,EAAWE,EAAKpC,EAC3B,GAAIqC,EAAK,GAAKA,GAAM1C,EAAS2C,QAC3B,SAEF,MAAME,EAAWiB,EAAWrB,EAAK1C,EAAOzI,QAAQ,GAC1C0M,EAAWpB,EAAWF,EAAK1C,EAAS+C,WAC1C,IAAIkB,EAAWpB,EACf,IAAK,IAAIC,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAAI,CAC/C,MAAME,EAAOxK,EAAMwL,EAAWlB,GAC9B,IAAK,IAAIG,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAC5C3B,EAAMyC,EAAWd,IAAOD,EAAO3B,EAAM4C,EAAWhB,GAElDgB,GAAYjE,EAASkD,mBASrC,OAAO3D,EAAEhH,WAGX7D,eACI4K,EAAcS,EACdC,GACFnN,EAAiB,CAACyM,EAAIS,GAAS,kBAE/B,MAAMmE,EAAK1N,SAAmBwJ,EAASmE,QAAS,WAC1CC,EAAWF,EAAGlP,OACd0K,EAAW9K,KAAKiB,SAASyJ,EAAG/J,QAC5B8O,EAAYzP,KAAKiB,SAASkK,EAAOxK,SAChC+O,EAAOC,EAAOC,GAASzE,EAAOzI,SAC/BiK,UACJA,EAASrB,aACTA,EAAYC,YACZA,EAAW4C,WACXA,EAAUd,SACVA,EAAQU,QACRA,EAAOO,YACPA,EAAWvB,UACXA,EAASU,SACTA,EAAQP,aACRA,EAAYU,YACZA,EAAW5B,WACXA,GACEZ,EACEyE,EAASvE,EAAe,EAAIF,EAASO,QAAQG,IAC7CgE,EAAUvE,EAAc,EAAIH,EAASO,QAAQC,KAE7CG,EAAgC,iBAAfC,EACjBC,EAAeqD,EAAG5M,QAAQ,GAC1BwJ,EAAaH,EAAiBuD,EAAG5M,QAAQ,GAAK4M,EAAG5M,QAAQ,GACzDyJ,EAAaJ,EAAiBuD,EAAG5M,QAAQ,GAAK,EAC9C0J,EAAiBL,EAAiB,EAAIuD,EAAG5M,QAAQ,GACjD2J,EAAe3B,EAAGhI,QAAQ,GAC1B4J,EAAaP,EAAiBrB,EAAGhI,QAAQ,GAAKgI,EAAGhI,QAAQ,GACzD6J,EAAaR,EAAiBrB,EAAGhI,QAAQ,GAAK,EAC9C8J,EAAiBT,EAAiB,EAAIrB,EAAGhI,QAAQ,GAEvD,IAAK,IAAI+C,EAAI,EAAGA,EAAIkH,IAAalH,EAC/B,IAAK,IAAIyI,EAAK,EAAGA,EAAKC,IAAcD,EAClC,IAAK,IAAId,EAAK,EAAGA,EAAKC,IAAYD,EAAI,CACpC,MAAMH,EAAWG,EAAKyC,EAChBE,EAAQ9J,KAAKb,IAAI,EAAGa,KAAK+J,KAAK/C,EAAWC,IACzC+C,EACFhK,KAAKsB,IAAIwF,GAAYzB,EAAe2B,GAAYC,GAEpD,IAAK,IAAIY,EAAK,EAAGA,EAAKC,IAAWD,EAAI,CACnC,MAAMH,EAAWG,EAAKgC,EAChBI,EAAQjK,KAAKb,IAAI,EAAGa,KAAK+J,KAAKrC,EAAWC,IACzCuC,EACFlK,KAAKsB,IAAIkG,GAAWlC,EAAcoC,GAAYC,GAElD,IAAIwC,EAAU,EACd,IAAK,IAAItD,EAAKiD,EAAOjD,EAAKmD,IAASnD,EAAI,CACrC,MAAMK,EAAKL,EAAKI,EAAeD,EAE/B,IAAK,IAAIO,EAAK0C,EAAO1C,EAAK2C,IAAS3C,EAAI,CACrC,MACM6C,EACFhE,EAAe5G,EAAI6G,EAAaQ,EAAKP,EAAaiB,EAChD8C,EAAYZ,GAASpE,EAAe,EAAI6B,GAC1CwC,GAASpE,EAAc,GAJhBiC,EAAKI,EAAcD,IAIOiC,EAAQ1B,EAE7C,IAAK,IAAIG,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvC+B,GAFctF,EAASuF,EAAW7D,EAAiB6B,GACpCoB,EAAUa,EAAYjC,KAO3CmB,EAFiBvD,EAAexG,EAAIyG,EAAakB,EAC7CjB,EAAa2B,EAAK1B,EAAiB8B,GAClBkC,GAK7B,OAAOd,EAAG3L,WAGZ7D,eACI4K,EAAcS,EACdC,GACF,MAAMkE,EAAK1N,SAAmBwJ,EAASmE,QAAS,WAC1CC,EAAWF,EAAGlP,QACbmQ,EAAMC,EAAMC,EAAMC,GAAQpB,EAAG5M,QAC9BoI,EAAW9K,KAAKiB,SAASyJ,EAAG/J,SAC3BgQ,EAAMC,EAAMC,EAAMC,GAAQpG,EAAGhI,QAC9B+M,EAAYzP,KAAKiB,SAASkK,EAAOxK,SAChC+O,EAAOC,EAAOC,EAAOmB,GAAS5F,EAAOzI,SACtCiK,UACJA,EAAS4B,YACTA,EAAWjD,aACXA,EAAYC,YACZA,EAAW4C,WACXA,EAAUc,QACVA,EAAO5B,SACPA,EAAQU,QACRA,EAAOO,YACPA,EAAWM,SACXA,EAAQ7B,UACRA,EAASU,SACTA,EAAQqB,YACRA,EAAW5B,aACXA,EAAYU,YACZA,GACExC,EACE4F,EAAWzC,EAAc,EAAInD,EAASO,QAAQ+C,MAC9CmB,EAASvE,EAAe,EAAIF,EAASO,QAAQG,IAC7CgE,EAAUvE,EAAc,EAAIH,EAASO,QAAQC,KAEnD,IAAK,IAAInG,EAAI,EAAGA,EAAIkH,IAAalH,EAC/B,IAAK,IAAIyI,EAAK,EAAGA,EAAKC,IAAcD,EAElC,IAAK,IAAIc,EAAK,EAAGA,EAAKC,IAAWD,EAAI,CACnC,MAAMH,EAAWG,EAAKgC,EAChBC,EAAQhL,KAAKb,IAAI,EAAGa,KAAK+J,KAAKnB,EAAWC,IACzCoC,EACFjL,KAAKsB,IAAIqH,GAAWL,EAAcM,GAAYC,GAGlD,IAAK,IAAI1B,EAAK,EAAGA,EAAKC,IAAYD,EAAI,CACpC,MAAMH,EAAWG,EAAKyC,EAChBE,EAAQ9J,KAAKb,IAAI,EAAGa,KAAK+J,KAAK/C,EAAWC,IACzC+C,EACFhK,KAAKsB,IAAIwF,GAAYzB,EAAe2B,GAAYC,GAEpD,IAAK,IAAIY,EAAK,EAAGA,EAAKC,IAAWD,EAAI,CACnC,MAAMH,EAAWG,EAAKgC,EAChBI,EAAQjK,KAAKb,IAAI,EAAGa,KAAK+J,KAAKrC,EAAWC,IACzCuC,EACFlK,KAAKsB,IAAIkG,GAAWlC,EAAcoC,GAAYC,GAElD,IAAIwC,EAAU,EACd,IAAK,IAAIzB,EAAKsC,EAAOtC,EAAKuC,IAASvC,EAAI,CACrC,MAAMI,EAAKJ,EAAKG,EAAcD,EAE9B,IAAK,IAAI/B,EAAKiD,EAAOjD,EAAKmD,IAASnD,EAAI,CACrC,MAAMK,EAAKL,EAAKI,EAAeD,EAE/B,IAAK,IAAIO,EAAK0C,EAAO1C,EAAK2C,IAAS3C,EAAI,CACrC,MACM6C,EACFM,EAAOlL,EAAImL,EAAOjC,EAAKkC,EAAO/D,EAAKgE,EAAOtD,EACxC8C,EAAYZ,GAASnB,EAAc,EAAIQ,GACzCY,GAASrE,EAAe,EAAI6B,GAC5ByC,GAASrE,EAAc,GALhBiC,EAAKI,EAAcD,IAKOoD,EAAQ7C,EAE7C,IAAK,IAAIG,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvC+B,GAFctF,EAASuF,EAAWhC,GACnBoB,EAAUa,EAAYjC,MAM7CmB,EAASe,EAAO9K,EAAI+K,EAAOxB,EAAKyB,EAAOrD,EAAKsD,EAAO5C,EAAKI,GACpDkC,IAMd,OAAOd,EAAG3L,WAGZ7D,gBAAgBX,EAAauL,EAAcU,GAEzCnN,EAAiB,CAACkB,EAAGuL,GAAK,mBAE1B,MAAMwC,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBtC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBQ,EAAyC,iBAAxBX,EAASY,WAC1BmF,EAAKvP,SAAmBwJ,EAASgG,YAAa,WAE9CtB,EAAU1E,EAASO,QAAQC,KAC3BiE,EAASzE,EAASO,QAAQG,IAC1B5I,EAAOlD,KAAKmD,WAAWhE,GACvBkS,EAAQrR,KAAKmD,WAAWuH,GAC9B,IAAK,IAAIyC,EAAK,EAAGA,EAAK7B,IAAgB6B,EAAI,CACxC,MAAMmE,EAAQrL,KAAKb,IAAI,EAAGa,KAAK+J,MAAMH,EAAS1C,GAAMD,IAC9C+C,EAAQhK,KAAKsB,IACf6D,EAAS2B,WAAY3B,EAASiC,SAAWwC,EAAS1C,GAAMD,GAE5D,IAAK,IAAIW,EAAK,EAAGA,EAAKtC,IAAesC,EAAI,CACvC,MAAM0D,EAAQtL,KAAKb,IAAI,EAAGa,KAAK+J,MAAMF,EAAUjC,GAAMD,IAC/CuC,EAAQlK,KAAKsB,IACf6D,EAASqC,UAAWrC,EAAS2C,QAAU+B,EAAUjC,GAAMD,GAE3D,IAAK,IAAIM,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAC3C,IAAK,IAAIG,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAAI,CAEhD,IAAI+B,EAAU,EACd,IAAK,IAAI3K,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EACxC,IAAK,IAAIqH,EAAKwE,EAAOxE,EAAKmD,IAASnD,EAAI,CACrC,MAAMM,EAAKD,EAAKL,EAAKI,EAAe2C,EACpC,IAAK,IAAIrC,EAAK+D,EAAO/D,EAAK2C,IAAS3C,EAAI,CACrC,MAAMM,EAAKD,EAAKL,EAAKI,EAAckC,EAEjCM,GADErE,EAEE7I,EAAK1C,IAAIiF,EAAG2H,EAAIU,EAAII,GAAMmD,EAAM7Q,IAAIiF,EAAGqH,EAAIU,EAAIa,GAG/CnL,EAAK1C,IAAIiF,EAAGyI,EAAId,EAAIU,GAAMuD,EAAM7Q,IAAIiF,EAAG4I,EAAIvB,EAAIU,IAK3D2D,EAAGvQ,IAAIwP,EAASjD,EAAIU,EAAIK,EAAIG,KAKpC,OAAO8C,EAAGxN,WAGZ7D,gBAAgBX,EAAauL,EAAcU,GAEzC,MAAM0D,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBW,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YAEvBiG,EAAK5P,SAAmBwJ,EAASgG,YAAa,WAC9CK,EAAWD,EAAGpR,QACbsR,EAAMC,EAAMC,EAAMC,GAAQL,EAAG9O,QAC9BoI,EAAW9K,KAAKiB,SAASyJ,EAAG/J,SAC3BgQ,EAAMC,EAAMC,EAAMC,GAAQpG,EAAGhI,QAC9BoP,EAAU9R,KAAKiB,SAAS9B,EAAEwB,SACzBoR,EAAKC,EAAKC,EAAKC,GAAO/S,EAAEuD,QAEzBsO,EAAW5F,EAASO,QAAQ+C,MAC5BoB,EAAU1E,EAASO,QAAQC,KAC3BiE,EAASzE,EAASO,QAAQG,IAEhC,IAAK,IAAIiD,EAAK,EAAGA,EAAKR,IAAeQ,EAAI,CACvC,MAAMoD,EAAQlM,KAAKb,IAAI,EAAGa,KAAK+J,MAAMgB,EAAWjC,GAAMD,IAChDoC,EAAQjL,KAAKsB,IACf6D,EAASwD,UAAWxD,EAAS6D,QAAU+B,EAAWjC,GAAMD,GACtDxB,EAAWyB,EAAK2C,EAEtB,IAAK,IAAIvE,EAAK,EAAGA,EAAK7B,IAAgB6B,EAAI,CACxC,MAAMmE,EAAQrL,KAAKb,IAAI,EAAGa,KAAK+J,MAAMH,EAAS1C,GAAMD,IAC9C+C,EAAQhK,KAAKsB,IACf6D,EAAS2B,WACR3B,EAASiC,SAAWwC,EAAS1C,GAAMD,GAClCgC,EAAW/B,EAAKwE,EAAOrE,EAE7B,IAAK,IAAIO,EAAK,EAAGA,EAAKtC,IAAesC,EAAI,CACvC,MAAM0D,EAAQtL,KAAKb,IAAI,EAAGa,KAAK+J,MAAMF,EAAUjC,GAAMD,IAC/CuC,EAAQlK,KAAKsB,IACf6D,EAASqC,UACRrC,EAAS2C,QAAU+B,EAAUjC,GAAMD,GAClCK,EAAWJ,EAAK+D,EAAO1C,EAE7B,IAAK,IAAIhB,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAAI,CAC/C,MAAMmB,EAAWnB,EAAK2D,EAAO5D,EAE7B,IAAK,IAAII,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAAI,CAChD,IAAI+B,EAAU,EACd,IAAK,IAAI3K,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EAAG,CAC3C,MAAMmH,EAAWnH,EAAIsM,EACflF,EAAWpH,EAAIkL,EAErB,IAAK,IAAIhC,EAAKwD,EAAOxD,EAAKuC,IAASvC,EAAI,CACrC,MACMpB,GADKwB,EAAKJ,EAAKG,EAAckC,GACbgB,EAAMpF,EACtBI,EAAW2B,EAAKiC,EAAO/D,EAE7B,IAAK,IAAIC,EAAKwE,EAAOxE,EAAKmD,IAASnD,EAAI,CACrC,MACMkB,GADKb,EAAKL,EAAKI,EAAe2C,GACdoC,EAAM1E,EACtBG,EAAWZ,EAAK+D,EAAO7D,EAE7B,IAAK,IAAIQ,EAAK+D,EAAO/D,EAAK2C,IAAS3C,EAAI,CACrC,MAEM2B,EAAW3B,EAAKsD,EAAOpD,EAE7B0C,GACI0B,GALOjE,EAAKL,EAAKI,EAAckC,GACboC,EAAMlE,EAILE,GAAMpD,EAASqE,EAAWd,MAKzDoD,EAASpC,EAAWhB,GAAM+B,MAMpC,OAAOoB,EAAG7N,WAGZ7D,sBACIoL,MAACA,EAAKC,OAAEA,EAAMC,SAAEA,EAAQzD,KAAEA,EAAIvI,WAAEA,EAAUC,uBAAEA,IAE9C,IAAIuF,EAAS5E,KAAKoS,gBAAgBlH,EAAOC,EAAQC,GAYjD,OAVIzD,IAGF/C,EAASiD,MAAOjD,EAAQ+C,IAEtBvI,IACFwF,EACI3F,EAAce,KAAM4E,EAAQxF,EAAYC,IAGvCuF,EAGT9E,gBACIX,EAAagM,EACbC,GACFnN,EAAiB,CAACkB,EAAGgM,GAAS,mBAE9B,MAAMG,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAUN,EAASO,QAAQC,KAC3BC,EAAST,EAASO,QAAQG,IAC1BuG,EAAQjH,EAASkD,YAAclD,EAAS+C,WACxCxD,EAAI/I,SAAUwJ,EAASzI,SAAUxD,EAAET,OACnCkF,EAAQ5D,KAAKiB,SAAS9B,EAAEwB,QACxB8L,EAAQzM,KAAKiB,SAASkK,EAAOxK,QAC7B+L,EAAQ/B,EAAEvK,OAEhB,IAAK,IAAIqF,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EAAG,CAC3C,MAAMmH,EAAWnH,EAAItG,EAAEuD,QAAQ,GACzBmK,EAAWpH,EAAIkF,EAAEjI,QAAQ,GAC/B,IAAK,IAAIoK,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAAI,CAC9C,MAAME,EAAWH,EAAWC,EAAKnC,EAAEjI,QAAQ,GACrCuK,EAAWH,EAAK1B,EAAS8B,aAAexB,EAC9C,IAAK,IAAIyB,EAAK,EAAGA,EAAK7B,IAAgB6B,EAAI,CACxC,MAAMC,EAAKH,EAAWE,EAAK3B,EAC3B,GAAI4B,EAAK,GAAKA,GAAMhC,EAASiC,SAC3B,SAEF,MAAMC,EAAWH,EAAKhC,EAAOzI,QAAQ,GAC/B6K,EAAWX,EAAWQ,EAAKjO,EAAEuD,QAAQ,GAC3C,IAAK,IAAI8K,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAAI,CAC7C,MAAME,EAAWV,EAAWQ,EAAK7C,EAAEjI,QAAQ,GACrCiL,EAAWH,EAAKpC,EAASwC,YAAc/B,EAC7C,IAAK,IAAIgC,EAAK,EAAGA,EAAKtC,IAAesC,EAAI,CACvC,MAAMC,EAAKH,EAAWE,EAAKpC,EAC3B,GAAIqC,EAAK,GAAKA,GAAM1C,EAAS2C,QAC3B,SAEF,MAAMmB,EAAW5B,EAAWO,EAAK1C,EAAOzI,QAAQ,GAC1CsL,EAAWT,EAAWO,EAAK1C,EAAS+C,WAC1C,IAAIgB,EAAWzB,EACXO,EAAWiB,EACf,IAAK,IAAIhB,EAAK,EAAGA,EAAK9C,EAAS+C,aAAcD,EAAI,CAC/C,MAAME,EAAOxK,EAAMoK,EAAWE,GAC9B,IAAK,IAAIoE,EAAI,EAAGA,EAAID,IAASC,EAC3B5F,EAAMyC,EAAWmD,IAAMlE,EAAO3B,EAAMwB,EAAWqE,GAEjDnD,GAAYkD,EACZpE,GAAYoE,OAQxB,OAAO1H,EAAEhH,WAGX7D,wBACI4K,EAAcS,EACdC,GACFnN,EAAiB,CAACyM,EAAIS,GAAS,2BAE/B,MAAMmE,EAAK1N,SAAmBwJ,EAASmE,QAAS,WAC1CC,EAAWF,EAAGlP,QACbmQ,EAAMC,EAAMC,GAAQnB,EAAG5M,QACxBoI,EAAW9K,KAAKiB,SAASyJ,EAAG/J,SAC3BgQ,EAAMC,EAAMC,GAAQnG,EAAGhI,QACxB+M,EAAYzP,KAAKiB,SAASkK,EAAOxK,SAChC+O,EAAOC,EAAOC,GAASzE,EAAOzI,SAC/BiK,UACJA,EAASrB,aACTA,EAAYC,YACZA,EAAW4C,WACXA,EAAUd,SACVA,EAAQU,QACRA,EAAOO,YACPA,EAAWvB,UACXA,EAASU,SACTA,EAAQP,aACRA,EAAYU,YACZA,GACExC,EACEyE,EAASvE,EAAe,EAAIF,EAASO,QAAQG,IAC7CgE,EAAUvE,EAAc,EAAIH,EAASO,QAAQC,KAC7CyG,EAAQ/D,EAAcH,EAE5B,IAAK,IAAI1I,EAAI,EAAGA,EAAIkH,IAAalH,EAC/B,IAAK,IAAIyI,EAAK,EAAGA,EAAKC,IAAcD,EAClC,IAAK,IAAId,EAAK,EAAGA,EAAKC,IAAYD,EAAI,CACpC,MAAMH,EAAWG,EAAKyC,EAChBE,EAAQ9J,KAAKb,IAAI,EAAGa,KAAK+J,KAAK/C,EAAWC,IACzC+C,EACFhK,KAAKsB,IAAIwF,GAAYzB,EAAe2B,GAAYC,GAEpD,IAAK,IAAIY,EAAK,EAAGA,EAAKC,IAAWD,EAAI,CACnC,MAAMH,EAAWG,EAAKgC,EAChBI,EAAQjK,KAAKb,IAAI,EAAGa,KAAK+J,KAAKrC,EAAWC,IACzCuC,EACFlK,KAAKsB,IAAIkG,GAAWlC,EAAcoC,GAAYC,GAElD,IAAIwC,EAAU,EACd,IAAK,IAAItD,EAAKiD,EAAOjD,EAAKmD,IAASnD,EAAI,CACrC,MAAMK,EAAKL,EAAKI,EAAeD,EAE/B,IAAK,IAAIO,EAAK0C,EAAO1C,EAAK2C,IAAS3C,EAAI,CACrC,MACM6C,EAAWM,EAAOlL,EAAImL,EAAO9D,EAAK+D,EAAOrD,EACzC8C,EAAYZ,GAASpE,EAAe,EAAI6B,GAC1CwC,GAASpE,EAAc,GAHhBiC,EAAKI,EAAcD,IAGOiC,EAAQ1B,EAE7C,IAAK,IAAIqE,EAAK,EAAGA,EAAKF,IAASE,EAAI,CAIjCnC,GAFctF,EAASuF,GADZnC,EAAKmE,EAAQE,IAET9C,EAAUa,EAAYiC,KAK3C/C,EAASe,EAAO9K,EAAI+K,EAAOpD,EAAKqD,EAAO3C,EAAKI,GAAMkC,GAK1D,OAAOd,EAAG3L,WAGZ7D,yBACIX,EAAauL,EAAcU,GAC7BnN,EAAiB,CAACkB,EAAGuL,GAAK,4BAE1B,MAAMwC,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBtC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB4F,EAAKvP,SAAmBwJ,EAASgG,YAAa,WAE9CtB,EAAU1E,EAASO,QAAQC,KAC3BiE,EAASzE,EAASO,QAAQG,IAC1BuG,EAAQjH,EAASkD,YAAclD,EAAS+C,WAExCjL,EAAOlD,KAAKmD,WAAWhE,GACvBkS,EAAQrR,KAAKmD,WAAWuH,GAC9B,IAAK,IAAIyC,EAAK,EAAGA,EAAK7B,IAAgB6B,EAAI,CACxC,MAAMmE,EAAQrL,KAAKb,IAAI,EAAGa,KAAK+J,MAAMH,EAAS1C,GAAMD,IAC9C+C,EAAQhK,KAAKsB,IACf6D,EAAS2B,WAAY3B,EAASiC,SAAWwC,EAAS1C,GAAMD,GAE5D,IAAK,IAAIW,EAAK,EAAGA,EAAKtC,IAAesC,EAAI,CACvC,MAAM0D,EAAQtL,KAAKb,IAAI,EAAGa,KAAK+J,MAAMF,EAAUjC,GAAMD,IAC/CuC,EAAQlK,KAAKsB,IACf6D,EAASqC,UAAWrC,EAAS2C,QAAU+B,EAAUjC,GAAMD,GAE3D,IAAK,IAAIS,EAAK,EAAGA,EAAKjD,EAASkD,cAAeD,EAAI,CAChD,MAAMH,EAAKjI,KAAKuM,MAAMnE,EAAKgE,GACrBE,EAAKlE,EAAKgE,EAEhB,IAAIjC,EAAU,EACd,IAAK,IAAI3K,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EACxC,IAAK,IAAIqH,EAAKwE,EAAOxE,EAAKmD,IAASnD,EAAI,CACrC,MAAMM,EAAKD,EAAKL,EAAKI,EAAe2C,EACpC,IAAK,IAAIrC,EAAK+D,EAAO/D,EAAK2C,IAAS3C,EAAI,CACrC,MAAMM,EAAKD,EAAKL,EAAKI,EAAckC,EACnCM,GAAWlN,EAAK1C,IAAIiF,EAAG2H,EAAIU,EAAII,GAAMmD,EAAM7Q,IAAIiF,EAAGqH,EAAIU,EAAIa,IAIhE8C,EAAGvQ,IAAIwP,EAASjD,EAAIU,EAAIK,EAAIqE,KAIlC,OAAOpB,EAAGxN,WAGZ7D,KAAuBX,EAAMsT,GAE3B,OADAxU,EAAiBkB,EAAG,QACbL,EAAKkB,KAAKmD,WAAWhE,GAAIsT,GAGlC3S,OAAyBX,EAAMuT,EAAmB3P,GAChD9E,EAAiB,CAACkB,EAAGuT,GAAU,UAE/B,MAAMC,EAAqBxT,EAAEkB,MAAM6D,QAC7B0O,EAAgB5S,KAAKiB,SAASyR,EAAQ/R,QAC5CgS,EAAS5P,GAAQ6P,EAAcnP,OAC/B,MAAMmB,EAAShD,SAAU+Q,EAAUxT,EAAET,OAC/BwE,EAAOlD,KAAKmD,WAAWhE,GAE7B,IAAK,IAAIiE,EAAI,EAAGA,EAAIwB,EAAOvB,OAAQD,EAAG,CACpC,MAAMI,EAASoB,EAAOrB,WAAWH,GAE3ByP,EAAwBrP,EAAOU,QACrC2O,EAAY9P,GAAQ6P,EAAcpP,EAAOT,IAEzC,MAAM+P,EAAgB5P,EAAK6P,WAAWF,GACtCjO,EAAOxE,OAAOgD,GAAKF,EAAK9C,OAAO0S,GAEjC,OAAOlO,EAAOjB,WAGhB7D,eACIX,EAAM6T,EAAsBC,GAC9BhV,EAAiB,CAACkB,GAAI,kBAEtB,MAAMsJ,EAAOuK,EAAWE,OAAO,CAAC3N,EAAGE,IAAMF,EAAIE,GAEvC0N,EAAW1S,eAAa2S,YAAYjU,EAAEkB,MAAO2S,EAAYvK,GACzD4K,EACF5S,eAAa6S,YAAYH,EAAS1P,OAAQuP,EAAWvP,QACnD8P,EACF9S,eAAa+S,oBAAoBrU,EAAEkB,MAAO2S,EAAYvK,GACpDgL,EACFhT,eAAaiT,oBAAoBT,EAAOD,EAAWvP,QACjDkQ,EACFlT,eAAamT,aAAaL,EAAkBN,EAAOD,EAAWvP,QAElE,OAAOoQ,YAAa1U,EAAEkF,QAAQ8O,GAAWE,GAC7BhP,QAAQkP,GACRrP,MAAMuP,EAAkBE,GAG9B7T,OACJX,EAAaiM,EACb0I,GACF7V,EAAiBkB,EAAG,UAEpB,MAAM2P,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBY,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBsI,EAAuB3I,EAAS2I,qBAChCC,EAAwB5I,EAAS4I,sBACjCC,EAAuB7I,EAAS6I,qBAChCxF,EAAWrD,EAASO,QAAQ+C,MAC5B7C,EAAST,EAASO,QAAQG,IAC1BJ,EAAUN,EAASO,QAAQC,KAE3BsI,EACY,QAAbJ,EAAqBK,OAAOC,kBACPD,OAAOE,kBAE3BvC,EAAU9R,KAAKiB,SAAS9B,EAAEwB,QAC1B2T,EAAS1S,SAAUwJ,EAASzI,SAAUxD,EAAET,OACxC6V,EAAaD,EAAOlU,OAEpBoU,EAAqBpJ,EAASzI,SAAS,GAAKyI,EAASzI,SAAS,GAChEyI,EAASzI,SAAS,GAAKyI,EAASzI,SAAS,GACvC8R,EACFrJ,EAASzI,SAAS,GAAKyI,EAASzI,SAAS,GAAKyI,EAASzI,SAAS,GAC9D+R,EAAmBtJ,EAASzI,SAAS,GAAKyI,EAASzI,SAAS,GAC5DgS,EAAmBvJ,EAASzI,SAAS,GAE3C,IAAK,IAAIiS,EAAQ,EAAGA,EAAQxJ,EAASuB,YAAaiI,EAAO,CACvD,MAAMC,EAAoBD,EAAQJ,EAC5BM,EAAmBF,EAAQzV,EAAEuD,QAAQ,GAC3C,IAAK,IAAIqS,EAAU,EAAGA,EAAU3J,EAAS+C,aAAc4G,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS5J,EAASwD,WAAYoG,EAAQ,CACzD,MAAMC,EAAeD,EAASlG,EAAcL,EAC5C,IAAIyG,EAAYD,EAChB,KAAOC,EAAY,GACjBA,GAAa1G,EAEf,MAAM2G,EACFlP,KAAKsB,IAAI6D,EAAS6D,QAAS8E,EAAuBkB,GAChDG,EACFP,EAAoBG,EAASP,EACjC,IAAK,IAAIY,EAAO,EAAGA,EAAOjK,EAAS2B,YAAasI,EAAM,CACpD,MAAMC,EAAaD,EAAOnI,EAAerB,EACzC,IAAI0J,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAW/J,EAEb,MAAMgK,EACFvP,KAAKsB,IAAI6D,EAASiC,SAAU2G,EAAwBsB,GAClDG,EAAkBL,EAAoBC,EAAOX,EACnD,IAAK,IAAIgB,EAAO,EAAGA,EAAOtK,EAASqC,WAAYiI,EAAM,CACnD,MAAMC,EAAaD,EAAO9H,EAAclC,EACxC,IAAIkK,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAWnK,EAEb,MAAMoK,EACF5P,KAAKsB,IAAI6D,EAAS2C,QAASkG,EAAuB0B,GAEhDG,EAAkBL,EAAkBC,EAAOf,EACjD,IAAIoB,EAAc7B,EACd8B,EAAW,EACXC,EAAQ,EACZ,IAAK,IAAIC,EAAShB,EAAWgB,EAASf,EACjCe,GAAU1H,EAAe,CAC5B,MAAM2H,EAAerB,EAAmBoB,EAAS/W,EAAEuD,QAAQ,GAC3D,IAAK,IAAI0T,EAAOb,EAASa,EAAOZ,EAC3BY,GAAQ5K,EAAgB,CAC3B,MAAM6K,EAAaF,EAAeC,EAAOjX,EAAEuD,QAAQ,GACnD,IAAK,IAAI4T,EAAOV,EAASU,EAAOT,EAC3BS,GAAQ7K,EAAe,CAC1B,MACM8K,EAAQzE,EADKuE,EAAaC,EAAOnX,EAAEuD,QAAQ,GACdqS,GAOnC,GANkB,QAAbjB,GAAsByC,EAAQR,EACjCA,EAAcQ,EACQ,QAAbzC,IACTkC,GAAYO,EACZN,KAEEO,MAAMT,GACR,MAGJ,GAAIS,MAAMT,GACR,MAGJ,GAAIS,MAAMT,GACR,MAIJxB,EADqBuB,EAAkBf,GAEtB,QAAbjB,EAAqBkC,EAAWC,EAAQF,KAMtD,OAAOzB,EAAO3Q,WAGhB7D,UAAUX,EAAaiM,GAGrB,OAFAnN,EAAiBkB,EAAG,aAEba,KAAKyW,OAAOtX,EAAGiM,EAAU,OAAOsL,UAGzC5W,kBACI4K,EAAcvL,EAAaiM,GAC7BnN,EAAiB,CAACyM,EAAIvL,GAAI,qBAE1B,MAAM2P,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBW,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBsI,EAAuB3I,EAAS2I,qBAChCC,EAAwB5I,EAAS4I,sBACjCC,EAAuB7I,EAAS6I,qBAChCxF,EAAWsF,EAAuB,EAAI3I,EAASO,QAAQ+C,MACvDhD,EAAUuI,EAAuB,EAAI7I,EAASO,QAAQC,KACtDC,EAASmI,EAAwB,EAAI5I,EAASO,QAAQG,IACtDwD,EAAK1N,SAAmBzC,EAAEkB,MAAO,WAEjCsW,EAAgB,GAAKpI,EAAcjD,EAAeC,GAElD8F,EAAQrR,KAAKmD,WAAWuH,GAE9B,IAAK,IAAIkK,EAAQ,EAAGA,EAAQxJ,EAASuB,YAAaiI,EAChD,IAAK,IAAIG,EAAU,EAAGA,EAAU3J,EAAS+C,aAAc4G,EACrD,IAAK,IAAI6B,EAAU,EAAGA,EAAUxL,EAAS6D,UAAW2H,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQzL,EAASiC,WAAYwJ,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ1L,EAAS2C,UAAW+I,EAAO,CAErD,MAAMC,EAAgBH,EAAUnI,EAC1BuI,EAAcH,EAAQhL,EACtBoL,EAAcH,EAAQpL,EAC5B,IAAI0E,EAAU,EACd,IAAK,IAAI8G,EAAS,EAAGA,EAASnD,EACzBmD,GAAU1I,EAAe,CAC5B,MAAM2I,GAAWJ,EAAgBG,GAAUpI,EAC3C,KAAIqI,EAAU,GAAKA,GAAW/L,EAASwD,UACnC3I,KAAK6B,MAAMqP,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAOpD,EACrBoD,GAAQ5L,EAAgB,CAC3B,MAAM6L,GAASL,EAAcI,GAAQlK,EACrC,KAAImK,EAAQ,GAAKA,GAASjM,EAAS2B,WAC/B9G,KAAK6B,MAAMuP,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAOrD,EACrBqD,GAAQ7L,EAAe,CAC1B,MAAM8L,GAASN,EAAcK,GAAQ1J,EACjC2J,EAAQ,GAAKA,GAASnM,EAASqC,UAC/BxH,KAAK6B,MAAMyP,KAAWA,IAM1BnH,GADIiB,EAAM7Q,IAAIoU,EAAOuC,EAASE,EAAOE,EAAOxC,MAKlDzF,EAAG1O,IACCwP,EAAUuG,EAAe/B,EAAOgC,EAASC,EAAOC,EAChD/B,GAMd,OAAOzF,EAAG3L,WAGZ7D,UAAUX,EAAaiM,GAGrB,OAFAnN,EAAiBkB,EAAG,aAEba,KAAKyW,OAAOtX,EAAGiM,EAAU,OAAOsL,UAGjC5W,mBAAmBX,EAAaiM,GAEtC,MAAMoM,EAAe5V,SAAUwJ,EAASzI,SAAU,SAC5CmM,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBY,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBsI,EAAuB3I,EAAS2I,qBAChCC,EAAwB5I,EAAS4I,sBACjCC,EAAuB7I,EAAS6I,qBAChCxF,EAAWrD,EAASO,QAAQ+C,MAC5B7C,EAAST,EAASO,QAAQG,IAC1BJ,EAAUN,EAASO,QAAQC,KAE3B1I,EAAOlD,KAAKmD,WAAWhE,GAC7B,IAAK,IAAIyV,EAAQ,EAAGA,EAAQxJ,EAASuB,YAAaiI,EAChD,IAAK,IAAIG,EAAU,EAAGA,EAAU3J,EAAS+C,aAAc4G,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS5J,EAASwD,WAAYoG,EAAQ,CACzD,MAAMC,EAAeD,EAASlG,EAAcL,EAC5C,IAAIyG,EAAYD,EAChB,KAAOC,EAAY,GACjBA,GAAa1G,EAEf,MAAM2G,EACFlP,KAAKsB,IAAI6D,EAAS6D,QAAS8E,EAAuBkB,GACtD,IAAK,IAAII,EAAO,EAAGA,EAAOjK,EAAS2B,YAAasI,EAAM,CACpD,MAAMC,EAAaD,EAAOnI,EAAerB,EACzC,IAAI0J,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAW/J,EAEb,MAAMgK,EACFvP,KAAKsB,IAAI6D,EAASiC,SAAU2G,EAAwBsB,GACxD,IAAK,IAAII,EAAO,EAAGA,EAAOtK,EAASqC,WAAYiI,EAAM,CACnD,MAAMC,EAAaD,EAAO9H,EAAclC,EACxC,IAAIkK,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAWnK,EAEb,MAAMoK,EACF5P,KAAKsB,IAAI6D,EAAS2C,QAASkG,EAAuB0B,GAGtD,IAAI8B,EAAWtD,OAAOC,kBAClBsD,GAAe,EAEnB,IAAK,IAAIxB,EAAShB,EAAWgB,EAASf,EACjCe,GAAU1H,EAAe,CAC5B,MAAM0I,EAAShB,EAASjB,EACxB,IAAK,IAAImB,EAAOb,EAASa,EAAOZ,EAC3BY,GAAQ5K,EAAgB,CAC3B,MAAM4L,EAAOhB,EAAOd,EACpB,IAAK,IAAIgB,EAAOV,EAASU,EAAOT,EAC3BS,GAAQ7K,EAAe,CAC1B,MAAM6L,EAAOhB,EAAOX,EACdY,EAAQrT,EAAK1C,IAAIoU,EAAOsB,EAAQE,EAAME,EAAMvB,GAC9CwB,GAASkB,IACXA,EAAWlB,EACXmB,EAAcR,EAASlD,EACfC,EACJmD,EAAOpD,EAAwBsD,KAM3CE,EAAa5W,IAAI8W,EAAa9C,EAAOI,EAAQK,EAAMK,EAAMX,KAMnE,OAAOyC,EAAa7T,WAGtB7D,kBACI4K,EAAcvL,EAAawL,EAC3BS,GACFnN,EAAiB,CAACkB,EAAGwL,GAAI,qBAEzB,MAAM6M,EAAexX,KAAK2X,mBAAmBxY,EAAGiM,GAC1C0D,EAAc1D,EAAS0D,YACvB5B,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBY,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBsI,EAAuB3I,EAAS2I,qBAChCC,EAAwB5I,EAAS4I,sBACjCC,EAAuB7I,EAAS6I,qBAChCxF,EAAWsF,EAAuB,EAAI3I,EAASO,QAAQ+C,MACvDhD,EAAUuI,EAAuB,EAAI7I,EAASO,QAAQC,KACtDC,EAASmI,EAAwB,EAAI5I,EAASO,QAAQG,IACtDwD,EAAK1N,SAAmBzC,EAAEkB,MAAO,WAEjCuX,EAAY5X,KAAKmD,WAAWqU,GAC5BnG,EAAQrR,KAAKmD,WAAWuH,GAE9B,IAAK,IAAIkK,EAAQ,EAAGA,EAAQxJ,EAASuB,YAAaiI,EAChD,IAAK,IAAIG,EAAU,EAAGA,EAAU3J,EAAS+C,aAAc4G,EACrD,IAAK,IAAI6B,EAAU,EAAGA,EAAUxL,EAAS6D,UAAW2H,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQzL,EAASiC,WAAYwJ,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ1L,EAAS2C,UAAW+I,EAAO,CAErD,MAAMC,EAAgBH,EAAUnI,EAC1BuI,EAAcH,EAAQhL,EACtBoL,EAAcH,EAAQpL,EAC5B,IAAI0E,EAAU,EACd,IAAK,IAAI8G,EAAS,EAAGA,EAASnD,EACzBmD,GAAU1I,EAAe,CAC5B,MAAM2I,GAAWJ,EAAgBG,GAAUpI,EAC3C,KAAIqI,EAAU,GAAKA,GAAW/L,EAASwD,UACnC3I,KAAK6B,MAAMqP,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAOpD,EACrBoD,GAAQ5L,EAAgB,CAC3B,MAAM6L,GAASL,EAAcI,GAAQlK,EACrC,KAAImK,EAAQ,GAAKA,GAASjM,EAAS2B,WAC/B9G,KAAK6B,MAAMuP,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAOrD,EACrBqD,GAAQ7L,EAAe,CAC1B,MAAM8L,GAASN,EAAcK,GAAQ1J,EACrC,GAAI2J,EAAQ,GAAKA,GAASnM,EAASqC,UAC/BxH,KAAK6B,MAAMyP,KAAWA,EACxB,SAGF,MAQMM,EARS9D,EACPC,EAAwBC,EAC5B,EACA2D,EAAUpX,IAAIoU,EAAOuC,EAASE,EAAOE,EAAOxC,KAE5CmC,EAASlD,EAAwBC,EACjCmD,EAAOnD,EAAuBqD,EAED,EAAI,EACxB,IAATO,IAMJzH,GADIiB,EAAM7Q,IAAIoU,EAAOuC,EAASE,EAAOE,EAAOxC,GACzB8C,KAIzBvI,EAAG1O,IAAIwP,EAASwE,EAAOgC,EAASC,EAAOC,EAAO/B,GAMxD,OAAOzF,EAAG3L,WAGZ7D,eACIX,EAAa2Y,EAAmBC,EAChCC,GACF/Z,EAAiBkB,EAAG,kBAEpB,MAAOyV,EAAOqD,EAAWC,EAAUC,GAAehZ,EAAEkB,MAC9CyR,EAAU9R,KAAKiB,SAAS9B,EAAEwB,QAC1BiE,EAAS,IAAIiG,aACfrM,OAAK8J,cAAc,CAACsM,EAAOkD,EAAWC,EAAUI,KAE9CC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAElD,IAAIO,EAAY,EAChB,MAAMC,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GAChD,IAAK,IAAI5S,EAAI,EAAGA,EAAImP,EAAOnP,IACzB,IAAK,IAAIgT,EAAI,EAAGA,EAAIX,EAAWW,IAAK,CAClC,MAAMC,EAAgBH,EAAwBE,EACxCE,EAAiB1S,KAAK6B,MAAM4Q,GAC5BE,EAAUF,EAAgBC,EAC1BE,EAAgB5S,KAAKsB,IAAI0Q,EAAY,EAAGhS,KAAK+J,KAAK0I,IAClDI,EAAerT,EAAItG,EAAEuD,QAAQ,GAAKiW,EAAiBxZ,EAAEuD,QAAQ,GAC7DqW,EAAetT,EAAItG,EAAEuD,QAAQ,GAAKmW,EAAgB1Z,EAAEuD,QAAQ,GAClE,IAAK,IAAIsW,EAAI,EAAGA,EAAIjB,EAAUiB,IAAK,CACjC,MAAMC,EAAgBT,EAAwBQ,EACxCE,EAAiBjT,KAAK6B,MAAMmR,GAC5BE,EAAUF,EAAgBC,EAC1BE,EACFnT,KAAKsB,IAAI2Q,EAAW,EAAGjS,KAAK+J,KAAKiJ,IAC/BI,EAAgBP,EAAeI,EAAiB/Z,EAAEuD,QAAQ,GAC1D4W,EAAgBP,EAAeG,EAAiB/Z,EAAEuD,QAAQ,GAC1D6W,EAAiBT,EAAeM,EAAgBja,EAAEuD,QAAQ,GAC1D8W,EAAiBT,EAAeK,EAAgBja,EAAEuD,QAAQ,GAChE,IAAK,IAAIhB,EAAI,EAAGA,EAAIyW,EAAazW,IAAK,CAIpC,MAAM+X,EAAU3H,EAAQuH,EAAgB3X,GAClCgY,EAAa5H,EAAQwH,EAAgB5X,GAIrCoK,EAAM2N,GAHK3H,EAAQyH,EAAiB7X,GAGR+X,GAAWN,EAEvCQ,EAAW7N,GADF4N,GAHK5H,EAAQ0H,EAAiB9X,GAGFgY,GAAcP,EACxBrN,GAAO8M,EAExChU,EAAO0T,KAAeqB,IAK9B,OAAO3W,SAAU4B,EAAQ,CAACgQ,EAAOkD,EAAWC,EAAUI,IAGxDrY,uBAAuB4K,EAAcvL,EAAa6Y,GAChD/Z,EAAiB,CAACyM,EAAIvL,GAAI,0BAE1B,MAAOyV,EAAOgF,EAASC,EAAQC,GAAS3a,EAAEkB,QACjC0Z,EAASC,GAAUtP,EAAGrK,MAEzBiU,EAAS,IAAIzJ,aAAa+J,EAAQgF,EAAUC,EAASC,GAOrDG,EAAmC,CACtCjC,GAAgB+B,EAAU,EAAKH,EAAU,EAAIA,EAC7C5B,GAAgBgC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtClC,GAAgB+B,EAAU,EAAKA,EAAU,EAAIA,EAC7C/B,GAAgBgC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAMhDpP,EAAW9K,KAAKiB,SAASyJ,EAAG/J,QAClC,IAAI6H,EAAS,EACb,IAAK,IAAI/C,EAAI,EAAGA,EAAImP,EAAOnP,IAAK,CAC9B,MAAM4U,EAAU5U,EAAItG,EAAEuD,QAAQ,GAC9B,IAAK,IAAI+V,EAAI,EAAGA,EAAIsB,EAAStB,IAAK,CAChC,MAAM6B,EAAM7B,EAAI0B,EACVI,EAActU,KAAK6B,MAAMwS,GACzBE,EAAiBvU,KAAKsB,IAAItB,KAAK+J,KAAKsK,GAAMV,EAAU,GAEpDa,EAAeJ,EAAUE,EAAcpb,EAAEuD,QAAQ,GACjDgY,EAAkBL,EAAUG,EAAiBrb,EAAEuD,QAAQ,GAEvDiY,EAAUL,EAAMC,EAChBK,EAAiB,EAAMD,EAC7B,IAAK,IAAI3B,EAAI,EAAGA,EAAIgB,EAAQhB,IAAK,CAC/B,MAAM6B,EAAM7B,EAAIoB,EACVU,EAAe7U,KAAK6B,MAAM+S,GAC1BE,EAAgB9U,KAAKsB,IAAItB,KAAK+J,KAAK6K,GAAMhB,EAAS,GAClDmB,EAAUH,EAAMC,EAChBG,EAAiB,EAAMD,EAEvBE,EAAkBT,EAAeK,EAAe3b,EAAEuD,QAAQ,GAC1DyY,EAAmBV,EAAeM,EAAgB5b,EAAEuD,QAAQ,GAC5D0Y,EACFV,EAAkBI,EAAe3b,EAAEuD,QAAQ,GACzC2Y,EACFX,EAAkBK,EAAgB5b,EAAEuD,QAAQ,GAE1C4Y,EACFV,EAAiBK,EACfM,EAA6BX,EAAiBI,EAC9CQ,EAA6Bb,EAAUM,EACvCQ,EAAsBd,EAAUK,EACtC,IAAK,IAAItZ,EAAI,EAAGA,EAAIoY,EAAOpY,IAAK,CAC9B,MAAMga,EAAQ5Q,EAAStC,KACvB8L,EAAO4G,EAAkBxZ,IACrBga,EAAQJ,EACZhH,EAAO6G,EAAmBzZ,IAAMga,EAAQH,EACxCjH,EAAO8G,EAAqB1Z,IACxBga,EAAQF,EACZlH,EAAO+G,EAAsB3Z,IAAMga,EAAQD,KAKnD,OAAOE,WAAYrH,EAAQ,CAACM,EAAOiF,EAAQD,EAASE,GAAQ3a,EAAET,OAGhEoB,sBACIX,EAAa2Y,EAAmBC,EAChCC,GACF/Z,EAAiBkB,EAAG,yBAEpB,MAAOyV,EAAOqD,EAAWC,EAAUC,GAAehZ,EAAEkB,MAC9CyR,EAAU9R,KAAKiB,SAAS9B,EAAEwB,QAC1B2T,EAAS,IAAIzJ,aAAa+J,EAAQkD,EAAYC,EAAWI,GAEzDC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAG5CQ,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GAEhD,IAAIuD,EAAe,EACnB,IAAK,IAAInW,EAAI,EAAGA,EAAImP,EAAOnP,IAAK,CAC9B,MAAMoW,EAAcpW,EAAItG,EAAEuD,QAAQ,GAClC,IAAK,IAAI+V,EAAI,EAAGA,EAAIX,EAAWW,IAAK,CAClC,MAAMC,EAAgBH,EAAwBE,EAKxCqD,EAAYD,EAJO5V,KAAKsB,IAC1B0Q,EAAY,EACZD,EAAe/R,KAAK8V,MAAMrD,GACXzS,KAAK6B,MAAM4Q,IACqBvZ,EAAEuD,QAAQ,GAC7D,IAAK,IAAIsW,EAAI,EAAGA,EAAIjB,EAAUiB,IAAK,CACjC,MAAMC,EAAgBT,EAAwBQ,EAKxCgD,EAAYF,EAJO7V,KAAKsB,IAC1B2Q,EAAW,EACXF,EAAe/R,KAAK8V,MAAM9C,GACXhT,KAAK6B,MAAMmR,IACmB9Z,EAAEuD,QAAQ,GAC3D,IAAK,IAAIhB,EAAI,EAAGA,EAAIyW,EAAazW,IAAK,CAGpC,MAAMua,EAASnK,EAAQkK,EAAYta,GACnC4S,EAAOsH,KAAkBK,KAKjC,OAAOjZ,SACHsR,EAAQ,CAACM,EAAOkD,EAAWC,EAAUI,GAAchZ,EAAET,OAG3DoB,8BACI4K,EAAcvL,EAAa6Y,GAC7B/Z,EAAiB,CAACyM,EAAIvL,GAAI,iCAE1B,MAAOyV,EAAOgF,EAASC,EAAQC,GAAS3a,EAAEkB,QACjC0Z,EAASC,GAAUtP,EAAGrK,MAEzBiU,EAAS,IAAIzJ,aAAa+J,EAAQgF,EAAUC,EAASC,GACrDhP,EAAW9K,KAAKiB,SAASyJ,EAAG/J,QAK5BsZ,EAAmC,CACtCjC,GAAgB+B,EAAU,EAAKH,EAAU,EAAIA,EAC7C5B,GAAgBgC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtClC,GAAgB+B,EAAU,EAAKA,EAAU,EAAIA,EAC7C/B,GAAgBgC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAEhDgC,EAAiB,EAAI/B,EACrBgC,EAAgB,EAAI/B,EAIpBgC,EAAyC,EAA5BnW,KAAK+J,KAAKkM,GAAuB,EAC9CG,EAAuC,EAA3BpW,KAAK+J,KAAKmM,GAAsB,EAGlD,IAAK,IAAI1W,EAAI,EAAGA,EAAImP,EAAOnP,IAAK,CAC9B,MAAMoW,EAAcpW,EAAItG,EAAEuD,QAAQ,GAClC,IAAK,IAAI+V,EAAI,EAAGA,EAAImB,EAASnB,IAAK,CAChC,MAAMqD,EAAYD,EAAcpD,EAAItZ,EAAEuD,QAAQ,GAGxC4Z,EAAarW,KAAK6B,MAAM2Q,EAAIyD,GAC5BK,EAAWtW,KAAK6B,MAAMwU,EAAcF,EAAY,GACtD,IAAK,IAAIpD,EAAI,EAAGA,EAAIa,EAAQb,IAAK,CAC/B,MAAMgD,EAAYF,EAAY9C,EAAI7Z,EAAEuD,QAAQ,GAGtC8Z,EAAavW,KAAK6B,MAAMkR,EAAImD,GAC5BM,EAAWxW,KAAK6B,MAAM0U,EAAcH,EAAW,GAErD,IAAK,IAAI3a,EAAI,EAAGA,EAAIoY,EAAOpY,IAAK,CAC9B,IAAIgb,EAAQ,EAGZ,IAAK,IAAIC,EAAW,EAAGA,EAAWP,EAAWO,IAAY,CACvD,MAAMC,EAAMD,EAAWJ,EAEvB,GAAIK,EAAM,GAAKA,GAAO7C,EACpB,SAGF,MAAM8C,EAAYhB,EAAce,EAAMlS,EAAGhI,QAAQ,GAC3CgW,EAAgBkE,EAAMzC,EAK5B,GAAI1B,IAJqBxS,KAAKsB,IAC1BqS,EAAU,EACV5B,EAAe/R,KAAK8V,MAAMrD,GACXzS,KAAK6B,MAAM4Q,IAI9B,IAAK,IAAIoE,EAAW,EAAGA,EAAWT,EAAUS,IAAY,CACtD,MAAMC,EAAMD,EAAWL,EAEvB,GAAIM,EAAM,GAAKA,GAAO/C,EACpB,SAGF,MAAMgD,EAAYH,EAAYE,EAAMrS,EAAGhI,QAAQ,GACzCuW,EAAgB8D,EAAM3C,EAMxBpB,IALqB/S,KAAKsB,IAC1BsS,EAAS,EACT7B,EAAe/R,KAAK8V,MAAM9C,GACXhT,KAAK6B,MAAMmR,MAG5ByD,GAAS5R,EAASkS,EAAYtb,KAIpC4S,EAAO0H,EAAYta,GAAKgb,KAKhC,OAAOf,WAAYrH,EAAQnV,EAAEkB,MAAOlB,EAAET,OAGxCoB,6BACIX,EAAa8d,EAAqBtV,EAAcuV,EAChDC,GACFlf,EAAiBkB,EAAG,gCAEpB,MAAMie,EAAWje,EAAEkB,MAAM,GACnBgd,EAAOD,EAAW,EAClBtL,EAAU9R,KAAKiB,SAAS9B,EAAEwB,QAC1B0C,EAAOlE,EAAEkE,KACTuB,EAAS,IAAIiG,aAAaxH,GAEhC,SAASia,EAAkB9U,GACzB,MAAM+U,EAAiB/U,EAAS4U,EAChC,IAAII,EACAhV,EAAS+U,EAAiBtX,KAAKb,IAAI,EAAGmY,EAAiBN,GAC3D,MAAMQ,EAAejV,EAAS+U,EAC1BtX,KAAKsB,IAAIgW,EAAiBN,EAAaI,GAE3C,IAAIzX,EAAM,EACV,KAAO4X,GAAkBC,EAAcD,IAAkB,CACvD,MAAME,EAAI5L,EAAQ0L,GAClB5X,GAAO8X,EAAIA,EAEb,OAAO9X,EAGT,IAAK,IAAI4C,EAAS,EAAGA,EAASnF,EAAMmF,IAAU,CAC5C,MAAM5C,EAAM0X,EAAkB9U,GACxBmV,EAAM7L,EAAQtJ,GAAUvC,KAAKC,IAAIyB,EAAOuV,EAAQtX,GAAMuX,GAC5DvY,EAAO4D,GAAUmV,EAGnB,OAAOhC,WAAY/W,EAAQzF,EAAEkB,OAG/BP,QACI4K,EAAckT,EAAsBC,EACpCZ,EAAqBtV,EAAcuV,EACnCC,GACFlf,EAAiByM,EAAI,WACrB,MAAM0S,EAAW1S,EAAGrK,MAAM,GACpByK,EAAW9K,KAAKiB,SAASyJ,EAAG/J,QAC5Bmd,EAAmB9d,KAAKiB,SAAS2c,EAAWjd,QAC5Cod,EAAoB/d,KAAKiB,SAAS4c,EAAYld,QAC9CiE,EAAS,IAAIiG,aAAaH,EAAGrH,MAC7BA,EAAOqH,EAAGrH,KAEhB,IAAK,IAAImF,EAAS,EAAGA,EAASnF,EAAMmF,IAAU,CAC5C,MAAM+U,EAAiB/U,EAAS4U,EAC1BY,EACDxV,EAAS+U,EAAkBtX,KAAKb,IAAI,EAAGmY,EAAiBN,GACvDgB,EAAYzV,EAAS+U,EACvBtX,KAAKsB,IAAI6V,EAAUG,EAAiBN,EAAc,GAEtD,IAAIiB,EAAO,EACX,IAAK,IAAIxW,EAAIsW,EAAYtW,EAAIuW,EAAUvW,IACrCwW,GAAQjY,KAAKC,IAAI4X,EAAiBpW,GAAI,GAExCwW,EAAOhB,EAAQgB,EAAOvW,EAEtB,IAAK,IAAID,EAAIsW,EAAYtW,EAAIuW,EAAUvW,IAAK,CAC1C,IAAIyW,GAAO,EAAIjB,EAAQC,EAAOW,EAAiBpW,GAC3CqW,EAAkBvV,GAAU0V,EAC5B1V,IAAWd,IACbyW,GAAOlY,KAAKC,IAAIgY,GAAOf,IAEzBgB,GAAOrT,EAAStC,GAChB5D,EAAO8C,IAAMyW,GAGjB,OAAOxC,WAAY/W,EAAQ8F,EAAGrK,OAGhCP,YACIiF,EAAkBqZ,EAAqBC,EACvCC,GACFrgB,EAAiB8G,EAAQ,eAEzB,MAAMwZ,EAAgBH,EAAarZ,EAASyZ,UAAWzZ,GACjD4H,EAAY4R,EAAcle,MAAM,GAChCoe,EAAYF,EAAcle,MAAM,GAChC8D,EAAMiE,QAAkB,CAACuE,EAAW0R,GAAa,SACjDpX,EAAUjH,KAAKiB,SAASkD,EAAIxD,QAC5B+d,EAAW1e,KAAKiB,SAASsd,EAAc5d,QAE7C,IAAK,IAAI8E,EAAI,EAAGA,EAAIkH,IAAalH,EAAG,CAClC,MAAM+C,EAAS/C,EAAIgZ,EAGbE,EAAM,IAAI9T,aAAa4T,EAAY,GACzCE,EAAI,GAAKD,EAASlW,GAClB,IAAK,IAAIoW,EAAQ,EAAGA,EAAQD,EAAIlb,SAAUmb,EACxCD,EAAIC,GAASD,EAAIC,EAAQ,GAAKF,EAASlW,EAASoW,GAGlD,MAAMC,EAASC,OAAgBR,EAAKS,YAC9BC,EAAYvZ,EAAI4Y,EACtB,IAAK,IAAIY,EAAW,EAAGA,EAAWZ,IAAcY,EAAU,CACxD,MAAMxG,EAAIoG,IAGV5X,EAAQ+X,EAAYC,GAAYN,EAAIlb,OAEpC,IAAK,IAAImb,EAAQ,EAAGA,EAAQD,EAAIlb,OAAQmb,IACtC,GAAInG,EAAIkG,EAAIC,GAAQ,CAClB3X,EAAQ+X,EAAYC,GAAYL,EAChC,QAKR,OAAOza,EAGTrE,OAAO4S,EAAmBoH,EAAeoF,EAAiBC,GAExDlhB,EAAiByU,EAAS,UAE1B,MAAMvO,EAAM,IAAI0G,aAAa6H,EAAQrP,KAAOyW,GAC5C3V,EAAIF,KAAKkb,GACT,MAAMC,EAAapf,KAAKiB,SAASyR,EAAQ/R,QAEzC,IAAK,IAAIie,EAAQ,EAAGA,EAAQlM,EAAQrP,OAAQub,EACtCQ,EAAWR,IAAU,GAAKQ,EAAWR,GAAS9E,IAChD3V,EAAIya,EAAQ9E,EAAQsF,EAAWR,IAAUM,GAG7C,OAAOG,WAAYlb,EAAK,CAACuO,EAAQrP,KAAMyW,GAAQ,SAGjDha,kBACIwf,EAAiBC,EAAkBC,EACnCC,EAAsBC,GACxBzhB,EAAiBqhB,EAAO,qBAExB,MAAMK,EAAY3f,KAAKiB,SAASqe,EAAM3e,QAChCif,EAAa5f,KAAKiB,SAASse,EAAO5e,QACxC,OAAOhC,EACHghB,EAAWC,EAAYJ,EAAeC,EAAcC,GAG1D5f,aAAaX,EAAa+H,EAAmB8E,GAE3CxN,OAAKC,OACc,SAAfuN,EACA,IAAM,+DACFA,KACRxN,OAAKC,OACDyI,EAAY,EACZ,IACI,sDAAsDA,KAE9D,MAAMyF,EAAYxN,EAAEkB,MAAM,GACpBwf,EAAc1gB,EAAEkB,MAAM,GACtByf,EAAa3gB,EAAEkB,MAAM,GACrB0f,EAAa5gB,EAAEkB,MAAM,GAErB2f,EAAeH,EAAc3Y,EAC7B+Y,EAAcH,EAAa5Y,EAC3BgZ,EAAcH,GAAc7Y,EAAYA,GAExC4K,EAAU9R,KAAKiB,SAAS9B,EAAEwB,QAC1BiE,EACF,IAAIiG,aAAa8B,EAAYqT,EAAeC,EAAcC,GAE9D,IAAI5H,EAAY,EAChB,IAAK,IAAI7S,EAAI,EAAGA,EAAIkH,IAAalH,EAC/B,IAAK,IAAI0a,EAAI,EAAGA,EAAIH,IAAgBG,EAAG,CACrC,MAAMC,EAAMna,KAAK6B,MAAMqY,EAAIjZ,GACrBmZ,EAAWF,EAAIjZ,EACrB,IAAK,IAAIoZ,EAAI,EAAGA,EAAIL,IAAeK,EAAG,CACpC,MAAMC,EAAMta,KAAK6B,MAAMwY,EAAIpZ,GAErBsZ,GAAWH,EAAUnZ,EADVoZ,EAAIpZ,GAC6BgZ,EAClD,IAAK,IAAIxe,EAAI,EAAGA,EAAIwe,IAAexe,EAAG,CACpC,MACM+e,EADM/e,EAAI8e,EAENT,GAAcQ,EAAMT,GAAcM,EAAMP,EAAcpa,IAChEb,EAAO0T,KAAexG,EAAQ2O,KAKtC,OAAO9E,WACH/W,EAAQ,CAAC+H,EAAWqT,EAAcC,EAAaC,IAG7CpgB,oBACJyF,EAAWE,EAAW/G,EACtBgiB,GACF,MAAM/N,EAAWlS,eAAakgB,2BAA2Bpb,EAAElF,MAAOoF,EAAEpF,OAC9DuE,EAAShD,SAAU+Q,EAAUjU,GAC7B6J,EAAQvI,KAAKiB,SAASsE,EAAE5E,QACxBigB,EAAQ5gB,KAAKiB,SAASwE,EAAE9E,QACxBkgB,EAAiBpgB,eAAaqgB,iBAAiBvb,EAAElF,MAAOsS,GACxDoO,EAAiBtgB,eAAaqgB,iBAAiBrb,EAAEpF,MAAOsS,GAExD1L,EAAUrC,EAAOxE,OACvB,GAAIygB,EAAepd,OAASsd,EAAetd,SAAW,EACpD,IAAK,IAAIL,EAAI,EAAGA,EAAI6D,EAAQxD,SAAUL,EACpC6D,EAAQ7D,GAAKsd,EAAGnY,EAAMnF,EAAImF,EAAM9E,QAASmd,EAAMxd,EAAIwd,EAAMnd,aAEtD,CACL,MAAMud,EAAOhhB,KAAKmD,WAAWoC,GACvB0b,EAAOjhB,KAAKmD,WAAWsC,GAC7B,IAAK,IAAIrC,EAAI,EAAGA,EAAI6D,EAAQxD,SAAUL,EAAG,CACvC,MAAME,EAAMsB,EAAOrB,WAAWH,GAExB8d,EAAO5d,EAAIY,OAAOqB,EAAExB,MAC1B8c,EAAeviB,QAAQoD,GAAKwf,EAAKxf,GAAK,GACtC,MAAMyf,EAASH,EAAKjO,WAAWmO,GAEzBE,EAAO9d,EAAIY,OAAOuB,EAAE1B,MAC1Bgd,EAAeziB,QAAQoD,GAAK0f,EAAK1f,GAAK,GACtC,MAAM2f,EAASJ,EAAKlO,WAAWqO,GAE/Bna,EAAQ7D,GAAKsd,EAAGnY,EAAM4Y,GAASP,EAAMS,KAGzC,OAAOzc,EAAOjB,WAGhB7D,MAAwBX,EAAMmiB,EAAsBve,GAClD,OAAOlE,EAAMM,EAAGmiB,EAAYve,GAG9BjD,WAEAA,iBACE,OAAO,GAITA,UACE,OAAOC,MAAMwhB,UAGfzhB,cACI0hB,EACAlC,EACAmC,EACAC,EACAC,EACAC,GAEF,MAAOhN,EAAOiN,EAAaC,EAAY3J,GAAeqJ,EAAOnhB,MACvD0hB,EAAWzC,EAAMjf,MAAM,IAEtB2hB,EAAYC,GAAaP,EAC1BpN,EACF1S,SAAU,CAACmgB,EAAUC,EAAYC,EAAW9J,GAAc,WAExD+J,EAAUliB,KAAKiB,SAASqe,EAAM3e,QAC9BwhB,EAAaniB,KAAKiB,SAASwgB,EAAS9gB,QACpCyhB,EAAYpiB,KAAKiB,SAASugB,EAAO7gB,QAEjC0hB,EAAWb,EAAO9e,QAClB4f,EAAYhO,EAAO5R,QAKzB,IAAK,IAAI+C,EAAI,EAAGA,EAAIsc,EAAUtc,IAAK,CACjC,MAAM8c,EAAe,EAAJ9c,EACX+c,EAAKN,EAAQK,GACbE,EAAKP,EAAQK,EAAW,GACxBG,EAAKR,EAAQK,EAAW,GACxBI,EAAKT,EAAQK,EAAW,GAExBK,EAAeT,EAAW1c,GAChC,GAAImd,GAAQhO,EACV,SAGF,MAAMuF,EAAe6H,EAAa,GAC7BU,EAAKF,IAAOX,EAAc,IAAMG,EAAa,GAC9C,EACE5H,EACD6H,EAAY,GAAMU,EAAKF,IAAOX,EAAa,IAAMG,EAAY,GAAK,EAEvE,IAAK,IAAItX,EAAI,EAAGA,EAAIqX,EAAYrX,IAAK,CACnC,MAAMkY,EAAgBb,EAAa,EAC/BQ,GAAMX,EAAc,GAAKlX,IACzB,IAAO6X,EAAKE,IAAOb,EAAc,GAErC,GAAIgB,EAAO,GAAKA,EAAOhB,EAAc,EACnC,IAAK,IAAI1iB,EAAI,EAAGA,EAAI8iB,EAAW9iB,IAC7B,IAAK,IAAI6Z,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,MAAM8J,EACF9J,EAAI7Z,EAAImjB,EAAU,GAAK3X,EAAI2X,EAAU,GAAK7c,EAAI6c,EAAU,GAC5DhO,EAAOlU,OAAO0iB,GAAOlB,OAM3B,GAAe,aAAXD,EAAuB,CACzB,MAAMoB,EAAS9c,KAAK6B,MAAM+a,GACpBG,EAAY/c,KAAK+J,KAAK6S,GACtBI,EAAQJ,EAAOE,EAErB,IAAK,IAAI5jB,EAAI,EAAGA,EAAI8iB,EAAW9iB,IAAK,CAClC,MAAM+jB,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAK3iB,EAAIib,EAC5B,IAAOqI,EAAKE,IAAOb,EAAa,GAEpC,GAAIoB,EAAO,GAAKA,EAAOpB,EAAa,EAAG,CACrC,IAAK,IAAI9I,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,MAAM8J,EACF9J,EAAI7Z,EAAImjB,EAAU,GAAK3X,EAAI2X,EAAU,GAAK7c,EAAI6c,EAAU,GAC5DhO,EAAOlU,OAAO0iB,GAAOlB,EAEvB,SAGF,MAAMuB,EAAUld,KAAK6B,MAAMob,GACrBE,EAAWnd,KAAK+J,KAAKkT,GACrBG,EAAQH,EAAOC,EAErB,IAAK,IAAInK,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,IAAI8J,EAAM9J,EAAImK,EAAUd,EAAS,GAAKU,EAASV,EAAS,GACpDO,EAAOP,EAAS,GACpB,MAAM5I,EAAU2I,EAAUU,GAE1BA,EAAM9J,EAAIoK,EAAWf,EAAS,GAAKU,EAASV,EAAS,GACjDO,EAAOP,EAAS,GACpB,MAAMiB,EAAWlB,EAAUU,GAE3BA,EAAM9J,EAAImK,EAAUd,EAAS,GAAKW,EAAYX,EAAS,GACnDO,EAAOP,EAAS,GACpB,MAAM3I,EAAa0I,EAAUU,GAE7BA,EAAM9J,EAAIoK,EAAWf,EAAS,GAAKW,EAAYX,EAAS,GACpDO,EAAOP,EAAS,GACpB,MAEMvW,EAAM2N,GAAW6J,EAAW7J,GAAW4J,EACvCE,EAAS7J,GAHK0I,EAAUU,GAGapJ,GAAc2J,EAEzDP,EAAM9J,EAAI7Z,EAAImjB,EAAU,GAAK3X,EAAI2X,EAAU,GAAK7c,EAAI6c,EAAU,GAC9DhO,EAAOlU,OAAO0iB,GAAOhX,GAAQyX,EAASzX,GAAOmX,SAIjD,IAAK,IAAI9jB,EAAI,EAAGA,EAAI8iB,IAAa9iB,EAAG,CAClC,MAAM+jB,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAK3iB,EAAIib,EAC5B,IAAOqI,EAAKE,IAAOb,EAAa,GAEpC,GAAIoB,EAAO,GAAKA,EAAOpB,EAAa,EAAG,CACrC,IAAK,IAAI9I,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,MAAM8J,EACF9J,EAAI7Z,EAAImjB,EAAU,GAAK3X,EAAI2X,EAAU,GAAK7c,EAAI6c,EAAU,GAC5DhO,EAAOlU,OAAO0iB,GAAOlB,EAEvB,SAGF,MAAM4B,EAAWvd,KAAK8V,MAAMmH,GACtBO,EAAWxd,KAAK8V,MAAM8G,GAC5B,IAAK,IAAI7J,EAAI,EAAGA,EAAIb,EAAaa,IAAK,CACpC,MAAM0K,EAAQ1K,EAAIwK,EAAWnB,EAAS,GAClCoB,EAAWpB,EAAS,GAAKO,EAAOP,EAAS,GACvCsB,EACF3K,EAAI7Z,EAAImjB,EAAU,GAAK3X,EAAI2X,EAAU,GAAK7c,EAAI6c,EAAU,GAC5DhO,EAAOlU,OAAOujB,GAAUvB,EAAUsB,MAM5C,OAAOpP,EAAO3Q,WAGhB7D,cACI8jB,EAAuBC,EAAsBC,EAC7CC,GACF,MAAMC,UAACA,EAASC,WAAEA,EAAUtQ,UAAEA,EAASjR,QAAEA,EAAOwhB,WAAEA,GAC9CzjB,eAAa0jB,gBAAgBN,EAAcD,EAAeE,GAE9D,OAAO9jB,KAAKokB,QACRR,EAAeC,EAAcC,EAAaI,EAAYvQ,EACtDsQ,EAAYD,EAAWthB,EAASqhB,GAHb,GAMzBjkB,SAASX,EAAWuT,GAClB,MAAM2R,EAAe3R,EAAQrS,MACvB2jB,EAAYK,EAAaA,EAAa5gB,OAAS,IAE9C6gB,EAAaC,EAAW5Q,EAAWjR,GACtCjC,eAAa+jB,mBAAmBrlB,EAAGuT,GACvC,GAAkB,IAAd6R,EACF,OAAOvhB,SAAU,GAAIshB,EAAanlB,EAAET,OAGtC,MAAMuE,EAAS,IAAIwhB,eAAa,CAACF,EAAW5Q,GAAYxU,EAAET,OACpDgmB,EAAc1kB,KAAKiB,SAASyR,EAAQ/R,QACpCgkB,EAAQ3kB,KAAKiB,SAAS9B,EAAEwB,QAE9B,IAAK,IAAIyC,EAAI,EAAGA,EAAImhB,EAAWnhB,IAAK,CAClC,MAAM6G,EAAQ,GACd,IAAI2a,EAAe,EACnB,IAAK,IAAIlhB,EAAI,EAAGA,EAAIsgB,EAAWtgB,IAAK,CAClC,MAAMsB,EAAM0f,EAAYthB,EAAI4gB,EAAYtgB,GACxCkhB,GAAgB5f,EAAMtC,EAAQgB,GAC9BuG,EAAMf,KAAKlE,GAEb,GAAI4f,EAAe,GAAKA,GAAgBzlB,EAAEkE,KAAOsQ,EAC/C,MAAM,IAAIhU,MACN,oBAAoBsK,yBAA6B9K,EAAEkB,SAGzD,IAAK,IAAIqH,EAAI,EAAGA,EAAIiM,EAAWjM,IAC7BzE,EAAO7C,OAAOgD,EAAIuQ,EAAYjM,GAAKid,EAAMC,EAAejR,EAAYjM,GAGxE,OAAOzE,EAAOU,WAAWU,QAAQigB,GAGnCxkB,UACI4S,EAAiBmS,EAAiBxkB,GACpC,MAAM2jB,UAACA,EAASC,WAAEA,EAAUtQ,UAAEA,EAASjR,QAAEA,EAAOwhB,WAAEA,GAC9CzjB,eAAa0jB,gBAAgBU,EAASnS,EAASrS,GAC7C0jB,EAAerf,SAAU,GAE/B,OAAO1E,KAAKokB,QACR1R,EAASmS,EAASxkB,EAAO6jB,EAAYvQ,EAAWsQ,EAAYD,EAC5DthB,EAASqhB,GAHU,GAMzBjkB,KACIO,EAAoBgJ,EAAsB3K,GAC5CA,EAAQA,GAASF,OAAKsmB,WAAWzb,GACjC,MAAMjJ,EACF5B,OAAKumB,kBAAkBrmB,EAAOF,OAAK8J,cAAcjI,IAErD,OADAD,EAAO6D,KAAKoF,GACLlJ,WAAS6kB,WAAW5kB,EAAQC,EAAO3B,EAAOsB,MAGnDF,SAAyBX,GACvB,GAAgB,WAAZA,EAAET,MACJ,MAAM,IAAIiB,MAAM,gDAEhB,OAAOK,KAAKiE,KAAK9E,EAAEkB,MAAO,EAAGlB,EAAET,OAInCoB,UAA0BX,GACxB,MAAMiB,EAAS5B,OAAKumB,kBACD5lB,EAAET,MAAOF,OAAK8J,cAAcnJ,EAAEkB,QACjD,OAAOL,KAAKgL,WAAW5K,EAAQjB,EAAEkB,MAAOlB,EAAET,OAG5CoB,SAASqC,EAAe8iB,EAAcnhB,GACpC,OAAOrD,eAAaykB,aAAa/iB,EAAO8iB,EAAMnhB,GAGxChE,QACJ4S,EAAiBmS,EAAiBxkB,EAAoB6jB,EACtDvQ,EAAmBsQ,EAAoBD,EACvCthB,EAAmBqhB,EACnBoB,GACF,MAAMC,EAAe,CAAClB,EAAavQ,EAAWA,GAExC+Q,EAAc1kB,KAAKiB,SAASyR,EAAQ/R,QACpC0kB,EAAcrlB,KAAKiB,SAAS4jB,EAAQlkB,QAE1C,GAAmB,IAAfujB,EACF,OAAOlhB,SAAU,GAAI3C,EAAOwkB,EAAQnmB,OAGtC,MAAMuE,EAAS,IAAIwhB,eAAaW,EAAcP,EAAQnmB,OACtDuE,EAAO7C,OAAO6D,KAAMjE,KAAKiB,SAAS8iB,EAAapjB,QAAuB,IAEtE,IAAK,IAAIyC,EAAI,EAAGA,EAAI6gB,EAAY7gB,IAAK,CACnC,MAAM6G,EAAQ,GACd,IAAI2a,EAAe,EACnB,IAAK,IAAIlhB,EAAI,EAAGA,EAAIsgB,EAAWtgB,IAAK,CAClC,MAAMsB,EAAM0f,EAAYthB,EAAI4gB,EAAYtgB,GACxCuG,EAAMf,KAAKlE,GACX4f,GAAgB5f,EAAMtC,EAAQgB,GAGhC,GAAIkhB,EAAe,GAAKA,GAAgBV,EAAavQ,EACnD,MAAM,IAAIhU,MACN,oBAAoBsK,yBAA6B5J,KAGvD,IAAK,IAAIqH,EAAI,EAAGA,EAAIiM,EAAWjM,IACzByd,EACFliB,EAAO7C,OAAOwkB,EAAejR,EAAYjM,IACrC2d,EAAYjiB,EAAIuQ,EAAYjM,GAEhCzE,EAAO7C,OAAOwkB,EAAejR,EAAYjM,GAAsB,IAAjBmd,EAAQ9gB,KAClDshB,EAAY,GACZA,EAAYjiB,EAAIuQ,EAAYjM,GAItC,OAAOzE,EAAOU,WAAWU,QAAQhE,aC9lFrBilB,EAAczhB,GAC5B,MAAM+G,EAAe,IAAIC,aAAahH,EAAKJ,QAC3C,IAAK,IAAIL,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EACjCwH,EAAaxH,GAAK6C,KAAKsf,IAAI1hB,EAAKT,IAElC,OAAOwH,EAGF,MAyBM4a,EAA0B,CACrCC,WAAYC,MACZC,YAAa,MACbC,WA3BGC,IACC,MAAM1mB,EAACA,GAAK0mB,EAAKC,OACXC,EAAaF,EAAK3mB,QACxB,IAAI0L,EAAe,IAAIC,aAAarM,OAAK8J,cAAcnJ,EAAEkB,QACzD,GAAgB,cAAZlB,EAAET,MAAuB,CAE3BkM,EAAe0a,EADAS,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,YAExC,CACL,MAAM4lB,EAAcD,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QACpCS,EAAO4kB,EAAY9kB,mBAAmBE,KACtCE,EAAO0kB,EAAY9kB,mBAAmBI,KACtC2kB,EACFF,EAAW9lB,KAAKO,IAAIY,EAAKT,QAAQP,OAC/B8lB,EACFH,EAAW9lB,KAAKO,IAAIc,EAAKX,QAAQP,OACrC,IAAK,IAAIgD,EAAI,EAAGA,EAAI6iB,EAASxiB,OAAQL,IAAK,CACxC,MAAMhC,EAAO6kB,EAAS7iB,GAChB9B,EAAO4kB,EAAS9iB,GACtBwH,EAAaxH,GAAK6C,KAAKkgB,MAAM/kB,EAAME,IAGvC,OAAOykB,EAAW/a,WAAWJ,EAAczL,EAAEkB,MAAO,sBC3B1C+lB,EAA6B1F,GAE3C,MAAO,CAAC2F,EAAkBC,EAAkB/d,EACpCqY,EAAmBliB,KACzB,MAAMiU,EAAWlS,eAAakgB,2BAA2B0F,EAAQC,GAE3DC,EAAa5T,EAASlP,OACtB+iB,EAAgBhoB,OAAKioB,eAAe9T,GACpC+T,EAAaloB,OAAK8J,cAAcqK,GAEhC/N,EACFpG,OAAKmoB,uBAAuBjoB,EAA0BgoB,GAEpDE,EAAQP,EAAO5iB,OACfojB,EAAQP,EAAO7iB,OAEfqjB,EAAWtoB,OAAKioB,eAAeJ,GAC/BU,EAAWvoB,OAAKioB,eAAeH,GAE/BzF,EAAiBpgB,eAAaqgB,iBAAiBuF,EAAQ1T,GACvDoO,EAAiBtgB,eAAaqgB,iBAAiBwF,EAAQ3T,GAE7D,GAAIkO,EAAepd,OAASsd,EAAetd,SAAW,EACpD,IAAK,IAAIL,EAAI,EAAGA,EAAIwB,EAAOnB,SAAUL,EACnCwB,EAAOxB,GAAKsd,EAAGnY,EAAMnF,EAAImF,EAAM9E,QAASmd,EAAMxd,EAAIwd,EAAMnd,cAG1D,IAAK,IAAIL,EAAI,EAAGA,EAAIwB,EAAOnB,SAAUL,EAAG,CACtC,MAAME,EAAM9E,OAAK+E,WAAWH,EAAGmjB,EAAYC,GAErCtF,EAAO5d,EAAIY,OAAO0iB,GACxB/F,EAAeviB,QAAQoD,GAAKwf,EAAKxf,GAAK,GACtC,MAAMyf,EAAS3iB,OAAKuU,WAAWmO,EAAM0F,EAAOE,GAEtC1F,EAAO9d,EAAIY,OAAO2iB,GACxB9F,EAAeziB,QAAQoD,GAAK0f,EAAK1f,GAAK,GACtC,MAAM2f,EAAS7iB,OAAKuU,WAAWqO,EAAMyF,EAAOE,GAE5CniB,EAAOxB,GAAKsd,EAAGnY,EAAM4Y,GAASP,EAAMS,IAIxC,MAAO,CAACzc,EAAQ+N,aC7CJqU,EAAQnB,GAEtB,MAAMC,OAACA,EAAM5mB,QAAEA,GAAW2mB,GACpBzkB,KAACA,EAAIE,KAAEA,GAAQwkB,EAEfG,EAAW/mB,EAAQe,KAAKO,IAAIY,EAAKT,QAAQP,OACzC8lB,EAAWhnB,EAAQe,KAAKO,IAAIc,EAAKX,QAAQP,OAEzC6mB,EAAc/nB,EAAQgoB,eAAe9lB,EAAKf,MAAO,aAYvD,OAVgBnB,EAAQe,KAAKO,IAAIymB,EAAYtmB,QAKrCO,mBAAqB,CAC3BE,KAAMlC,EAAQgoB,eAAe9lB,EAAKf,MAAO,UAAW4lB,GACpD3kB,KAAMpC,EAAQgoB,eAAe5lB,EAAKjB,MAAO,UAAW6lB,IAG/Ce,EAGF,MAAME,EAA8B,CACzC1B,WAAY2B,UACZzB,YAAa,MACbC,WAAYoB,YC1BEK,EACZxB,GACF,MAAMC,OAACA,EAAM5mB,QAAEA,GAAW2mB,GACpB1mB,EAACA,GAAK2mB,EAIZ,OAFA5mB,EAAQooB,OAAOnoB,EAAEwB,QAEV,CAACA,OAAQxB,EAAEwB,OAAQN,MAAOlB,EAAEkB,MAAO3B,MAAOS,EAAET,OAG9C,MAAM6oB,EAA+B,CAC1C9B,WAAY+B,WACZ7B,YAAa,MACbC,WAAYyB,YCbEjmB,EAAKykB,GAEnB,MAAMC,OAACA,EAAM5mB,QAAEA,GAAW2mB,GACpB3a,MAACA,GAAS4a,EAEV1kB,EAAOlC,EAAQe,KAAKO,IAAI0K,EAAMvK,QAAQO,mBAAmBE,KACzDqmB,EAAUvoB,EAAQe,KAAKO,IAAIY,EAAKT,QAAQP,OAK9C,OAAOlB,EAAQgoB,eAAe9lB,EAAKf,MAAOe,EAAK1C,MAAO+oB,GAGjD,MAAMC,EAA2B,CACtCjC,WAAYkC,OACZhC,YAAa,MACbC,WAAYxkB,YCZEwmB,EACZ/B,GAEF,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B1mB,EAACA,GAAK2mB,GACNpnB,MAACA,GAASmpB,EAGhB,GAAc,cAAVnpB,EAAuB,CACzB,GAAgB,cAAZS,EAAET,MACJ,OAAO2oB,EAAS,CAACvB,OAAQ,CAAC3mB,EAAAA,GAAID,QAAAA,IAIhC,MAAM4oB,EAAc1f,QAASjJ,EAAEkB,OACzB0nB,EAASH,EAAK,CAAC9B,OAAQ,CAAC3mB,EAAAA,GAAID,QAAAA,EAAS2oB,MAAO,CAACnpB,MAAO,aAEpDkG,EACFoiB,EAAQ,CAAClB,OAAQ,CAAC1kB,KAAM2mB,EAAQzmB,KAAMwmB,GAAc5oB,QAAAA,IAKxD,OAHA4oB,EAAYE,UACZ9oB,EAAQ+oB,8BAA8BF,GAE/BnjB,EAIT,GAAgB,cAAZzF,EAAET,MAAuB,CAC3B,MAAMwpB,EAAW9mB,EAAK,CAAC0kB,OAAQ,CAAC5a,MAAO/L,GAAID,QAAAA,IACrC0F,EAASgjB,EAAK,CAAC9B,OAAQ,CAAC3mB,EAAG+oB,GAAWhpB,QAAAA,EAAS2oB,MAAO,CAACnpB,MAAAA,KAI7D,OAFAQ,EAAQ+oB,8BAA8BC,GAE/BtjB,EAGT,IAAKpG,OAAK2pB,gBAAgBhpB,EAAET,MAAOA,GAAQ,CAGzC,MAAMkG,EAASyiB,EAAS,CAACvB,OAAQ,CAAC3mB,EAAAA,GAAID,QAAAA,IACtC,MAAO,CAACyB,OAAQiE,EAAOjE,OAAQN,MAAOuE,EAAOvE,MAAO3B,MAAAA,GAGtD,GAAc,UAAVA,EAAmB,CACrB,MAAM0B,EAASlB,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACpCwK,EAAewd,WAAWC,KAAKjoB,GACrC,OAAOlB,EAAQgoB,eAAe/nB,EAAEkB,MAAO,QAASuK,GAGlD,GAAc,SAAVlM,EAAkB,CAIpB,MAAMkF,EAAQ1E,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACnCkoB,EAAO9pB,OAAK+pB,aAAa,CAAC,GAAIppB,EAAET,QAE/B8pB,EAAYlE,GAAe8B,EAC9B,CAAC7gB,EAAGE,IAAOF,IAAME,EAAK,EAAI,EADI2gB,CACDjnB,EAAEkB,MAAO,GAAIuD,EAAO0kB,EAAM,QAE3D,OAAOppB,EAAQgoB,eAAe5C,EAAa,OAAQkE,GAGrD,MAAM,IAAI7oB,MAAM,iCAAiCR,EAAET,YAAYA,KAG1D,MAAM+pB,EAA2B,CACtChD,WAAYiD,OACZ/C,YAAa,MACbC,WAAYgC,YCzDEe,EACZC,EAAcC,EACdC,EAAuCpqB,GACzC,OAAmB,MAAfoqB,EACK,EAAEhD,OAAAA,EAAQ5mB,QAAAA,MACf,MAAMqG,EAACA,EAACE,EAAEA,GAAKqgB,EACTC,EAAa7mB,EAEnBjB,EAAiB,CAACsH,EAAGE,GAAImjB,GAEzB,MAAMrgB,EAAQwd,EAAW9lB,KAAKO,IAAI+E,EAAE5E,QAAQP,OACtCwgB,EAAQmF,EAAW9lB,KAAKO,IAAIiF,EAAE9E,QAAQP,OAEtC2oB,EAASrqB,GAAS6G,EAAE7G,OAEnB8pB,EAAYlE,GACfuE,EAAWtjB,EAAElF,MAAOoF,EAAEpF,MAAOkI,EAAOqY,EAAOmI,GAE/C,OAAOhD,EAAWmB,eAAe5C,EAAayE,EAAQP,IAInD,EAAE1C,OAAAA,EAAQ5mB,QAAAA,MACf,MAAMqG,EAACA,EAACE,EAAEA,GAAKqgB,EACTC,EAAa7mB,EAEnB,GAAgB,cAAZqG,EAAE7G,OAAqC,cAAZ+G,EAAE/G,MAAuB,CACtD,MAAMsqB,EAAYpB,EACd,CAAC9B,OAAQ,CAAC3mB,EAAGoG,GAAIrG,QAAS6mB,EAAY8B,MAAO,CAACnpB,MAAO,eAEnDuqB,EAAgBlD,EAAW9lB,KAAKO,IAAIwoB,EAAUroB,QAE9CuoB,EAAQD,EAAc/nB,mBAAmBE,KACzC+nB,EAAQF,EAAc/nB,mBAAmBI,KAEzC8nB,EACFrD,EAAW9lB,KAAKO,IAAI0oB,EAAMvoB,QAAQP,OAChCipB,EACFtD,EAAW9lB,KAAKO,IAAI2oB,EAAMxoB,QAAQP,OAEhCkpB,EAAY1B,EACd,CAAC9B,OAAQ,CAAC3mB,EAAGsG,GAAIvG,QAAS6mB,EAAY8B,MAAO,CAACnpB,MAAO,eAEnD6qB,EAAgBxD,EAAW9lB,KAAKO,IAAI8oB,EAAU3oB,QAE9C6oB,EAAQD,EAAcroB,mBAAmBE,KACzCqoB,EAAQF,EAAcroB,mBAAmBI,KAEzCooB,EACF3D,EAAW9lB,KAAKO,IAAIgpB,EAAM7oB,QAAQP,OAChCupB,EACF5D,EAAW9lB,KAAKO,IAAIipB,EAAM9oB,QAAQP,QAE/BwpB,EAAgBC,EAAgBvF,GAAewE,EAClDvjB,EAAElF,MAAOoF,EAAEpF,MAAO+oB,EAAWC,EAAWK,EAAWC,GAEjDG,EACF/D,EAAWmB,eAAe5C,EAAa,UAAWsF,GAEhDG,EACFhE,EAAWmB,eAAe5C,EAAa,UAAWuF,GAEhDjlB,EAASoiB,EACX,CAAClB,OAAQ,CAAC1kB,KAAM0oB,EAAYxoB,KAAMyoB,GAAa7qB,QAAS6mB,IAO5D,OALAA,EAAWkC,8BAA8Be,GACzCjD,EAAWkC,8BAA8BqB,GACzCvD,EAAWkC,8BAA8B6B,GACzC/D,EAAWkC,8BAA8B8B,GAElCnlB,EACF,CACL,MAAM2D,EAAQwd,EAAW9lB,KAAKO,IAAI+E,EAAE5E,QAAQP,OACtCwgB,EAAQmF,EAAW9lB,KAAKO,IAAIiF,EAAE9E,QAAQP,OAEtC2oB,EAASrqB,GAAS6G,EAAE7G,OAEnB8pB,EAAYlE,GACfuE,EAAWtjB,EAAElF,MAAOoF,EAAEpF,MAAOkI,EAAOqY,EAAOmI,GAE/C,OAAOhD,EAAWmB,eAAe5C,EAAayE,EAAQP,cAS5CwB,EAA8BtJ,GAE5C,MAAO,CAAC2F,EAAkBC,EAAkB8C,EACpCC,EAAyBK,EACzBC,KACN,MAAMrF,EAAc7jB,eAAakgB,2BAA2B0F,EAAQC,GAC9DI,EAAaloB,OAAK8J,cAAcgc,GAChCiC,EAAajC,EAAY7gB,OACzB+iB,EAAgBhoB,OAAKioB,eAAenC,GAEpC2F,EAAiBzrB,OAAKmoB,uBAAuB,UAAWD,GACxDwD,EAAiB1rB,OAAKmoB,uBAAuB,UAAWD,GAExD7F,EAAiBpgB,eAAaqgB,iBAAiBuF,EAAQ/B,GACvDvD,EAAiBtgB,eAAaqgB,iBAAiBwF,EAAQhC,GAEvD/b,EAAQ9H,eAAac,uBAAuB6nB,EAAWC,GACvDzI,EAAQngB,eAAac,uBAAuBmoB,EAAWC,GAEvD/C,EAAQP,EAAO5iB,OACfqjB,EAAWtoB,OAAKioB,eAAeJ,GAE/BQ,EAAQP,EAAO7iB,OACfsjB,EAAWvoB,OAAKioB,eAAeH,GAErC,GAAIzF,EAAepd,OAASsd,EAAetd,SAAW,EACpD,IAAK,IAAIL,EAAI,EAAGA,EAAI6mB,EAAexmB,OAAQL,IAAK,CAC9C,MAAM+mB,EAAO/mB,EAAImF,EAAM9E,OACjB2mB,EAAOhnB,EAAIwd,EAAMnd,OAEjBmB,EACF8b,EAAGnY,EAAa,EAAP4hB,GAAW5hB,EAAa,EAAP4hB,EAAW,GAAIvJ,EAAa,EAAPwJ,GAC5CxJ,EAAa,EAAPwJ,EAAW,IAExBH,EAAe7mB,GAAKwB,EAAOxD,KAC3B8oB,EAAe9mB,GAAKwB,EAAOtD,UAG7B,IAAK,IAAI8B,EAAI,EAAGA,EAAI6mB,EAAexmB,OAAQL,IAAK,CAC9C,MAAME,EAAM9E,OAAK+E,WAAWH,EAAGmjB,EAAYC,GAErCtF,EAAO5d,EAAIY,OAAO0iB,GACxB/F,EAAeviB,QAAQoD,GAAKwf,EAAKxf,GAAK,GACtC,MAAMyf,EAAS3iB,OAAKuU,WAAWmO,EAAM0F,EAAOE,GAEtC1F,EAAO9d,EAAIY,OAAO2iB,GACxB9F,EAAeziB,QAAQoD,GAAK0f,EAAK1f,GAAK,GACtC,MAAM2f,EAAS7iB,OAAKuU,WAAWqO,EAAMyF,EAAOE,GAEtCsD,EACF3J,EAAGnY,EAAe,EAAT4Y,GAAa5Y,EAAe,EAAT4Y,EAAa,GAAIP,EAAe,EAATS,GAChDT,EAAe,EAATS,EAAa,IAE1B4I,EAAe7mB,GAAKinB,EAASjpB,KAC7B8oB,EAAe9mB,GAAKinB,EAAS/oB,KAGjC,MAAO,CAAC2oB,EAAgBC,EAAgB5F,ICjKrC,MAAMgG,EAAUlE,GAA+B7gB,EAAGE,IAAMF,EAAIE,GACtD8kB,EACTP,GAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CAACroB,KAAM8nB,EAAQM,EAAOloB,KAAM6nB,EAAQM,KAGpCe,EAAM7B,EAAiB8B,MAAKH,EAASC,GAErCG,EAA0B,CACrCjF,WAAYgF,MACZ9E,YAAa,MACbC,WAAY4E,YCTEG,EAAsBjK,GAEpC,MAAO,CAACtgB,EAAQ1B,EAAOmpB,KACrB,MAAM7d,EACFxL,OAAKmoB,uBAAuBjoB,EAA0B0B,EAAOqD,QACjE,IAAK,IAAIL,EAAI,EAAGA,EAAIhD,EAAOqD,SAAUL,EACnC4G,EAAU5G,GAAKsd,EAAGtgB,EAAOgD,GAAIykB,GAE/B,OAAO7d,YCAK4gB,EACZhC,EAAclI,EAA0BhiB,GAC1C,MAAO,EAAEonB,OAAAA,EAAQ+B,MAAAA,EAAO3oB,QAAAA,MACtB,MAAMC,EAACA,GAAK2mB,EAEZ,GADA7nB,EAAiBkB,EAAGypB,GACJ,WAAZzpB,EAAET,OAAgC,WAAVA,EAC1B,MAAM,IAAIiB,MAAM,wDAGlB,MAAMomB,EAAa7mB,EACbkB,EAAS2lB,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,OACvCyqB,EAAQrsB,OAAK8J,cAAcnJ,EAAEkB,OAC7B0oB,EAASrqB,GAASS,EAAET,MACpBsL,EAAYxL,OAAKumB,kBAAkBgE,EAAQ8B,GACjD,IAAK,IAAIznB,EAAI,EAAGA,EAAIynB,IAASznB,EAC3B4G,EAAU5G,GAAKsd,EAAGtgB,EAAOgD,GAAIykB,GAE/B,OAAO9B,EAAWmB,eAAe/nB,EAAEkB,MAAO0oB,EAAQ/e,aAatC8gB,EACZlC,EAAcmC,EAA4BrsB,GAC5C,MAAO,EAAEonB,OAAAA,EAAQ+B,MAAAA,EAAO3oB,QAAAA,MACtB,MAAMC,EAACA,GAAK2mB,EAEZ,GADA7nB,EAAiBkB,EAAGypB,GACJ,WAAZzpB,EAAET,OAAgC,WAAVA,EAC1B,MAAM,IAAIiB,MAAM,wDAGlB,MAAMomB,EAAa7mB,EACbkB,EAAS2lB,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,OACvC2oB,EAASrqB,GAASS,EAAET,MACpBsL,EAAY+gB,EAAU3qB,EAAQ2oB,EAAQlB,GAC5C,OAAO9B,EAAWmB,eAAe/nB,EAAEkB,MAAO0oB,EAAQ/e,ICrD/C,MAAMghB,EAAWL,EAAuBM,GAAOhlB,KAAK+J,KAAKib,IACnDC,EAAiBJ,EAAwBK,OAAMH,GAE/CI,EAA2B,CACtC3F,WAAY0F,OACZxF,YAAa,MACbC,WAAYsF,GCNDG,EAAUV,EAAuBM,GAAOhlB,KAAKqlB,IAAIL,IACjDM,EAAgBT,EAAwBU,MAAKH,GAE7CI,EAA0B,CACrChG,WAAY+F,MACZ7F,YAAa,MACbC,WAAY2F,GCNDG,EAAYf,EAAuBM,GAAOhlB,KAAK0lB,MAAMV,IACrDW,EAAkBd,EAAwBe,QAAOH,GAEjDI,EAA4B,CACvCrG,WAAYoG,QACZlG,YAAa,MACbC,WAAYgG,GCNDG,EAAYpB,EAAuBM,GAAOhlB,KAAK6B,MAAMmjB,IACrDe,EAAkBlB,EAAwBmB,QAAOF,GAEjDG,EAA4B,CACvCzG,WAAYwG,QACZtG,YAAa,MACbC,WAAYoG,GCNDG,EAAUxB,EAAuBM,GAAOhlB,KAAKmmB,IAAInB,IACjDoB,EAAgBvB,EAAwBwB,MAAKH,GAE7CI,EAA0B,CACrC9G,WAAY6G,MACZ3G,YAAa,MACbC,WAAYyG,YCTEG,EACZjkB,EAAmBF,EAAoB1F,EACvCjE,GACF,MAAMmF,EAAOrF,OAAKmoB,uBACdjoB,EAA0BF,OAAK8J,cAAc3F,IAEjD,IAAK,IAAIS,EAAI,EAAGA,EAAIS,EAAKJ,SAAUL,EAAG,CACpC,MAAMoF,EAASpF,EAAIiF,EACnB,IAAIjD,EAAMmD,EAAMC,GAChB,IAAK,IAAI9E,EAAI,EAAGA,EAAI2E,IAAc3E,EAAG,CACnC,MAAM2F,EAAQd,EAAMC,EAAS9E,GACzB2F,EAAQjE,IACVA,EAAMiE,GAGVxF,EAAKT,GAAKgC,EAEZ,OAAOvB,ECfF,MAAM4oB,EACTrG,GAA+BrgB,EAAQC,IAAWD,EAASC,GAClD0mB,EACT1C,GAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CACLroB,KAAM8nB,EAAQM,EAAQL,EAAQM,EAC9BnoB,KAAM4nB,EAAQO,EAAQN,EAAQK,KAIzBmD,EACThE,EAAiBiE,WAAUH,EAAcC,GAEhCG,EAA+B,CAC1CpH,WAAYmH,WACZjH,YAAa,MACbC,WAAY+G,GCfDG,EAAYnC,EAAuBM,GAAO,EAAIhlB,KAAK8mB,KAAK9B,IACxD+B,EAAkBlC,EAAwBmC,QAAOH,GAEjDI,EAA4B,CACvCzH,WAAYwH,QACZtH,YAAa,MACbC,WAAYoH,YCNEG,GACZtpB,EAAkBrB,EAAiBa,EAAgBhD,EACnD3B,GACF,MAAM0uB,EAAcxqB,aAAWyqB,iBAAiBhtB,EAAOmC,EAAOa,GACxDI,EAASjF,OAAK8J,cAAcjF,GAC5BiqB,EAAW9uB,OAAKioB,eAAepmB,GAErC,GAAI+sB,EAAa,CACf,MAAMG,EAAa3qB,aAAW4qB,kBAAkBhrB,EAAO8qB,GACvD,OAAOzpB,EAAK4pB,SAASF,EAAYA,EAAa9pB,GAGhD,MAAMiqB,EAAUlvB,OAAKmoB,uBAAuBjoB,EAA0B+E,GACtE,IAAK,IAAIL,EAAI,EAAGA,EAAIK,IAAUL,EAAG,CAC/B,MAAMW,EAAOV,EAAKI,OACZf,EAAUlE,OAAKioB,eAAepjB,GAE9BsqB,EADMnvB,OAAK+E,WAAWH,EAAGW,EAAMrB,GACpBjB,IAAI,CAACkI,EAAajG,IAAMiG,EAAMnH,EAAMkB,IAC/CkqB,EAASpvB,OAAKuU,WAAW4a,EAAMttB,EAAMoD,OAAQ6pB,GACnDI,EAAQtqB,GAAKS,EAAK+pB,GAEpB,OAAOF,WAGOxpB,GACZ2hB,GAEF,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B1mB,EAACA,GAAK2mB,GACNtjB,MAACA,EAAKa,KAAEA,GAAQwkB,EAEtB5pB,EAAiBkB,EAAG,SAEpB,MAAO0uB,EAAQC,GAASlrB,aAAWmrB,iBAAiB5uB,EAAGqD,EAAOa,GAC9DT,aAAWorB,kBAAkB7uB,EAAG0uB,EAAQC,GAExC,MACMJ,EAAUP,GADHjuB,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACRytB,EAAQC,EAAO3uB,EAAEkB,MAAOlB,EAAET,OAC1D,OAAOQ,EAAQgoB,eAAe4G,EAAO3uB,EAAET,MAAOgvB,GAGzC,MAAMO,GAA4B,CACvCxI,WAAYyI,QACZvI,YAAa,MACbC,WAAY1hB,IC5CDiqB,GACT/H,GAA+BrgB,EAAQC,IAAWD,EAASC,GAClDooB,GACTpE,GAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CAACroB,KAAM8nB,EAAQM,EAAOloB,KAAM6nB,EAAQM,KAEpC4E,GAAM1F,EAAiB2F,MAAKH,GAASC,IAErCG,GAA0B,CACrC9I,WAAY6I,MACZ3I,YAAa,MACbC,WAAYyI,aCbEG,GACZ5qB,EAAmB6qB,EAAkB/vB,EAAiBgwB,EACtD/b,GACF,MAAMgc,EAAQF,EAAOhrB,OACfonB,EAAQrsB,OAAK8J,cAAcmmB,GAC3BnB,EAAW9uB,OAAKioB,eAAegI,GAC/BG,EAAapwB,OAAKioB,eAAe9T,GAEjC/N,EAASpG,OAAKmoB,uBAChBjoB,EAA0BF,OAAK8J,cAAcqK,IAEjD,IAAK,IAAIvP,EAAI,EAAGA,EAAIynB,IAASznB,EAAG,CAC9B,MAAME,EAAM9E,OAAK+E,WAAWH,EAAGurB,EAAOrB,GAGhC9pB,EAAmB,IAAIpF,MAAMkF,EAAIG,QACvC,IAAK,IAAIL,EAAI,EAAGA,EAAII,EAAOC,OAAQL,IACjCI,EAAOJ,GAAKE,EAAIorB,EAAKtrB,IAIvBwB,EADiBpG,OAAKuU,WAAWvP,EAAQmrB,EAAOC,IAC7BhrB,EAAMR,GAE3B,OAAOwB,WCxBOiqB,GACZzuB,EAAuB2C,EAAc1C,EAAiB3B,GAMxD,MAAMowB,EAAQtwB,OAAK0G,eAAenC,EAAM1C,GAAO,GAyDzCsS,EAAW,CAAC,EAAGtS,EAAM,GAAI,GAC/B,IAAK,IAAI+C,EAAI,EAAGA,EAAI0rB,EAAO1rB,IACzBuP,EAAS,IAAMtS,EAAM+C,GAEvBuP,EAAS,GAAKtS,EAAMyuB,GACpB,IAAK,IAAI1rB,EAAI0rB,EAAQ,EAAG1rB,EAAI/C,EAAMoD,OAAQL,IACxCuP,EAAS,IAAMtS,EAAM+C,GAKvB,MAAM2rB,EAA0C,GAG1Crc,EAAU,IAAI0V,WAAW/nB,EAAMyuB,IAE/BE,EAAc,IAAIvK,eAAa9R,EAAUjU,EAAO0B,GAGhD6uB,EAA0B,GAC1BC,EAA6B,IAAhBvc,EAAS,IAA4B,IAAhBA,EAAS,GACjD,IAAK,IAAIvP,EAAI,EAAGA,EAAI/C,EAAMyuB,GAAQ1rB,IAAK,CAErC,IAAI+rB,EACJ,GAAID,EAEFC,EAAU/uB,EAAOgD,GAAG2b,eACf,CACL,MAAMqQ,EAAa,GACnB,IAAK,IAAIC,EAAI,EAAGA,EAAI1c,EAAS,GAAI0c,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAI3c,EAAS,GAAI2c,IAC/BF,EAAWlmB,KAAK8lB,EAAYxuB,IAAI6uB,EAAGjsB,EAAGksB,IAG1CH,EAAUC,EAAWG,KAAK,KAI5B,QAAgCC,IAA5BT,EAAeI,GACjBzc,EAAQtP,GAAK2rB,EAAeI,OACvB,CACL,MAAMM,EAAcC,OAAOC,KAAKZ,GAAgBtrB,OAChDsrB,EAAeI,GAAWM,EAC1B/c,EAAQtP,GAAKqsB,EACbR,EAAc/lB,KAAK9F,IAOvB,MAAMwsB,EAAiBjd,EAASzO,QAChC0rB,EAAe,GAAKF,OAAOC,KAAKZ,GAAgBtrB,OAChD,MAAMosB,EAAe,IAAIpL,eAAamL,EAAgBlxB,GACtDuwB,EAAc3wB,QAAQ,CAACwxB,EAAoB1sB,KACzC,IAAK,IAAIisB,EAAI,EAAGA,EAAI1c,EAAS,GAAI0c,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAI3c,EAAS,GAAI2c,IAC/BO,EAAajvB,IAAIouB,EAAYxuB,IAAI6uB,EAAGS,EAAoBR,GAAID,EAAGjsB,EAAGksB,KAOxE,MAAMxL,EAAczjB,EAAM6D,QAG1B,OAFA4f,EAAYgL,GAASc,EAAe,GAE7B,CACLG,aAAcF,EAAazvB,OAC3B0jB,YAAAA,EACApR,QAAAA,yOC3HY,MAAO,IAAM,IAAI9S,EAAkB,GCT5C,MAAMowB,GAAiBpF,EAAgBqF,OAAOhF,GAAOhlB,KAAKiqB,KAAKjF,IAEzDkF,GAA2B,CACtC1K,WAAYwK,OACZtK,YAAa,MACbC,WAAYoK,ICLDI,GAAkBxF,EAAgByF,QAAQpF,GAAOhlB,KAAKqqB,MAAMrF,IAE5DsF,GAA4B,CACvC9K,WAAY4K,QACZ1K,YAAa,MACbC,WAAYwK,ICLDI,GAAiB5F,EAAgB6F,OAAOxF,GAAOhlB,KAAKyqB,KAAKzF,IAEzD0F,GAA2B,CACtClL,WAAYgL,OACZ9K,YAAa,MACbC,WAAY4K,ICLDI,GAAkBhG,EAAgBiG,QAAQ5F,GAAOhlB,KAAK6qB,MAAM7F,IAE5D8F,GAA4B,CACvCtL,WAAYoL,QACZlL,YAAa,MACbC,WAAYgL,ICLDI,GAAiBpG,EAAgBqG,OAAOhG,GAAOhlB,KAAKirB,KAAKjG,IAEzDkG,GAA2B,CACtC1L,WAAYwL,OACZtL,YAAa,MACbC,WAAYoL,ICLDI,GAAkBxG,EAAgByG,QAAQpG,GAAOhlB,KAAKqrB,MAAMrG,IAE5DsG,GAA4B,CACvC9L,WAAY4L,QACZ1L,YAAa,MACbC,WAAYwL,aCPEI,GACZ1f,EAAqB2c,EAAkB/vB,EAAiBgE,EACxD0I,EACA0I,GACF,MAAM5G,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBpC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBuI,EAAwB5I,EAAS4I,sBACjCC,EAAuB7I,EAAS6I,qBAChCpI,EAAST,EAASO,QAAQG,IAC1BJ,EAAUN,EAASO,QAAQC,KAE3BsI,EACY,QAAbJ,EAAqBK,OAAOC,kBACPD,OAAOE,kBAE3BC,EAASrR,SAAOmI,EAASzI,SAAUjE,GACnC6V,EAAaD,EAAOlU,OAEpBoU,EACFpJ,EAASzI,SAAS,GAAKyI,EAASzI,SAAS,GAAKyI,EAASzI,SAAS,GAC9D+R,EAAmBtJ,EAASzI,SAAS,GAAKyI,EAASzI,SAAS,GAC5DgS,EAAmBvJ,EAASzI,SAAS,GAE3C,IAAK,IAAI8C,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EAAG,CAC3C,MAAMoP,EAAoBpP,EAAI+O,EACxBM,EAAmBrP,EAAI/C,EAAQ,GACrC,IAAK,IAAIhB,EAAI,EAAGA,EAAI0J,EAAS+C,aAAczM,EACzC,IAAK,IAAIoL,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAAI,CAC9C,MAAMG,EAAWH,EAAKI,EAAerB,EAC/BkE,EAAQ9J,KAAKb,IAAI,EAAG6H,GACpBwkB,EACFxrB,KAAKsB,IAAI6D,EAASiC,SAAU2G,EAAwB/G,GAClDwI,EAAkBZ,EAAoB/H,EAAK4H,EACjD,IAAK,IAAIlH,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAAI,CAC7C,MAAMG,EAAWH,EAAKI,EAAclC,EAC9BwE,EAAQjK,KAAKb,IAAI,EAAGuI,GACpB+jB,EACFzrB,KAAKsB,IAAI6D,EAAS2C,QAASkG,EAAuBtG,GACtD,IAAIoI,EAAc7B,EACd8B,EAAW,EACXC,EAAQ,EACZ,IAAK,IAAI7I,EAAK2C,EAAO3C,EAAKqkB,EAAOrkB,GAAM5B,EAAgB,CACrD,MAAMmmB,EAAW7c,EAAmB1H,EAAK1K,EAAQ,GACjD,IAAK,IAAIoL,EAAKoC,EAAOpC,EAAK4jB,EAAO5jB,GAAMrC,EAAe,CACpD,MACM8K,EAAQzE,EADG6f,EAAW7jB,EAAKpL,EAAQ,GACRhB,GACf,QAAboS,GAAsByC,EAAQR,EACjCA,EAAcQ,EACQ,QAAbzC,IACTkC,GAAYO,EACZN,KAGJ,GAAIO,MAAMT,GACR,MAIJxB,EADqBkB,EAAkBjI,EAAKmH,EAAmBjT,GAE9C,QAAboS,EAAqBkC,EAAWC,EAAQF,IAKpD,OAAOzB,WAGOsd,GACZ9f,EAAqB2c,EAAkB/vB,EACvC0M,EAAmCymB,GAAmB,EACtDC,GAAsB,GACxB,MAAMta,EAAevU,SAAOmI,EAASzI,SAAU,SACzCuK,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBpC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBuI,EAAwB5I,EAAS4I,sBACjCC,EAAuB7I,EAAS6I,qBAChCpI,EAAST,EAASO,QAAQG,IAC1BJ,EAAUN,EAASO,QAAQC,KAE3B1I,EAAOD,SAAOwrB,EAAQ/vB,EAAOoT,GACnC,IAAK,IAAIrM,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EACxC,IAAK,IAAI/D,EAAI,EAAGA,EAAI0J,EAAS+C,aAAczM,EACzC,IAAK,IAAIoL,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAAI,CAC9C,MAAMG,EAAWH,EAAKI,EAAerB,EACrC,IAAIkE,EAAQ9C,EACZ,KAAO8C,EAAQ,GACbA,GAASvE,EAGX,MAAMimB,EACFxrB,KAAKsB,IAAI6D,EAASiC,SAAU2G,EAAwB/G,GACxD,IAAK,IAAIO,EAAK,EAAGA,EAAKpC,EAASqC,WAAYD,EAAI,CAC7C,MAAMG,EAAWH,EAAKI,EAAclC,EACpC,IAAIwE,EAAQvC,EACZ,KAAOuC,EAAQ,GACbA,GAASzE,EAEX,MAAMimB,EACFzrB,KAAKsB,IAAI6D,EAAS2C,QAASkG,EAAuBtG,GACtD,IAAI8J,EAAWtD,OAAOC,kBAClBsD,GAAe,EAEnB,IAAK,IAAItK,EAAK2C,EAAO3C,EAAKqkB,EAAOrkB,GAAM5B,EAAgB,CACrD,MAAM2B,EAAKC,EAAKH,EAChB,IAAK,IAAIa,EAAKoC,EAAOpC,EAAK4jB,EAAO5jB,GAAMrC,EAAe,CACpD,MAAMoC,EAAKC,EAAKH,EACV4I,EAAQrT,EAAK1C,IAAIiF,EAAG2H,EAAIU,EAAIpM,GAC9B6U,EAAQkB,IACVA,EAAWlB,EAETmB,EADEma,EACYC,IACRrsB,EAAI2F,EAASiC,SAAWD,GAAMhC,EAAS2C,QAAUD,GAC3C1C,EAAS+C,WACbzM,GACH0L,EAAKhC,EAAS2C,QAAUD,GAAM1C,EAAS+C,WAAazM,EAE3CyL,EAAK8G,EAAuBpG,IAKlD2J,EAAa5W,IAAI8W,EAAajS,EAAGqH,EAAIU,EAAI9L,IAKjD,OAAO8V,EC7FF,MAAMua,GAA8B,CACzCtM,WAAYuM,UACZrM,YAAa,MACbC,oBAnCEC,GAGF,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B1mB,EAACA,GAAK2mB,EACZ7nB,EAAiBkB,EAAG,WACpB,MAAM8yB,WAACA,EAAUvvB,QAAEA,EAAOwvB,IAAEA,EAAGC,gBAAEA,GAAmBtK,EAGpDrpB,OAAKC,OACDgC,eAAa2xB,+BAA+B1vB,EAH9B,GAId,IAAM,4DACF,eAAeA,uBAEvB,MAAM0I,EAAW3K,eAAa4xB,kBAC1BlzB,EAAEkB,MAA2C4xB,EAAYvvB,EAR3C,EASHwvB,EAAKC,GACpB,IAAIhuB,EAEJ,GAA6B,IAAzBiH,EAASG,aAA+C,IAA1BH,EAASE,cACvC9M,OAAK8zB,YAAYlnB,EAASmE,QAASnE,EAASzI,UAC9CwB,EAAMkjB,EAAS,CAACvB,OAAQ,CAAC3mB,EAAAA,GAAID,QAAAA,QACxB,CACL,MAAM4S,EAAU5S,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACrCsC,EAAUlE,OAAKioB,eAAetnB,EAAEkB,OAChC4C,EAASuuB,GAAK1f,EAAS3S,EAAEkB,MAAOlB,EAAET,MAAOgE,EAAS0I,EAAU,OAClEjH,EAAMjF,EAAQgoB,eACV9b,EAASzI,SAAUxD,EAAET,MAAOuE,EAAO7C,QAEzC,OAAO+D,ICkCF,MAAMouB,GAAsC,CACjD9M,WAAY+M,kBACZ7M,YAAa,MACbC,oBArE8BC,GAK9B,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3Bnb,GAACA,EAAEQ,MAAEA,GAAS4a,EACd3mB,EAAI+L,EACVjN,EAAiB,CAACyM,EAAIQ,GAAQ,mBAC9B,MAAM+mB,WAACA,EAAUvvB,QAAEA,EAAOwvB,IAAEA,GAAOrK,EAE7Bzc,EAAW3K,eAAa4xB,kBAC1BlzB,EAAEkB,MAA2C4xB,EAAYvvB,EACzD,EAAmBwvB,GACjBhlB,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBtC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBuI,EAAwB5I,EAAS4I,sBACjCC,EAAuB7I,EAAS6I,qBAChCvI,EAAUuI,EAAuB,EAAI7I,EAASO,QAAQC,KACtDC,EAASmI,EAAwB,EAAI5I,EAASO,QAAQG,IACtDwD,EACFrM,SAAgB9D,EAAEkB,MAA2C,WAE3DsW,EAAgB,GAAKrL,EAAeC,GAEpCknB,EAASvzB,EAAQe,KAAKO,IAAIkK,EAAG/J,QAAQP,OACrCiR,EAAQpO,SACVyH,EAAGrK,MAA2C,UAAWoyB,GAE7D,IAAK,IAAIhtB,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EACxC,IAAK,IAAI/D,EAAI,EAAGA,EAAI0J,EAAS+C,aAAczM,EACzC,IAAK,IAAI4Y,EAAM,EAAGA,EAAMlP,EAASiC,WAAYiN,EAC3C,IAAK,IAAIO,EAAM,EAAGA,EAAMzP,EAAS2C,UAAW8M,EAAK,CAE/C,MAAM6X,EAAYpY,EAAMzO,EAClB8mB,EAAY9X,EAAMnP,EACxB,IAAI0E,EAAU,EACd,IAAK,IAAIjD,EAAK,EAAGA,EAAK6G,EAAuB7G,GAAM3B,EAAgB,CACjE,MAAMoR,GAAO8V,EAAYvlB,GAAMD,EAC/B,KAAI0P,EAAM,GAAKA,GAAOxR,EAAS2B,WAC3B9G,KAAK6B,MAAM8U,KAASA,GAGxB,IAAK,IAAI/O,EAAK,EAAGA,EAAKoG,EAAsBpG,GAAMpC,EAAe,CAC/D,MAAMsR,GAAO4V,EAAY9kB,GAAMD,EAC3BmP,EAAM,GAAKA,GAAO3R,EAASqC,UAC3BxH,KAAK6B,MAAMiV,KAASA,IAKxB3M,GADciB,EAAM7Q,IAAIiF,EAAGmX,EAAKG,EAAKrb,KAIzC4N,EAAG1O,IAAIwP,EAAUuG,EAAelR,EAAG6U,EAAKO,EAAKnZ,GAKrD,OAAOxC,EAAQgoB,eAAe5X,EAAGjP,MAAOiP,EAAG5Q,MAAO4Q,EAAGlP,UCKhD,MAAMwyB,GAAgC,CAC3CnN,WAAYoN,iBACZlN,YAAa,MACbC,oBAtEkCC,GAKlC,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B1mB,EAACA,EAAC2zB,MAAEA,EAAKtqB,OAAEA,EAAMuqB,KAAEA,EAAIC,SAAEA,GAAYlN,EAE3CtnB,OAAKC,OACDs0B,EAAK1yB,MAAMoD,SAAWuvB,EAAS3yB,MAAMoD,OACrC,IAAM,gFAEVjF,OAAKC,OACS,MAAV+J,GAAkBuqB,EAAK1yB,MAAMoD,SAAW+E,EAAOnI,MAAMoD,OACrD,IAAM,8EAEVjF,OAAKC,OACQ,MAATq0B,GAAiBC,EAAK1yB,MAAMoD,SAAWqvB,EAAMzyB,MAAMoD,OACnD,IAAM,6EAGVxF,EAAiB,CAACkB,EAAG4zB,EAAMC,EAAUF,EAAOtqB,GAAS,aAErD,IAAIyqB,gBAACA,GAAmBpL,EACD,MAAnBoL,IACFA,EAAkB,MAGpB,MAAMrvB,EAAQ1E,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACnC8yB,EAAQh0B,EAAQe,KAAKO,IAAIuyB,EAAKpyB,QAAQP,OACtC+yB,EAAUj0B,EAAQe,KAAKO,IAAIwyB,EAASryB,QAAQP,OAC5CgzB,EAAQN,EAAQ5zB,EAAQe,KAAKO,IAAIsyB,EAAMnyB,QAAQP,OAC/B,IAAIyK,aAAa,CAAC,IAClCwoB,EAAU7qB,EACZtJ,EAAQe,KAAKO,IAAIgI,EAAO7H,QAAQP,OAChC,IAAIyK,aAAa,CAAC,IAChB6iB,EAAU,IAAI7iB,aAAajH,EAAMH,QAEjC6vB,EAAgBD,EAAQ5vB,OACxB8vB,EAAcH,EAAM3vB,OACpB+vB,EAAgBL,EAAQ1vB,OACxBgwB,EAAcP,EAAMzvB,OAE1B,IAAIiwB,EAAO,EACPC,EAAK,EACLC,EAAK,EACLC,EAAK,EACT,IAAK,IAAIzwB,EAAI,EAAGA,EAAIQ,EAAMH,SAAUL,EAClCsqB,EAAQtqB,GAAKiwB,EAAQK,MAChB9vB,EAAMR,GAAK8vB,EAAMS,MAASP,EAAMQ,KAC7B3tB,KAAK8mB,KAAKoG,EAAQU,KAAQZ,GAC9BS,GAAQJ,IACVI,EAAO,GAELC,GAAMF,IACRE,EAAK,GAEHC,GAAML,IACRK,EAAK,GAEHC,GAAML,IACRK,EAAK,GAGT,OAAO30B,EAAQgoB,eAAe/nB,EAAEkB,MAAOlB,EAAET,MAAOgvB,KCjErCoG,GAAiBlJ,EAAgBmJ,cAAa,CAAC9I,EAAIpD,KAC9D,MAAMmM,EAAYnM,EAClB,OAAIoD,EAAK+I,EAAUC,aACVD,EAAUC,aAEZhJ,EAAK+I,EAAUE,aAAeF,EAAUE,aAAejJ,IAGnDkJ,GAA2B,CACtC1O,WAAYsO,cACZpO,YAAa,MACbC,WAAYkO,aCXExyB,GAAKukB,GAEnB,MAAMC,OAACA,EAAM5mB,QAAEA,GAAW2mB,GACpB3a,MAACA,GAAS4a,EAEVxkB,EAAOpC,EAAQe,KAAKO,IAAI0K,EAAMvK,QAAQO,mBAAmBI,KACzD8yB,EAAUl1B,EAAQe,KAAKO,IAAIc,EAAKX,QAAQP,OAK9C,OAAOlB,EAAQgoB,eAAe5lB,EAAKjB,MAAOiB,EAAK5C,MAAO01B,GAGjD,MAAMC,GAA2B,CACtC5O,WAAY6O,OACZ3O,YAAa,MACbC,WAAYtkB,aCjBE+C,GACZwhB,GAGF,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B1mB,EAACA,GAAK2mB,GACNzlB,MAACA,GAASwnB,EAEVgD,EAAQrsB,OAAK8J,cAAcnJ,EAAEkB,OAC7Bk0B,EAAS/1B,OAAKg2B,uBAAuBn0B,EAAOwqB,GAC5C4J,EAASj2B,OAAK8J,cAAcisB,GAElC/1B,OAAKC,OACDosB,IAAU4J,EACV,IAAM,kBAAkBF,UAAeE,0BACnC,UAAUt1B,EAAEkB,cAAcwqB,qCAC1B,gDAER3rB,EAAQooB,OAAOnoB,EAAEwB,QAEjB,MAAMgkB,EAAQzlB,EAAQe,KAAKO,IAAIrB,EAAEwB,QAEjC,GAAgC,MAA5BgkB,EAAMzjB,mBAA4B,CACpC,MAAME,EAAOujB,EAAMzjB,mBAAmBE,KAChCE,EAAOqjB,EAAMzjB,mBAAmBI,KAEtCF,EAAKf,MAAQk0B,EACbjzB,EAAKjB,MAAQk0B,EAGf,MAAO,CAAC5zB,OAAQxB,EAAEwB,OAAQN,MAAOk0B,EAAQ71B,MAAOS,EAAET,OAG7C,MAAMg2B,GAA8B,CACzCjP,WAAYkP,UACZhP,YAAa,MACbC,WAAYvhB,aC/BEuwB,GACZ/O,GAEF,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B9iB,KAACA,GAAQ8kB,EAETiH,EAAQtwB,OAAK0G,eAAenC,EAAM+iB,EAAO,GAAGzlB,OAAO,GACzD,IAAIsC,EAAWlC,eAAaoC,gBAAgBijB,EAAOrkB,IAAIlD,GAAKA,EAAE8B,OAAQyuB,GAEtE,GAAqC,IAAjCtwB,OAAK8J,cAAc3F,GACrB,OAAOzD,EAAQgoB,eAAevkB,EAAUmjB,EAAO,GAAGpnB,MAAO,IAI3D,MAAMm2B,EAAU/O,EAAO3a,OAAO5M,GAAKC,OAAK8J,cAAc/J,EAAE8B,OAAS,GACjE,GAAuB,IAAnBw0B,EAAQpxB,OACV,OAAOoxB,EAAQ,GAGjB,MAAMC,EAASD,EAAQpzB,IAAIlD,GAAKA,EAAE8B,OAGlC,GAFAI,eAAas0B,uBAAuBD,EAAQhG,GAEnB,cAArB+F,EAAQ,GAAGn2B,MAAuB,CACpC,MAAMs2B,EAAQH,EAAQpzB,IAAKlD,GAAM6C,EAAK,CAAC0kB,OAAQ,CAAC5a,MAAO3M,GAAIW,QAAAA,KACrD+1B,EAAQJ,EAAQpzB,IAAKlD,GAAM+C,GAAK,CAACwkB,OAAQ,CAAC5a,MAAO3M,GAAIW,QAAAA,KAErDg2B,EAAeN,GAAO,CAAC9O,OAAQkP,EAAO91B,QAAAA,EAAS2oB,MAAO,CAAC9kB,KAAAA,KACvDoyB,EAAeP,GAAO,CAAC9O,OAAQmP,EAAO/1B,QAAAA,EAAS2oB,MAAO,CAAC9kB,KAAAA,KAEvD6B,EACFoiB,EAAQ,CAAClB,OAAQ,CAAC1kB,KAAM8zB,EAAc5zB,KAAM6zB,GAAej2B,QAAAA,IAO/D,OALA81B,EAAM12B,QAAQma,GAAKvZ,EAAQ+oB,8BAA8BxP,IACzDwc,EAAM32B,QAAQ8E,GAAKlE,EAAQ+oB,8BAA8B7kB,IACzDlE,EAAQ+oB,8BAA8BiN,GACtCh2B,EAAQ+oB,8BAA8BkN,GAE/BvwB,EAUT,MAAMwwB,EAAWP,EAAQpzB,IAAIlD,IAC3B,MAAM82B,EAAY72B,OAAK8J,cAAc/J,EAAE8B,MAAM6D,MAAM4qB,IAEnD,OAAOzqB,GAAQ,CAACyhB,OAAQ,CAAC3mB,EAAGZ,GAAIW,QAAAA,EAAS2oB,MAAO,CAACxnB,MADnC,EAAE,EAAGg1B,QAKrB1yB,EACIlC,eAAaoC,gBAAgBuyB,EAAS3zB,IAAIlD,GAAKA,EAAE8B,OAAQ,GAE7D,MAAMqtB,EAAUlvB,OAAKmoB,uBACjBkO,EAAQ,GAAGn2B,MAAoBF,OAAK8J,cAAc3F,IAEtD,GAA6B,IAAzByyB,EAAS,GAAG/0B,MAAM,GAAU,CAE9B,IAAImI,EAAS,EACb4sB,EAAS92B,QAAQC,IACf,MAAMof,EAAMze,EAAQe,KAAKO,IAAIjC,EAAEoC,QAAQP,OACjCiD,EAAO7E,OAAK8J,cAAc/J,EAAE8B,OAElCqtB,EAAQ9sB,IAAI+c,EAAKnV,GACjBA,GAAUnF,QAEP,CACL,IAAI2Y,EAAY,EAEhBoZ,EAAS92B,QAAQC,IACf,MAAM+2B,EAAQp2B,EAAQe,KAAKO,IAAIjC,EAAEoC,QAAQP,OAEzC,IAAIm1B,EAAO,EAEX,IAAK,IAAIC,EAAM,EAAGA,EAAMj3B,EAAE8B,MAAM,KAAMm1B,EAAK,CACzC,MAAMC,EAASD,EAAM7yB,EAAS,GAAKqZ,EACnC,IAAK,IAAI0Z,EAAM,EAAGA,EAAMn3B,EAAE8B,MAAM,KAAMq1B,EACpChI,EAAQ+H,EAASC,GAAOJ,EAAMC,KAIlCvZ,GAAazd,EAAE8B,MAAM,KAIzB,MAAMs1B,EACFl1B,eAAaoC,gBAAgBgyB,EAAQpzB,IAAIlD,GAAKA,EAAE8B,OAAQyuB,GAEtD8G,EACF12B,EAAQgoB,eAAeyO,EAAe7P,EAAO,GAAGpnB,MAAOgvB,GAI3D,OAFA0H,EAAS92B,QAAQC,GAAKW,EAAQ+oB,8BAA8B1pB,IAErDq3B,EAGF,MAAMC,GAA6B,CACxCpQ,WAAYqQ,SACZnQ,YAAa,MACbC,WAAYgP,IC5GDmB,GAAgBnL,EAAgBoL,MAAM/K,GAAOhlB,KAAKgwB,IAAIhL,IAEtDiL,GAA0B,CACrCzQ,WAAYuQ,MACZrQ,YAAa,MACbC,WAAYmQ,ICLDI,GAAiBvL,EAAgBwL,OAAOnL,GAAOhlB,KAAKowB,KAAKpL,IAEzDqL,GAA2B,CACtC7Q,WAAY2Q,OACZzQ,YAAa,MACbC,WAAYuQ,ICLDI,GAAiC,CAC5C9Q,WAAY+Q,aACZ7Q,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ5mB,QAAAA,EAAS2oB,MAAAA,MAC7B,MAAM1oB,EAACA,EAACgM,OAAEA,GAAU2a,GACdpjB,QAACA,EAAOwvB,IAAEA,EAAGuE,UAAEA,GAAa5O,EAC5B9B,EAAa7mB,EAEb0E,EAAQmiB,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,OACtCuuB,EAAQxvB,EAAEkB,MAAMoD,OAEhBizB,EAAa3Q,EAAW9lB,KAAKO,IAAI2K,EAAOxK,QAAQP,OAChDu2B,EAAaxrB,EAAO9K,MAAMoD,QAE1BkJ,UACJA,EAASU,SACTA,EAAQU,QACRA,EAAOI,WACPA,EAAUpB,UACVA,EAASU,SACTA,EAAQ9B,QACRA,EAAOuB,aACPA,EAAYU,YACZA,EAAWtC,aACXA,EAAYC,YACZA,EAAWC,eACXA,EAAcC,cACdA,EAAa9I,SACbA,GAEElC,eAAam2B,sBACTz3B,EAAEkB,MACF8K,EAAO9K,MAAmCqC,EAASwvB,EACnD,OAAyBuE,GAE3BI,EAAUr4B,OAAK8J,cAAc3F,GAC7Bm0B,EAAUn0B,EAASc,OACnB8Q,EAAa/V,OAAKumB,kBAAkB5lB,EAAET,MAAOm4B,GAMnD,IAAK,IAAIpxB,EAAI,EAAGA,EAAIkH,IAAalH,EAC/B,IAAK,IAAIsxB,EAAO,EAAGA,EAAOhqB,IAAagqB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7pB,EAAevB,EAAQG,IAC3C,IAAK,IAAImrB,EAAO,EAAGA,EAAOxpB,IAAYwpB,EAAM,CAC1C,MAAMC,EAAOD,EAAOrpB,EAAcjC,EAAQC,KAC1C,IAAK,IAAIlK,EAAI,EAAGA,EAAIyM,IAAczM,EAAG,CACnC,IAAIy1B,EAAShjB,OAAOijB,iBACpB,IAAK,IAAIjX,EAAI,EAAGA,EAAI7U,IAAgB6U,EAAG,CACrC,MAAMkX,EAAML,EAAO7W,EAAI3U,EACvB,GAAI6rB,GAAO,GAAKA,EAAMhqB,EACpB,IAAK,IAAIiT,EAAI,EAAGA,EAAI/U,IAAe+U,EAAG,CACpC,MAAMgX,EAAMJ,EAAO5W,EAAI7U,EACvB,GAAI6rB,GAAO,GAAKA,EAAMvpB,EAAS,CAC7B,MAAM6f,EAASpvB,OAAKuU,WAChB,CAACtN,EAAG4xB,EAAKC,EAAK51B,GAAIitB,EAAOnwB,OAAKioB,eAAetnB,EAAEkB,QAC7Ck3B,EAAc/4B,OAAKuU,WACrB,CAACoN,EAAGG,EAAG5e,GAAIi1B,EACXn4B,OAAKioB,eAAetb,EAAO9K,QACzBsd,EAAM/Z,EAAMgqB,GAAU8I,EAAWa,GACnC5Z,EAAMwZ,IACRA,EAASxZ,KAQnBpJ,EAFoB/V,OAAKuU,WACrB,CAACtN,EAAGsxB,EAAME,EAAMv1B,GAAIo1B,EAASt4B,OAAKioB,eAAe9jB,KAC3Bw0B,IASlC,MAAO,CAACx2B,OAHOolB,EAAWjlB,MACtBtC,OAAK+pB,aAAahU,EAAYpV,EAAET,OAAQiE,EAAUxD,EAAET,OAExC2B,MAAOsC,EAAUjE,MAAOS,EAAET,SC/EjC84B,GAA+C,CAC1D/R,WAAYgS,2BACZ9R,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ5mB,QAAAA,EAAS2oB,MAAAA,MAC7B,MAAM1oB,EAACA,EAACgM,OAAEA,EAAMT,GAAEA,GACdob,GACEpjB,QAACA,EAAOwvB,IAAEA,EAAGuE,UAAEA,GAAa5O,EAC5B9B,EAAa7mB,EAEbw4B,EACFl5B,OAAKm5B,cACDx4B,EAAEkB,MAAO0lB,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,QAGzCw3B,EAAUp5B,OAAKm5B,cACDxsB,EAAO9K,MACP0lB,EAAW9lB,KAAKO,IAAI2K,EAAOxK,QAAQP,SAGjDuM,UACJA,EAASU,SACTA,EAAQU,QACRA,EAAOI,WACPA,EAAUpB,UACVA,EAASU,SACTA,EAAQ9B,QACRA,EAAOuB,aACPA,EAAYU,YACZA,EAAWtC,aACXA,EAAYC,YACZA,EAAWC,eACXA,EAAcC,cACdA,EAAa9I,SACbA,GAEElC,eAAam2B,sBACTz3B,EAAEkB,MACF8K,EAAO9K,MAAmCqC,EAASwvB,EACnD,OAAyBuE,GAEjCj4B,OAAKC,OACDiM,EAAG3G,OAASpB,EAASc,OACrB,IAAM,YAAYg0B,kCACd,qCAAqC90B,EAASc,mBAC9C,GAAGiH,EAAG3G,QAEd,MAAM8zB,EACFr5B,OAAKm5B,cACDh1B,EAAUojB,EAAW9lB,KAAKO,IAAIkK,EAAG/J,QAAQP,QAK3C03B,EAAYt5B,OAAKu5B,0BACD5sB,EAAO9K,MAAO8K,EAAOzM,OAO3C,IAAK,IAAI+G,EAAI,EAAGA,EAAIkH,IAAalH,EAC/B,IAAK,IAAIsxB,EAAO,EAAGA,EAAOhqB,IAAagqB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7pB,EAAevB,EAAQG,IAC3C,IAAK,IAAImrB,EAAO,EAAGA,EAAOxpB,IAAYwpB,EAAM,CAC1C,MAAMC,EAAOD,EAAOrpB,EAAcjC,EAAQC,KAC1C,IAAK,IAAIlK,EAAI,EAAGA,EAAIyM,IAAczM,EAAG,CACnC,IAAIy1B,EAAShjB,OAAOijB,iBAChBY,EAAO,EACPC,EAAO,EACX,IAAK,IAAI9X,EAAI,EAAGA,EAAI7U,IAAgB6U,EAAG,CACrC,MAAMkX,EAAML,EAAO7W,EAAI3U,EACvB,GAAI6rB,GAAO,GAAKA,EAAMhqB,EACpB,IAAK,IAAIiT,EAAI,EAAGA,EAAI/U,IAAe+U,EAAG,CACpC,MAAMgX,EAAMJ,EAAO5W,EAAI7U,EACvB,GAAI6rB,GAAO,GAAKA,EAAMvpB,EAAS,CAC7B,MAAM4P,EAAM+Z,EAAGjyB,GAAG4xB,GAAKC,GAAK51B,GAAKk2B,EAAQzX,GAAGG,GAAG5e,GAC3Cic,EAAMwZ,IACRA,EAASxZ,EACTqa,EAAO7X,EACP8X,EAAO3X,KAMjBwX,EAAUE,GAAMC,GAAMv2B,IAAMm2B,EAAIpyB,GAAGsxB,GAAME,GAAMv1B,KASvD,MAAO,CAACf,OAHOolB,EAAWjlB,MACtBtC,OAAK+pB,aAAauP,EAAW34B,EAAET,OAAQyM,EAAO9K,MAAO8K,EAAOzM,OAEhD2B,MAAO8K,EAAO9K,MAAO3B,MAAOyM,EAAOzM,SC/F1Cw5B,GAA8C,CACzDzS,WAAY0S,0BACZxS,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ5mB,QAAAA,EAAS2oB,MAAAA,MAC7B,MAAM1oB,EAACA,EAACgM,OAAEA,EAAMT,GAAEA,GACdob,GACEpjB,QAACA,EAAOwvB,IAAEA,EAAGuE,UAAEA,GAAa5O,EAC5B9B,EAAa7mB,EAEbw4B,EACFl5B,OAAKm5B,cACDx4B,EAAEkB,MAAO0lB,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,QAGzCw3B,EAAUp5B,OAAKm5B,cACDxsB,EAAO9K,MACP0lB,EAAW9lB,KAAKO,IAAI2K,EAAOxK,QAAQP,SAGjDuM,UACJA,EAASU,SACTA,EAAQU,QACRA,EAAOI,WACPA,EAAUpB,UACVA,EAASU,SACTA,EAAQ9B,QACRA,EAAOuB,aACPA,EAAYU,YACZA,EAAWtC,aACXA,EAAYC,YACZA,EAAWC,eACXA,EAAcC,cACdA,EAAa9I,SACbA,GAEElC,eAAam2B,sBACTz3B,EAAEkB,MACF8K,EAAO9K,MAAmCqC,EAASwvB,EACnD,OAAyBuE,GAEjCj4B,OAAKC,OACDiM,EAAG3G,OAASpB,EAASc,OACrB,IAAM,YAAY00B,iCACd,qCAAqCx1B,EAASc,mBAC9C,GAAGiH,EAAG3G,QAEd,MAAM8zB,EACFr5B,OAAKm5B,cACDh1B,EAAUojB,EAAW9lB,KAAKO,IAAIkK,EAAG/J,QAAQP,QAK3C03B,EACFt5B,OAAKu5B,0BAA0B54B,EAAEkB,MAAOlB,EAAET,OAO9C,IAAK,IAAI+G,EAAI,EAAGA,EAAIkH,IAAalH,EAC/B,IAAK,IAAIsxB,EAAO,EAAGA,EAAOhqB,IAAagqB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7pB,EAAevB,EAAQG,IAC3C,IAAK,IAAImrB,EAAO,EAAGA,EAAOxpB,IAAYwpB,EAAM,CAC1C,MAAMC,EAAOD,EAAOrpB,EAAcjC,EAAQC,KAC1C,IAAK,IAAIlK,EAAI,EAAGA,EAAIyM,IAAczM,EAAG,CACnC,IAAIy1B,EAAShjB,OAAOijB,iBAChBgB,EAAUpB,EAAO,EAAK,EAAIA,EAC1BqB,EAAUnB,EAAO,EAAK,EAAIA,EAC9B,IAAK,IAAI/W,EAAI,EAAGA,EAAI7U,IAAgB6U,EAAG,CACrC,MAAMkX,EAAML,EAAO7W,EAAI3U,EACvB,GAAI6rB,GAAO,GAAKA,EAAMhqB,EACpB,IAAK,IAAIiT,EAAI,EAAGA,EAAI/U,IAAe+U,EAAG,CACpC,MAAMgX,EAAMJ,EAAO5W,EAAI7U,EACvB,GAAI6rB,GAAO,GAAKA,EAAMvpB,EAAS,CAC7B,MAAM4P,EAAM+Z,EAAGjyB,GAAG4xB,GAAKC,GAAK51B,GAAKk2B,EAAQzX,GAAGG,GAAG5e,GAC3Cic,EAAMwZ,IACRA,EAASxZ,EACTya,EAASf,EACTgB,EAASf,KAMnBQ,EAAUryB,GAAG2yB,GAAQC,GAAQ32B,IAAMm2B,EAAIpyB,GAAGsxB,GAAME,GAAMv1B,KAS9D,MAAO,CAACf,OAHOolB,EAAWjlB,MACtBtC,OAAK+pB,aAAauP,EAAW34B,EAAET,OAAQS,EAAEkB,MAAOlB,EAAET,OAEtC2B,MAAOlB,EAAEkB,MAAO3B,MAAOS,EAAET,SC/FhC45B,GACTlS,EAA6B,CAAC7gB,EAAWE,IAAcF,EAAIE,GAClD8yB,GAAM5P,EAAiB6P,MAAKF,IAE5BG,GAA0B,CACrChT,WAAY+S,MACZ7S,YAAa,MACbC,WAAY2S,ICRDG,GACT9N,EAAgB+N,MAAM1N,GAAOA,GAAM,EAAIA,EAAMhlB,KAAKqlB,IAAIL,GAAM,GAEnD2N,GAA0B,CACrCnT,WAAYkT,MACZhT,YAAa,MACbC,WAAY8S,ICNRG,GAAIp4B,eAAaq4B,MACjBC,GAAKt4B,eAAau4B,OAClBC,GAAKx4B,eAAay4B,OAClBC,GAAK14B,eAAa24B,OAClBC,GAAK54B,eAAa64B,OAClBC,GAAK94B,eAAa+4B,OAEXC,GAAgB7O,EACzB8O,MACCzO,IACC,MAAM0O,EAAO1zB,KAAK0zB,KAAK1O,GACjBlgB,EAAI9E,KAAKsf,IAAI0F,GACb1sB,EAAI,GAAO,EAAMs6B,GAAI9tB,GAC3B,OAAO4uB,GACF,MACKJ,GAAKh7B,EAAI86B,IAAM96B,EAAK46B,IAAM56B,EAAI06B,IAAM16B,EAAIw6B,IAAMx6B,EAC/C0H,KAAKqlB,KAAKvgB,EAAIA,MAIhB6uB,GAA0B,CACrCnU,WAAYiU,MACZ/T,YAAa,MACbC,WAAY6T,aCVEI,GACZ3uB,EAAmB4uB,EACnB/T,GACF,MAAMgU,EAAa7uB,EAAM7K,MACnBuU,EAAQmlB,EAAW,GACnBC,EAAWD,EAAW,GAEtBE,EAAYlU,EAAW9lB,KAAKO,IAAI0K,EAAMvK,QAEtCu5B,EAASD,EAAU/4B,mBAAmBE,KACtC+4B,EAASF,EAAU/4B,mBAAmBI,KAGtCgjB,EAAc,CAAC1P,EAAOolB,GACtBtT,EAAaloB,OAAK8J,cAAcgc,GAChCwF,EAAatrB,OAAKmoB,uBAAuB,UAAWD,GACpDqD,EAAavrB,OAAKmoB,uBAAuB,UAAWD,GAE1D,IAAK,IAAIjhB,EAAI,EAAGA,EAAImP,EAAOnP,IAAK,CAE9B,MAAMgT,EAAIvU,GAAM,CACd4hB,OAAQ,CAAC3mB,EAAG+6B,GACZh7B,QAAS6mB,EACT8B,MAAO,CAACrlB,MAAO,CAACiD,EAAG,GAAIpC,KAAM,CAAC,EAAG22B,MAE7B52B,EAAIc,GAAM,CACd4hB,OAAQ,CAAC3mB,EAAGg7B,GACZj7B,QAAS6mB,EACT8B,MAAO,CAACrlB,MAAO,CAACiD,EAAG,GAAIpC,KAAM,CAAC,EAAG22B,MAG7B9uB,EAAQ8b,EAAQ,CAAClB,OAAQ,CAAC1kB,KAAMqX,EAAGnX,KAAM8B,GAAIlE,QAAS6mB,KAGtD3kB,KAACA,EAAIE,KAAEA,GAAQ84B,GAAQlvB,EAAO4uB,EAAS/T,GACvC5hB,EAAM1D,eAAac,uBAAuBH,EAAME,GAEtD,IAAK,IAAII,EAAI,EAAGA,EAAIs4B,EAAUt4B,IAAK,CACjC,MAAMsX,EAAIvY,eAAa45B,oBAAoBl2B,EAAKzC,GAChDooB,EAAWrkB,EAAIu0B,EAAWt4B,GAAKsX,EAAE5X,KACjC2oB,EAAWtkB,EAAIu0B,EAAWt4B,GAAKsX,EAAE1X,KAGnCykB,EAAWkC,8BAA8BxP,GACzCsN,EAAWkC,8BAA8B7kB,GACzC2iB,EAAWkC,8BAA8B/c,GAG3C,MAAMovB,EACFvU,EAAWmB,eAAe5C,EAAa,UAAWwF,GAChDyQ,EACFxU,EAAWmB,eAAe5C,EAAa,UAAWyF,GAEhDnlB,EAASoiB,EACX,CAAClB,OAAQ,CAAC1kB,KAAMk5B,EAAWh5B,KAAMi5B,GAAYr7B,QAAS6mB,IAK1D,OAHAA,EAAWkC,8BAA8BqS,GACzCvU,EAAWkC,8BAA8BsS,GAElC31B,WAGOw1B,GACZlvB,EAAmB4uB,EACnB/T,GACF,MAAMyU,EAAYh8B,OAAK8J,cAAc4C,EAAM7K,OAErC45B,EAAYlU,EAAW9lB,KAAKO,IAAI0K,EAAMvK,QAEtCslB,EACFF,EAAW9lB,KAAKO,IAAIy5B,EAAU/4B,mBAAmBE,KAAKT,QAAQP,OAG5D8lB,EACFH,EAAW9lB,KAAKO,IAAIy5B,EAAU/4B,mBAAmBI,KAAKX,QAAQP,OAGlE,GAsD6B,KADRiD,EArDHm3B,GAsDHn3B,EAAO,GAtDQ,CAC5B,MAAMuB,EAyDV,SAAS61B,EACLxU,EAAwBC,EAAwB7iB,EAChDy2B,EACA/T,GACF,GAAa,IAAT1iB,EACF,MAAO,CAACjC,KAAM6kB,EAAU3kB,KAAM4kB,GAGhC,MAAMjmB,EAAOQ,eAAac,uBAAuB0kB,EAAUC,GAErDwU,EAAOr3B,EAAO,EAEds3B,EAAcl6B,eAAam6B,qBAAqB36B,GAEhD46B,EAAeF,EAAYv5B,KAC3B05B,EAAeH,EAAYr5B,KAE3By5B,EAAY,CAACF,EAAap3B,QAE1Bu3B,EACFjV,EAAWmB,eAAe6T,EAAW,UAAWF,GAC9CI,EACFlV,EAAWmB,eAAe6T,EAAW,UAAWD,GAE9CI,EAAiBlU,EACnB,CAAClB,OAAQ,CAAC1kB,KAAM45B,EAAc15B,KAAM25B,GAAe/7B,QAAS6mB,IAE1DoV,EAAa16B,eAAa26B,oBAAoBn7B,GAE9Co7B,EAAcF,EAAW/5B,KACzBk6B,EAAcH,EAAW75B,KAEzBi6B,EAAW,CAACF,EAAY53B,QAExB+3B,EACFzV,EAAWmB,eAAeqU,EAAU,UAAWF,GAC7CI,EACF1V,EAAWmB,eAAeqU,EAAU,UAAWD,GAE7CI,EAAgB1U,EAClB,CAAClB,OAAQ,CAAC1kB,KAAMo6B,EAAal6B,KAAMm6B,GAAcv8B,QAAS6mB,IAGxD4V,EACFlB,EAAUI,EAAcC,EAAcJ,EAAMZ,EAAS/T,GAEnD6V,EAAgBD,EAAav6B,KAC7By6B,EAAgBF,EAAar6B,KAE7Bw6B,EAAa,CAACF,EAAcn4B,QAE5Bs4B,EACFhW,EAAWmB,eAAe4U,EAAY,UAAWF,GAC/CI,EACFjW,EAAWmB,eAAe4U,EAAY,UAAWD,GAE/CI,EAAkBjV,EAAQ,CAC9BlB,OAAQ,CAAC1kB,KAAM26B,EAAez6B,KAAM06B,GACpC98B,QAAS6mB,IAGLmW,EACFzB,EAAUY,EAAaC,EAAaZ,EAAMZ,EAAS/T,GAEjDoW,EAAeD,EAAY96B,KAC3Bg7B,EAAeF,EAAY56B,KAE3B+6B,EAAY,CAACF,EAAa14B,QAE1B64B,EACFvW,EAAWmB,eAAemV,EAAW,UAAWF,GAC9CI,EACFxW,EAAWmB,eAAemV,EAAW,UAAWD,GAE9CI,EAAiBxV,EACnB,CAAClB,OAAQ,CAAC1kB,KAAMk7B,EAAch7B,KAAMi7B,GAAer9B,QAAS6mB,IAE1D0W,EAAIh8B,eAAai8B,UAAUr5B,EAAMy2B,GACjC6C,EAAS,CAACF,EAAEr7B,KAAKqC,QAEjBm5B,EAAY7W,EAAWmB,eAAeyV,EAAQ,UAAWF,EAAEr7B,MAC3Dy7B,EAAY9W,EAAWmB,eAAeyV,EAAQ,UAAWF,EAAEn7B,MAE3D2lB,EAAcD,EAChB,CAAClB,OAAQ,CAAC1kB,KAAMw7B,EAAWt7B,KAAMu7B,GAAY39B,QAAS6mB,IAEpD+W,EACFnQ,EACI,CAAC7G,OAAQ,CAACvgB,EAAG0hB,EAAaxhB,EAAG+2B,GAAiBt9B,QAAS6mB,IAGzDgX,EAAUvS,EAAI,CACF1E,OAAQ,CAACvgB,EAAG02B,EAAiBx2B,EAAGq3B,GAChC59B,QAAS6mB,IAErBiX,EAAU3O,GAAI,CACFvI,OAAQ,CAACvgB,EAAG02B,EAAiBx2B,EAAGq3B,GAChC59B,QAAS6mB,IAGrBkX,EAAc77B,EAAK,CAAC0kB,OAAQ,CAAC5a,MAAO6xB,GAAU79B,QAAS6mB,IACvDmX,EAAc97B,EAAK,CAAC0kB,OAAQ,CAAC5a,MAAO8xB,GAAU99B,QAAS6mB,IAEvDoX,EAAc77B,GAAK,CAACwkB,OAAQ,CAAC5a,MAAO6xB,GAAU79B,QAAS6mB,IACvDqX,EAAc97B,GAAK,CAACwkB,OAAQ,CAAC5a,MAAO8xB,GAAU99B,QAAS6mB,IAEvDsX,EAAQzI,GAAO,CACnB9O,OAAQ,CAACmX,EAAuBC,GAChCh+B,QAAS6mB,EACT8B,MAAO,CAAC9kB,KAAM,KAEVu6B,GAAQ1I,GAAO,CACnB9O,OAAQ,CAACqX,EAAuBC,GAChCl+B,QAAS6mB,EACT8B,MAAO,CAAC9kB,KAAM,KAGVw6B,GAAYxX,EAAW9lB,KAAKO,IAAI68B,EAAM18B,QAAQP,OAC9Co9B,GAAYzX,EAAW9lB,KAAKO,IAAI88B,GAAM38B,QAAQP,OA2BpD,OAzBA2lB,EAAWkC,8BAA8B+S,GACzCjV,EAAWkC,8BAA8BgT,GACzClV,EAAWkC,8BAA8BiT,GACzCnV,EAAWkC,8BAA8BuT,GACzCzV,EAAWkC,8BAA8BwT,GACzC1V,EAAWkC,8BAA8ByT,GACzC3V,EAAWkC,8BAA8B8T,GACzChW,EAAWkC,8BAA8B+T,GACzCjW,EAAWkC,8BAA8BgU,GACzClW,EAAWkC,8BAA8BqU,GACzCvW,EAAWkC,8BAA8BsU,GACzCxW,EAAWkC,8BAA8BuU,GACzCzW,EAAWkC,8BAA8B2U,GACzC7W,EAAWkC,8BAA8B4U,GACzC9W,EAAWkC,8BAA8BhB,GACzClB,EAAWkC,8BAA8B6U,GACzC/W,EAAWkC,8BAA8B8U,GACzChX,EAAWkC,8BAA8B+U,GACzCjX,EAAWkC,8BAA8BgV,GACzClX,EAAWkC,8BAA8BkV,GACzCpX,EAAWkC,8BAA8BiV,GACzCnX,EAAWkC,8BAA8BmV,GACzCrX,EAAWkC,8BAA8BoV,GACzCtX,EAAWkC,8BAA8BqV,IAElC,CAACl8B,KAAMm8B,GAAWj8B,KAAMk8B,IAzMzB/C,CAAUxU,EAAUC,EAAUsU,EAAWV,EAAS/T,GAEhDzB,EAAc,CAACpZ,EAAM7K,MAAM,GAAI6K,EAAM7K,MAAM,IAEjD,GAAIy5B,EAAS,CACX,MAAM2D,EACF1X,EAAWmB,eAAe5C,EAAa,UAAW1f,EAAOxD,MACvDs8B,EACF3X,EAAWmB,eAAe5C,EAAa,UAAW1f,EAAOtD,MAEvDq8B,EAAuB5X,EAAWmB,eACpC,GAAI,UACJ1oB,OAAKo/B,kBAAkBpD,EAA8B,YACnDqD,EACFxW,EAAS,CAACvB,OAAQ,CAAC3mB,EAAGw+B,GAAWz+B,QAAS6mB,IAExC+X,EACFrF,GAAU7S,WACN,CAACE,OAAQ,CAACvgB,EAAGk4B,EAAUh4B,EAAGk4B,GAAWz+B,QAAS6mB,IAEhDgY,EACFtF,GAAU7S,WACN,CAACE,OAAQ,CAACvgB,EAAGm4B,EAAUj4B,EAAGo4B,GAAe3+B,QAAS6mB,IAGpDiY,EACFjY,EAAW9lB,KAAKO,IAAIs9B,EAAYn9B,QAAQP,OACtC69B,EACFlY,EAAW9lB,KAAKO,IAAIu9B,EAAYp9B,QAAQP,OAS5C,OAPA2lB,EAAWkC,8BAA8BwV,GACzC1X,EAAWkC,8BAA8ByV,GACzC3X,EAAWkC,8BAA8B0V,GACzC5X,EAAWkC,8BAA8B4V,GACzC9X,EAAWkC,8BAA8B6V,GACzC/X,EAAWkC,8BAA8B8V,GAElC,CAAC38B,KAAM48B,EAAa18B,KAAM28B,GAGnC,OAAOr5B,EACF,CACL,MAEMs5B,EAiKV,SACIj+B,EAAkBoD,EAAcy2B,GAClC,MAAMqE,EAAM,IAAItzB,aAAoB,EAAPxH,GAE7B,IAAK,IAAIoV,EAAI,EAAGA,EAAIpV,EAAMoV,IAAK,CAC7B,IAAIrX,EAAO,EACPE,EAAO,EACX,IAAK,IAAI0X,EAAI,EAAGA,EAAI3V,EAAM2V,IAAK,CAC7B,MAAMyjB,EAAIh8B,eAAa29B,SAAS3lB,EAAIO,EAAG3V,EAAMy2B,GACvCuE,EAAO59B,eAAa45B,oBAAoBp6B,EAAsB+Y,GACpE5X,GAAQi9B,EAAKj9B,KAAOq7B,EAAEr7B,KAAOi9B,EAAK/8B,KAAOm7B,EAAEn7B,KAC3CA,GAAQ+8B,EAAKj9B,KAAOq7B,EAAEn7B,KAAO+8B,EAAK/8B,KAAOm7B,EAAEr7B,KAEzC04B,IACF14B,GAAQiC,EACR/B,GAAQ+B,GAEV5C,eAAa69B,mBAAmBH,EAAK/8B,EAAME,EAAMmX,GAEnD,OAAO0lB,EAnLDI,CAHS99B,eAAac,uBAAuB0kB,EAAUC,GAGxBsU,EAAWV,GAE9C,OAAOr5B,eAAa+9B,uBAAuBN,GAI/C,IAAuB76B,ECjHhB,MAAMo7B,GAA0B,CACrChZ,WAAYiZ,MACZ/Y,YAAa,MACbC,oBA/BkBC,GAElB,MAAMC,OAACA,EAAM5mB,QAAEA,GAAW2mB,GACpB3a,MAACA,GAAS4a,EAEV0U,EAAYh8B,OAAK8J,cAAc4C,EAAM7K,OAGrCs+B,EAAqBzzB,EAAM7K,MAAM6K,EAAM7K,MAAMoD,OAAS,GAGtDm7B,EAAUv6B,GAAQ,CACtByhB,OAAQ,CAAC3mB,EAAG+L,GACZhM,QAAAA,EACA2oB,MAAO,CAACxnB,MAAO,CALHm6B,EAAYmE,EAKDA,MAGnB/5B,EAASi1B,GAAS+E,GAAS,EAAO1/B,GAElC2/B,EACFx6B,GAAQ,CAACyhB,OAAQ,CAAC3mB,EAAGyF,GAAS1F,QAAAA,EAAS2oB,MAAO,CAACxnB,MAAO6K,EAAM7K,SAKhE,OAHAnB,EAAQ+oB,8BAA8B2W,GACtC1/B,EAAQ+oB,8BAA8BrjB,GAE/Bi6B,IC1BIC,GAAoC,CAC/CrZ,WAAYsZ,gBACZpZ,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ+B,MAAAA,EAAO3oB,QAAAA,MAC3B,MAAM8/B,MAACA,GAASlZ,EACVC,EAAa7mB,EAEboV,EAAS9V,OAAKmoB,uBAChBqY,EAAMtgC,MAA0BF,OAAK8J,cAAc02B,EAAM3+B,SACtDuU,EAAOiN,EAAaC,EAAY3J,GAAe6mB,EAAM3+B,MAEtD+hB,EAAY2D,EAAW9lB,KAAKO,IAAIw+B,EAAMr+B,QAAQP,OAEpD,IAAK,IAAI6+B,EAAW,EAAGA,EAAWrqB,EAAOqqB,IAAY,CACnD,MAAMpjB,EAAcojB,EAAWnd,EAAaD,EAAc1J,EAE1D,IAAK,IAAIqd,EAAM,EAAGA,EAAM3T,EAAa2T,IAAO,CAC1C,MAAM1Z,EAAY0Z,GAAO1T,EAAa3J,GAEtC,IAAK,IAAIud,EAAM,EAAGA,EAAM5T,EAAY4T,IAAO,CACzC,MAAM1Z,EAAY0Z,EAAMvd,EAExB,IAAK,IAAIpD,EAAU,EAAGA,EAAUoD,EAAapD,IAAW,CACtD,MAEM5V,EAFS,CAACyV,EAAO4gB,EAAKE,EAAK3gB,GAEhB,GAEXmqB,EAASj5B,KAAK8V,MAAM+F,EAAa3iB,GACjCggC,EAAStjB,EAAcC,EAAYE,EAAYjH,EAErD,IAAIqqB,EAAchd,EAAU+c,GAE5B,GAAID,GAAU,GAAKA,EAASpd,EAAY,CAKtCsd,EAAchd,EADVvG,EAAcC,EAFOojB,EAAS/mB,EAEepD,GAGnDT,EAAO6qB,GAAUC,KAOzB,MAAO,CAACz+B,OADOolB,EAAWjlB,MAAMwT,EAAQ0qB,EAAM3+B,MAAO2+B,EAAMtgC,OAC3C2B,MAAO2+B,EAAM3+B,MAAO3B,MAAOsgC,EAAMtgC,SCjB9C,MAAM2gC,GAA2B,CACtC5Z,WAAY6Z,OACZ3Z,YAAa,MACbC,oBA/BmBC,GAEnB,MAAMC,OAACA,EAAM5mB,QAAEA,GAAW2mB,GACpB3a,MAACA,GAAS4a,EAEV0U,EAAYh8B,OAAK8J,cAAc4C,EAAM7K,OAGrCs+B,EAAqBzzB,EAAM7K,MAAM6K,EAAM7K,MAAMoD,OAAS,GAGtDm7B,EAAUv6B,GAAQ,CACtByhB,OAAQ,CAAC3mB,EAAG+L,GACZhM,QAAAA,EACA2oB,MAAO,CAACxnB,MAAO,CALHm6B,EAAYmE,EAKDA,MAGnB/5B,EAASi1B,GAAS+E,GAAS,EAAM1/B,GAEjC2/B,EACFx6B,GAAQ,CAACyhB,OAAQ,CAAC3mB,EAAGyF,GAAS1F,QAAAA,EAAS2oB,MAAO,CAACxnB,MAAO6K,EAAM7K,SAKhE,OAHAnB,EAAQ+oB,8BAA8B2W,GACtC1/B,EAAQ+oB,8BAA8BrjB,GAE/Bi6B,IC3BIU,GACT3U,EAAgB4U,WAAWvU,GAAO9W,OAAOsrB,SAASxU,GAAM,EAAI,EAAG,QAEtDyU,GAA+B,CAC1Cja,WAAY+Z,WACZ7Z,YAAa,MACbC,WAAY2Z,ICNDI,GACT/U,EAAgBgV,QAAQ3U,GAAOhlB,KAAKsf,IAAI0F,KAAQ4U,EAAAA,EAAW,EAAI,EAAG,QAEzDC,GAA4B,CACvCra,WAAYma,QACZja,YAAa,MACbC,WAAY+Z,ICNDI,GACTnV,EAAgBoV,QAAQ/U,GAAO9W,OAAOqC,MAAMyU,GAAM,EAAI,EAAG,QAEhDgV,GAA4B,CACvCxa,WAAYua,QACZra,YAAa,MACbC,WAAYma,ICNDG,GAAkBtV,EAAgBuV,QAAQlV,GAAOhlB,KAAKm6B,MAAMnV,IAE5DoV,GAA4B,CACvC5a,WAAY0a,QACZxa,YAAa,MACbC,WAAYsa,ICLDI,GACT1V,EAAgB2V,aAAatV,GAAOA,EAAK,EAAI,EAAG,QAEvCuV,GAAiC,CAC5C/a,WAAY8a,aACZ5a,YAAa,MACbC,WAAY0a,ICADG,GAA0B,CACrChb,WAAYib,MACZ/a,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ+B,MAAAA,EAAO3oB,QAAAA,MAC3B,MAAMC,EAACA,GAAK2mB,GACN6a,iBAACA,EAAgBC,SAAEA,GAAY/Y,EAC/B9B,EAAa7mB,EACnB,IAAIuvB,EAAStvB,EAAEkB,MACf,MAAMsuB,EAAQF,EAAOhrB,OAEfo9B,EAAWriC,OAAK0G,eAAey7B,EAAkBlS,GACvD,IAAIxpB,EAAO47B,EACX,MAAMC,EAAergC,eAAasgC,mBAAmB97B,EAAM0pB,GAC3D,IAAI/qB,EAAQmiB,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,OAC1C,GAAoB,MAAhB0gC,EAAsB,CACxB,MAAMnuB,EAAqB,IAAIvU,MAAMuwB,GACrC,IAAK,IAAIvrB,EAAI,EAAGA,EAAIuP,EAASlP,OAAQL,IACnCuP,EAASvP,GAAKqrB,EAAOqS,EAAa19B,IAGpCQ,EAAQ4qB,GAAc5qB,EAAO6qB,EAAQtvB,EAAET,MAAOoiC,EAAcnuB,GAC5D1N,EAAOxE,eAAaugC,iBAAiB/7B,EAAKxB,OAAQkrB,GAElDF,EAAS9b,EAGX1U,EAAiBkB,EAAG,OACpBsB,eAAasH,2BAA2B,MAAO9C,EAAM0pB,GACrD,MAAOsS,EAAaj5B,GAChBvH,eAAawH,0BAA0BwmB,EAAQxpB,GAI7CL,EAAS4nB,EAAQ5oB,EAFJpF,OAAK8J,cAAcN,GAEIi5B,EAAa9hC,EAAET,OACnDiC,EAASolB,EAAWjlB,MAAM8D,EAAQq8B,EAAa9hC,EAAET,OAEvD,IAAIiE,EAAWs+B,EACf,GAAIL,EAAU,CAGZj+B,EADiBlC,eAAa6E,qBAAqB27B,EAAaJ,GAIlE,MAAO,CAAClgC,OAAAA,EAAQN,MAAOsC,EAAUjE,MAAOS,EAAET,SCdvC,MAAMwiC,GAA8B,CACzCzb,WAAY0b,UACZxb,YAAa,MACbC,oBAnCEC,GAGF,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B1mB,EAACA,GAAK2mB,EACZ7nB,EAAiBkB,EAAG,WACpB,MAAM8yB,WAACA,EAAUvvB,QAAEA,EAAOwvB,IAAEA,EAAGC,gBAAEA,GAAmBtK,EAGpDrpB,OAAKC,OACDgC,eAAa2xB,+BAA+B1vB,EAH9B,GAId,IAAM,4DACF,eAAeA,uBAEvB,MAAM0I,EAAW3K,eAAa4xB,kBAC1BlzB,EAAEkB,MAA2C4xB,EAAYvvB,EAR3C,EASHwvB,EAAKC,GACpB,IAAIhuB,EAEJ,GAA6B,IAAzBiH,EAASG,aAA+C,IAA1BH,EAASE,cACvC9M,OAAK8zB,YAAYlnB,EAASmE,QAASnE,EAASzI,UAC9CwB,EAAMkjB,EAAS,CAACvB,OAAQ,CAAC3mB,EAAAA,GAAID,QAAAA,QACxB,CACL,MAAM4S,EAAU5S,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACrCsC,EAAUlE,OAAKioB,eAAetnB,EAAEkB,OAChC4C,EAASuuB,GAAK1f,EAAS3S,EAAEkB,MAAOlB,EAAET,MAAOgE,EAAS0I,EAAU,OAClEjH,EAAMjF,EAAQgoB,eACV9b,EAASzI,SAAUxD,EAAET,MAAOuE,EAAO7C,QAEzC,OAAO+D,IC2CF,MAAMi9B,GAAsC,CACjD3b,WAAY4b,kBACZ1b,YAAa,MACbC,oBA7E8BC,GAK9B,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3Bnb,GAACA,EAAEQ,MAAEA,EAAKoJ,OAAEA,GAAUwR,EACtB3mB,EAAI+L,EACVjN,EAAiB,CAACiN,EAAOoJ,GAAS,mBAClC,MAAM2d,WAACA,EAAUvvB,QAAEA,EAAOwvB,IAAEA,EAAGC,gBAAEA,GAAmBtK,EAE9Czc,EAAW3K,eAAa4xB,kBAC1BlzB,EAAEkB,MAA2C4xB,EAAYvvB,EACzD,EAAmBwvB,EAAKC,GACtBrgB,EAAU5S,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACrCwX,EAAY3U,SACdmI,EAASzI,SAAUxD,EAAET,MACrBkzB,GAAiB9f,EAAS3S,EAAEkB,MAAOlB,EAAET,MAAO0M,GAAUhL,QACpD8M,EAAe9B,EAAS8B,aACxBU,EAAcxC,EAASwC,YACvBpC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBuI,EAAwB5I,EAAS4I,sBACjCC,EAAuB7I,EAAS6I,qBAChCvI,EAAUuI,EAAuB,EAAI7I,EAASO,QAAQC,KACtDC,EAASmI,EAAwB,EAAI5I,EAASO,QAAQG,IACtDwD,EACFrM,SAAgB9D,EAAEkB,MAA2C,WAE3DoyB,EAASvzB,EAAQe,KAAKO,IAAIkK,EAAG/J,QAAQP,OACrCiR,EAAQpO,SACVyH,EAAGrK,MAA2C,UAAWoyB,GAE7D,IAAK,IAAIhtB,EAAI,EAAGA,EAAI2F,EAASuB,YAAalH,EACxC,IAAK,IAAI/D,EAAI,EAAGA,EAAI0J,EAAS+C,aAAczM,EACzC,IAAK,IAAI4Y,EAAM,EAAGA,EAAMlP,EAASiC,WAAYiN,EAC3C,IAAK,IAAIO,EAAM,EAAGA,EAAMzP,EAAS2C,UAAW8M,EAAK,CAE/C,MAAM6X,EAAYpY,EAAMzO,EAClB8mB,EAAY9X,EAAMnP,EACxB,IAAI0E,EAAU,EACd,IAAK,IAAIjD,EAAK,EAAGA,EAAK6G,EAAuB7G,GAAM3B,EAAgB,CACjE,MAAMoR,GAAO8V,EAAYvlB,GAAMD,EAC/B,KAAI0P,EAAM,GAAKA,GAAOxR,EAAS2B,WAC3B9G,KAAK6B,MAAM8U,KAASA,GAGxB,IAAK,IAAI/O,EAAK,EAAGA,EAAKoG,EAAsBpG,GAAMpC,EAAe,CAC/D,MAAMsR,GAAO4V,EAAY9kB,GAAMD,EAC/B,GAAImP,EAAM,GAAKA,GAAO3R,EAASqC,UAC3BxH,KAAK6B,MAAMiV,KAASA,EACtB,SAEF,MAIMlF,EAJS7D,EAAwBC,EAAuB,EACzD2D,EAAUpX,IAAIiF,EAAGmX,EAAKG,EAAKrb,KACjByL,EAAK8G,EAAuBpG,EAEV,EAAI,EACxB,IAATgK,IAKJzH,GADciB,EAAM7Q,IAAIiF,EAAGmX,EAAKG,EAAKrb,GAClBmW,IAGvBvI,EAAG1O,IAAIwP,EAAS3K,EAAG6U,EAAKO,EAAKnZ,GAKrC,OAAOxC,EAAQgoB,eAAe5X,EAAGjP,MAAOiP,EAAG5Q,MAAO4Q,EAAGlP,UCrEhD,MAAMkhC,GAAwC,CACnD7b,WAAY8b,oBACZ5b,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ+B,MAAAA,EAAO3oB,QAAAA,MAC3B,MAAMC,EAACA,GAAK2mB,GACNmM,WAACA,EAAUvvB,QAAEA,EAAOwvB,IAAEA,EAAGJ,oBAAEA,GAC7BjK,EACE9B,EAAa7mB,EACnBjB,EAAiBkB,EAAG,qBAEpB,MAAMiB,EAAS2lB,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,OACvCgL,EAAW3K,eAAa4xB,kBAC1BlzB,EAAEkB,MAA2C4xB,EAAYvvB,EACzD,CAAC,EAAG,GAAIwvB,IACLsP,EAAQC,YClBf3vB,EAAqB2c,EAAkB/vB,EACvCozB,EAA8B1mB,GAChC,MACMs2B,EAAWlQ,GAAK1f,EAAS2c,EAAQ/vB,EADvBF,OAAKioB,eAAegI,GACmBrjB,EAAU,OAC3DoM,EAAeoa,GACjB9f,EAAS2c,EAAQ/vB,EAAO0M,GAAU,EAAM0mB,GAE5C,MAAO,CAAC4P,EAASthC,OAAQoX,EAAapX,QDWVuhC,CACtBvhC,EAAQjB,EAAEkB,MAAOlB,EAAET,MAAOozB,EAAqB1mB,GAE7Cw2B,EACF7b,EAAWjlB,MAAM0gC,EAAwBp2B,EAASzI,SAAUxD,EAAET,OAC5DmjC,EACF9b,EAAWjlB,MAAM2gC,EAAuBr2B,EAASzI,SAAUxD,EAAET,OACjE,MAAO,CACL,CAACiC,OAAQihC,EAAcvhC,MAAO+K,EAASzI,SAAUjE,MAAOS,EAAET,OAC1D,CAACiC,OAAQkhC,EAAexhC,MAAO+K,EAASzI,SAAUjE,MAAO,YE3BzDojC,GAA0BljC,eAAakjC,wBAIhCC,GAA0C,CACrDtc,WAAYuc,sBACZrc,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ5mB,QAAAA,EAAS2oB,MAAAA,MAC7B,MAAMvI,MAACA,EAAKC,OAAEA,GAAUuG,GAClBtG,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAcuiB,mBAAEA,GAChDpa,EAEE9B,EAAa7mB,EAEnBjB,EAAiBqhB,EAAO,2BAExB,MAAMK,EAAYoG,EAAW9lB,KAAKO,IAAI8e,EAAM3e,QAAQP,OAC9Cwf,EAAamG,EAAW9lB,KAAKO,IAAI+e,EAAO5e,QAAQP,QAEhD8hC,gBAACA,EAAeC,aAAEA,GAAgBL,GACpCniB,EAAWC,EAAYJ,EAAeC,EAAcC,EACpDuiB,GAEJ,MAAO,CAACC,EAAiBC,KCvBvBC,GAA0BxjC,eAAawjC,wBAIhCC,GAA0C,CACrD5c,WAAY6c,sBACZ3c,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ5mB,QAAAA,EAAS2oB,MAAAA,MAC7B,MAAMvI,MAACA,EAAKC,OAAEA,GAAUuG,GAClBtG,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAc6iB,aAAEA,GAChD1a,EAEE9B,EAAa7mB,EAEnBjB,EAAiBqhB,EAAO,8BAExB,MAAMK,EAAYoG,EAAW9lB,KAAKO,IAAI8e,EAAM3e,QAAQP,OAC9Cwf,EAAamG,EAAW9lB,KAAKO,IAAI+e,EAAO5e,QAAQP,OAEhDoiC,EAAmBhjB,EACnBijB,EAAkBhjB,EAClBijB,EAAoBhjB,EACpBijB,EAAkBJ,GAElBL,gBAACA,EAAeU,eAAEA,GAAkBR,GACtCziB,EAAWC,EAAY4iB,EAAkBC,EACzCC,EAAmBC,GAEvB,MAAO,CAACT,EAAiBU,KC1BhBC,GACTzc,GAA+B7gB,EAAGE,IAAOF,IAAME,EAAK,EAAI,GAC/Cq9B,GACTna,EAAiBoa,WAAUF,GAAc,KAAsB,QAEtDG,GAA+B,CAC1Cvd,WAAYsd,WACZpd,YAAa,MACbC,WAAYkd,ICkCP,MAAMG,GAA4B,CACvCxd,WAAYyd,QACZvd,YAAa,MACbC,oBA5CEC,GAEF,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B1mB,EAACA,GAAK2mB,GACNqd,SAACA,EAAQC,cAAEA,GAAiBvb,EAElC5pB,EAAiBkB,EAAG,OAEpB,MAAMwD,EAAWwgC,EAAS1hC,IACtB,CAACo3B,EAAGz1B,IAAMy1B,EAAE,GAAqB15B,EAAEkB,MAAM+C,GAAKy1B,EAAE,IAE9C12B,EAAQghC,EAAS1hC,IAAIo3B,GAAKA,EAAE,IAE5Bj1B,EAAQ1E,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACnCyqB,EAAQrsB,OAAK8J,cAAcnJ,EAAEkB,OAC7BsuB,EAAQxvB,EAAEkB,MAAMoD,OAChB6pB,EAAW9uB,OAAKioB,eAAetnB,EAAEkB,OAEjCqmB,EAAaloB,OAAK8J,cAAc3F,GAChC4jB,EAAa5jB,EAASc,OACtB+iB,EAAgBhoB,OAAKioB,eAAe9jB,GACpCsE,EACFzI,OAAKmoB,uBAAuBxnB,EAAET,MAA0BgoB,GAEtC,IAAlB0c,GACFn8B,EAAQhD,KAAKm/B,GAGf,IAAK,IAAIhgC,EAAI,EAAGA,EAAIynB,EAAOznB,IAAK,CAC9B,MACMigC,EADS7kC,OAAK+E,WAAWH,EAAGurB,EAAOrB,GAChB7rB,IAAI,CAACuX,EAAG5V,IAAM4V,EAAI7W,EAAMiB,IAGjD6D,EAFiBzI,OAAKuU,WAAWswB,EAAW9c,EAAYC,IAEpC5iB,EAAMR,GAK5B,MAAO,CAACzC,OAFMzB,EAAQ4B,MAAMmG,EAAStE,EAAUxD,EAAET,OAE1B2B,MAAOsC,EAAUjE,MAAOS,EAAET,SCxCtC4kC,GAAuB1Y,EAAgB2Y,aAAatY,GAAO,EAAIA,GAE/DuY,GAAiC,CAC5C/d,WAAY8d,aACZ5d,YAAa,MACbC,WAAY0d,ICJDG,GAAuC,CAClDhe,WAAYie,mBACZ/d,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ+B,MAAAA,EAAO3oB,QAAAA,MAC3B,MAAM8/B,MAACA,GAASlZ,GACV6d,QAACA,EAAOC,UAAEA,EAASC,OAAEA,GAAUhc,EAC/B9B,EAAa7mB,EAEboV,EAAS9V,OAAKmoB,uBAChBqY,EAAMtgC,MAA0BF,OAAK8J,cAAc02B,EAAM3+B,SACtDuU,EAAOiN,EAAaC,EAAY3J,GAAe6mB,EAAM3+B,OAErDyjC,EAASC,GACZtjC,eAAaujC,eAAeH,EAAQhiB,EAAaC,GAG/CmiB,EAAYh+B,KAAKi+B,IAAIP,GACrBQ,EAAYl+B,KAAKgwB,IAAI0N,GACrBvhB,EAAY2D,EAAW9lB,KAAKO,IAAIw+B,EAAMr+B,QAAQP,OAEpD,IAAK,IAAI6+B,EAAW,EAAGA,EAAWrqB,EAAOqqB,IAAY,CACnD,MAAMpjB,EAAcojB,EAAWnd,EAAaD,EAAc1J,EAE1D,IAAK,IAAIqd,EAAM,EAAGA,EAAM3T,EAAa2T,IAAO,CAC1C,MAAM1Z,EAAY0Z,GAAO1T,EAAa3J,GAEtC,IAAK,IAAIud,EAAM,EAAGA,EAAM5T,EAAY4T,IAAO,CACzC,MAAM1Z,EAAY0Z,EAAMvd,EAExB,IAAK,IAAIpD,EAAU,EAAGA,EAAUoD,EAAapD,IAAW,CACtD,MAAMqvB,EAAS,CAACxvB,EAAO4gB,EAAKE,EAAK3gB,GAE3B5V,EAAIilC,EAAO,GACXz5B,EAAIy5B,EAAO,GAGjB,IAAIlF,GAAU//B,EAAI2kC,GAAWK,GAAax5B,EAAIo5B,GAAWE,EACrDI,GAAUllC,EAAI2kC,GAAWG,GAAat5B,EAAIo5B,GAAWI,EACzDjF,EAASj5B,KAAK8V,MAAMmjB,EAAS4E,GAC7BO,EAASp+B,KAAK8V,MAAMsoB,EAASN,GAE7B,IAAI3E,EAAcwE,EAUlB,GATyB,iBAAdA,IAEPxE,EADc,IAAZrqB,EA7BW,IAgCC6uB,EAAU7uB,IAKxBmqB,GAAU,GAAKA,EAASpd,GAAcuiB,GAAU,GAChDA,EAASxiB,EAAa,CAMxBud,EAAchd,EADVvG,EAHqBwoB,GAAUviB,EAAa3J,GACvB+mB,EAAS/mB,EAEsBpD,GAK1DT,EADeuH,EAAcC,EAAYE,EAAYjH,GACpCqqB,KAOzB,MAAO,CAACz+B,OADOolB,EAAWjlB,MAAMwT,EAAQ0qB,EAAM3+B,MAAO2+B,EAAMtgC,OAC3C2B,MAAO2+B,EAAM3+B,MAAO3B,MAAOsgC,EAAMtgC,SCtExC4lC,GAAkB1Z,EAAgB2Z,QAAQtZ,IAErD,MAAMuZ,EAAOv+B,KAAK6B,MAAMmjB,GACxB,OAAIA,EAAKuZ,EAAO,GACPv+B,KAAK6B,MAAMmjB,GACTA,EAAKuZ,EAAO,GACdv+B,KAAK+J,KAAKib,GAEbuZ,EAAO,GAAQ,EACVA,EAEAA,EAAO,IAKPC,GAA4B,CACvChf,WAAY8e,QACZ5e,YAAa,MACbC,WAAY0e,ICnBRI,GAAajkC,eAAakkC,gBAC1B7R,GAAQryB,eAAamkC,WAEdC,GAAiBja,EAAgBka,OAAO7Z,GAC/CA,GAAM,EACD6H,GAAQ7H,EAERyZ,IAAcz+B,KAAKqlB,IAAIL,GAAM,IAI3B8Z,GAA2B,CACtCtf,WAAYqf,OACZnf,YAAa,MACbC,WAAYif,ICdDG,GACTpa,EAAgBqa,UAAUha,GAAO,GAAK,EAAIhlB,KAAKqlB,KAAKL,KAE3Cia,GAA8B,CACzCzf,WAAYwf,UACZtf,YAAa,MACbC,WAAYof,ICNDG,GAAiBva,EAAgBwa,OAAOna,GAC/CA,EAAK,GACC,EACCA,EAAK,EACP,EAEA,GAIEoa,GAA2B,CACtC5f,WAAY2f,OACZzf,YAAa,MACbC,WAAYuf,ICbDG,GAAgB1a,EAAgB2a,MAAMta,GAAOhlB,KAAKi+B,IAAIjZ,IAEtDua,GAA0B,CACrC/f,WAAY8f,MACZ5f,YAAa,MACbC,WAAY0f,ICLDG,GAAiB7a,EAAgB8a,OAAOza,GAAOhlB,KAAK0/B,KAAK1a,IAEzD2a,GAA2B,CACtCngB,WAAYigB,OACZ/f,YAAa,MACbC,WAAY6f,ICCRI,GAAY5/B,KAAKmmB,IADP,uBACsB,EAEzB0Z,GAAqBlb,EAAgBmb,WAAW9a,IAG3D,MAAM+a,EAAW/a,GAAM4a,GAIjBI,EAAWhb,EAAK4a,GAEhBK,EAAOjgC,KAAKqlB,IAAIL,GACtB,IAAIrmB,EASJ,OANEA,EADEqhC,EACOC,EACAF,EACA/a,EAEAhlB,KAAKmmB,IAAI,EAAM8Z,GAEnBthC,IAGIuhC,GAA+B,CAC1C1gB,WAAYsgB,WACZpgB,YAAa,MACbC,WAAYkgB,aC9BEM,GAAUvgB,GAKxB,MAAMC,OAACA,EAAM+B,MAAEA,EAAK3oB,QAAEA,GAAW2mB,GAC3B1mB,EAACA,GAAK2mB,GACN4I,KAACA,GAAQ7G,EAEf5pB,EAAiBkB,EAAG,aAEpB,MAAMwvB,EAAQxvB,EAAEkB,MAAMoD,OAEhBkP,EAAqB,IAAIvU,MAAMuwB,GACrC,IAAK,IAAIvrB,EAAI,EAAGA,EAAIuP,EAASlP,OAAQL,IACnCuP,EAASvP,GAAKjE,EAAEkB,MAAMquB,EAAKtrB,IAG7B,MACMwB,EAAS4pB,GADAtvB,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,OACLjB,EAAEkB,MAAOlB,EAAET,MAAOgwB,EAAM/b,GAG7D,MAAO,CAAChS,OADOzB,EAAQ4B,MAAM8D,EAAQ+N,EAAUxT,EAAET,OACjC2B,MAAOsS,EAAUjU,MAAOS,EAAET,OAGrC,MAAM2nC,GAAgC,CAC3C5gB,WAAY6gB,YACZ3gB,YAAa,MACbC,WAAYwgB,ICgCP,MAAMG,GAAqC,CAChD9gB,WAAY+gB,iBACZ7gB,YAAa,MACbC,oBA7D6BC,GAK7B,MAAMC,OAACA,EAAM5mB,QAAEA,EAAO2oB,MAAEA,GAAShC,GAC3B1mB,EAACA,GAAK2mB,GACN9S,WAACA,EAAUmwB,SAAEA,GAAYtb,EAE/B5pB,EAAiB,CAACkB,GAAI,kBAEtB,MAAMsJ,EAAOjK,OAAK8J,cAAc0K,GAE1ByzB,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiBv9B,QAASi6B,GAE1B,IAAK,IAAI//B,EAAI,EAAI4P,EAAWvP,OAAQL,EAAIjE,EAAEkB,MAAMoD,SAAUL,EACxDqjC,EAAiBv9B,KAAK,CAAC,EAAG,IAG5B,MAAMw9B,EAAUzD,GAAYrd,WAAW,CACrCE,OAAQ,CAAC3mB,EAAAA,GACTD,QAAAA,EACA2oB,MAAO,CAACsb,SAAUsD,EAAkBrD,cAAe,KAG/CuD,EACFlmC,eAAa2S,YAAYszB,EAAQrmC,MAAO2S,EAAYvK,GAAM,GAExDm+B,EAAoCnmC,eAAa6S,YACnDqzB,EAAoBljC,OAAQuP,EAAWvP,QAAQ,GAE7C2hB,EACF3kB,eAAa+S,oBAAoBkzB,EAAQrmC,MAAO2S,EAAYvK,GAAM,GAIhEo+B,EACFxiC,GAAQ,CAACyhB,OAHwB,CAAC3mB,EAAGunC,GAGLxnC,QAAAA,EAAS2oB,MAFV,CAACxnB,MAAOsmC,KAOrCG,EACFV,GAAU,CAACtgB,OAJ0B,CAAC3mB,EAAG0nC,GAIL3nC,QAAAA,EAAS2oB,MAF5B,CAAC6G,KAAMkY,KAMtBhiC,EAASP,GACX,CAACyhB,OAHsC,CAAC3mB,EAAG2nC,GAGb5nC,QAAAA,EAAS2oB,MAFF,CAACxnB,MAAO+kB,KAQjD,OAJAlmB,EAAQ+oB,8BAA8Bye,GACtCxnC,EAAQ+oB,8BAA8B4e,GACtC3nC,EAAQ+oB,8BAA8B6e,GAE/BliC,IC5DImiC,GAAiBnc,EAAgBoc,OAAO/b,GAAOhlB,KAAK8mB,KAAK9B,IAEzDgc,GAA2B,CACtCxhB,WAAYuhB,OACZrhB,YAAa,MACbC,WAAYmhB,ICJDG,GAA6B,CACxCzhB,WAAY0hB,SACZxhB,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQ5mB,QAAAA,MACpB,MAAMC,EAACA,GAAK2mB,EACNC,EAAa7mB,EACnBjB,EAAiBkB,EAAG,UAEpB,MAAMiB,EAAS2lB,EAAW9lB,KAAKO,IAAIrB,EAAEwB,QAAQP,OACvC4J,EAAY,IAAIa,aAAazK,EAAOqD,QAC1C,IAAK,IAAIL,EAAI,EAAGA,EAAIhD,EAAOqD,SAAUL,EAAG,CACtC,MAAMiG,EAAQjJ,EAAOgD,GACrB4G,EAAU5G,GAAKiG,EAAQA,EAGzB,MAAO,CAAC1I,OADOolB,EAAWjlB,MAAMkJ,EAAW7K,EAAEkB,MAAOlB,EAAET,OACtC2B,MAAOlB,EAAEkB,MAAO3B,MAAOS,EAAET,SCfhC0oC,GAAwBhhB,GAA+B7gB,EAAGE,KACrE,MAAM8E,EAAOhF,EAAIE,EACjB,OAAO8E,EAAOA,IAEH88B,GACT1e,EAAiB2e,oBAAmBF,IAE3BG,GAAwC,CACnD9hB,WAAY6hB,oBACZ3hB,YAAa,MACbC,WAAYyhB,ICXDG,GAAiB5c,EAAgB6c,OAAM,CAACxc,EAAIpD,KACvD,MAAM6f,EAAY7f,EAClB,OAAIrR,MAAMyU,GACD0c,IAEA1c,EAAK,EAAI,EAAIyc,EAAUxqB,QAIrB0qB,GAA2B,CACtCniB,WAAYgiB,OACZ9hB,YAAa,MACbC,WAAY4hB,ICZDK,GAAgBjd,EAAgBkd,MAAM7c,GAAOhlB,KAAK8hC,IAAI9c,IAEtD+c,GAA0B,CACrCviB,WAAYqiB,MACZniB,YAAa,MACbC,WAAYiiB,ICLDI,GAAiBrd,EAAgBsd,OAAOjd,GAAOhlB,KAAKkiC,KAAKld,IAEzDmd,GAA2B,CACtC3iB,WAAYyiB,OACZviB,YAAa,MACbC,WAAYqiB,ICeP,MAAMI,GAA6B,CACxC5iB,WAAY6iB,SACZ3iB,YAAa,MACbC,oBAnBEC,GAEF,MAAMC,OAACA,EAAM+B,MAAEA,EAAK3oB,QAAEA,GAAW2mB,GAC3B9iB,KAACA,GAAQ8kB,GACT1oB,EAACA,GAAK2mB,EACZ7nB,EAAiBkB,EAAG,UAEpB,MAAMiB,EAASlB,EAAQe,KAAKO,IAAIrB,EAAEwB,QAAQP,QACpC2vB,aAACA,EAAYjM,YAAEA,EAAWpR,QAAEA,GAC9Bmc,GAAWzuB,EAAQ2C,EAAM5D,EAAEkB,MAAOlB,EAAET,OACxC,MAAO,CACLQ,EAAQgoB,eAAepD,EAAa3kB,EAAET,MAAOqxB,GAC7C7wB,EAAQgoB,eAAe,CAACxU,EAAQjP,QAAS,QAASiP,MCwDhD61B,GAAgC,CACpC/iB,EACA2K,GACAI,GACA7F,EACAiG,GACAI,GACAI,GACAI,GACAQ,GACAQ,GACAK,GACAnK,EACA2C,EACA+I,GACAhN,EACA0O,GACAK,GACAI,GACAC,GACA2B,GACAV,GACAiB,GACAG,GACAgB,GACAnO,EACAK,EACA2S,GACAK,GACA5S,EACA3E,EACA8X,GACAhL,GACAqL,GACAI,GACAG,GACA1T,EACA8T,GACAG,GACAU,GACAE,GACAE,GACAb,GACA5T,EACAkV,GACAM,GACAW,GACAC,GACAvb,EACA8b,GACA9O,GACA+O,GACAgB,GACAvX,EACA6X,GACAG,GACAG,GACAG,GACAI,GACA3X,GACAkY,GACAI,GACAU,GACAC,GACAK,GACAK,GACArZ,GACAyZ,GACAI,GACA/B,GACAgC,IAGF,IAAK,MAAMG,KAAgBD,GACzBE,iBAAeD,gDCpKD"}